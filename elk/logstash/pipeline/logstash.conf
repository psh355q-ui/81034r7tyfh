input {
  # Filebeat input
  beats {
    port => 5044
    codec => json
  }

  # TCP input for direct application logs
  tcp {
    port => 5000
    codec => json_lines
    type => "app-logs"
  }

  # UDP input for syslog
  udp {
    port => 5000
    codec => json_lines
    type => "app-logs"
  }
}

filter {
  # Parse JSON logs
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      target => "parsed"
    }
  }

  # Extract log level
  if [parsed][level] {
    mutate {
      add_field => { "log_level" => "%{[parsed][level]}" }
    }
  } else if [log][level] {
    mutate {
      add_field => { "log_level" => "%{[log][level]}" }
    }
  }

  # Parse timestamp
  if [parsed][timestamp] {
    date {
      match => ["[parsed][timestamp]", "ISO8601", "yyyy-MM-dd HH:mm:ss"]
      target => "@timestamp"
    }
  }

  # Extract service name from container labels or log
  if [container][labels][com.docker.compose.service] {
    mutate {
      add_field => { "service_name" => "%{[container][labels][com.docker.compose.service]}" }
    }
  } else if [parsed][service] {
    mutate {
      add_field => { "service_name" => "%{[parsed][service]}" }
    }
  }

  # Classify log types
  if [service_name] == "backend" {
    mutate {
      add_tag => ["backend"]
    }

    # Extract API endpoint
    if [parsed][path] or [parsed][endpoint] {
      mutate {
        add_field => { "api_endpoint" => "%{[parsed][path]}" }
      }
    }

    # Extract response time
    if [parsed][duration] or [parsed][response_time] {
      mutate {
        add_field => { "response_time_ms" => "%{[parsed][duration]}" }
      }
      mutate {
        convert => { "response_time_ms" => "float" }
      }
    }

    # Extract user/ticker information
    if [parsed][ticker] {
      mutate {
        add_field => { "ticker" => "%{[parsed][ticker]}" }
      }
    }

    if [parsed][user_id] {
      mutate {
        add_field => { "user_id" => "%{[parsed][user_id]}" }
      }
    }
  }

  # Frontend logs
  if [service_name] == "frontend" {
    mutate {
      add_tag => ["frontend"]
    }
  }

  # Database logs
  if [service_name] =~ /postgres|timescale/ {
    mutate {
      add_tag => ["database"]
    }

    # Extract slow query information
    if [message] =~ /duration/ {
      grok {
        match => { "message" => "duration: %{NUMBER:query_duration_ms:float} ms" }
      }
    }
  }

  # Redis logs
  if [service_name] == "redis" {
    mutate {
      add_tag => ["cache"]
    }
  }

  # Error detection
  if [log_level] =~ /(?i)error|critical|fatal/ or [message] =~ /(?i)error|exception|traceback/ {
    mutate {
      add_tag => ["error"]
    }
  }

  # Warning detection
  if [log_level] =~ /(?i)warning|warn/ {
    mutate {
      add_tag => ["warning"]
    }
  }

  # Trading activity detection
  if [message] =~ /(?i)trade|order|buy|sell/ {
    mutate {
      add_tag => ["trading"]
    }
  }

  # AI/ML activity detection
  if [message] =~ /(?i)openai|gpt|ai|model|prediction/ {
    mutate {
      add_tag => ["ai"]
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => ["agent", "ecs", "input", "host"]
  }
}

output {
  # Main output to Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "ai-trading-%{+YYYY.MM.dd}"
    codec => json
  }

  # Error logs to separate index
  if "error" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "ai-trading-errors-%{+YYYY.MM.dd}"
      codec => json
    }
  }

  # Trading logs to separate index
  if "trading" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "ai-trading-trades-%{+YYYY.MM.dd}"
      codec => json
    }
  }

  # AI logs to separate index (for cost tracking)
  if "ai" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "ai-trading-ai-%{+YYYY.MM.dd}"
      codec => json
    }
  }

  # Debug output (comment out in production)
  # stdout {
  #   codec => rubydebug
  # }
}
