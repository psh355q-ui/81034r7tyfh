"""
KIS Auto Trading Scheduler - Enhanced News + RAG í†µí•©

ì‹¤ì‹œê°„ ë‰´ìŠ¤ â†’ 4-way Filter â†’ RAG â†’ KIS ìë™ë§¤ë§¤ íŒŒì´í”„ë¼ì¸

íŒŒì´í”„ë¼ì¸:
1. Enhanced News Crawler (30ë¶„ë§ˆë‹¤) + í‚¤ì›Œë“œ íƒœê¹…
2. 4-way í•„í„°ë§ (70% ë…¸ì´ì¦ˆ ì œê±°)
   - ìœ„í—˜ í´ëŸ¬ìŠ¤í„° (30%)
   - ì„¹í„°ë³„ ë²¡í„° (20%)
   - í­ë½ íŒ¨í„´ (30%)
   - ê°ì„± ì‹œê³„ì—´ (20%)
3. RAG-Enhanced Analysis (SEC ë¬¸ì„œ ì°¸ì¡°)
4. Phase Pipeline (Security â†’ Phase A/B/C)
5. KIS: ì‹¤ì œ ì£¼ë¬¸ ì‹¤í–‰

ì‘ì„±ì¼: 2025-12-03 (Updated with 4-way filter)
"""

import asyncio
import logging
import os
from datetime import datetime
from typing import Optional, List, Dict, Any

# APScheduler
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
import pytz

# Enhanced News Crawler with 4-way Filter
try:
    from backend.news.enhanced_news_crawler import EnhancedNewsCrawler
    ENHANCED_CRAWLER_AVAILABLE = True
except ImportError:
    from backend.news.news_crawler import NewsAPICrawler as EnhancedNewsCrawler
    ENHANCED_CRAWLER_AVAILABLE = False
    logging.warning("Enhanced News Crawler not available, using basic crawler")

# RAG-Enhanced Analysis
try:
    from backend.ai.rag_enhanced_analysis import RAGEnhancedAnalysis
    RAG_AVAILABLE = True
except ImportError:
    RAG_AVAILABLE = False
    logging.warning("RAG-Enhanced Analysis not available")

# KIS Integration
try:
    from backend.api.kis_integration_router import (
        KISAutoTradeRequest,
        kis_auto_trade,
        get_kis_broker
    )
    KIS_AVAILABLE = True
except ImportError:
    KIS_AVAILABLE = False
    logging.warning("KIS integration not available")

logger = logging.getLogger(__name__)


class KISAutoScheduler:
    """
    KIS ìë™ë§¤ë§¤ ìŠ¤ì¼€ì¤„ëŸ¬ (Enhanced + RAG)
    
    Enhanced News Crawler â†’ 4-way Filter â†’ RAG â†’ Phase Pipeline â†’ KIS Trading
    """
    
    def __init__(
        self,
        news_api_key: Optional[str] = None,
        kis_account_no: Optional[str] = None,
        is_virtual: bool = True,
        dry_run: bool = False,
        notifier: Optional[Any] = None,
        filter_threshold: float = 0.7,  # 4-way í•„í„° ì„ê³„ê°’
        db_session: Optional[Any] = None  # RAGìš© DB ì„¸ì…˜
    ):
        """
        Args:
            news_api_key: NewsAPI í‚¤
            kis_account_no: KIS ê³„ì¢Œë²ˆí˜¸
            is_virtual: ëª¨ì˜íˆ¬ì ì—¬ë¶€
            dry_run: Dry Run ëª¨ë“œ (ì£¼ë¬¸ ì•ˆ í•¨)
            notifier: ì•Œë¦¼ í´ë¼ì´ì–¸íŠ¸
            filter_threshold: 4-way í•„í„° ì„ê³„ê°’ (0.7 = 70%)
            db_session: RAGìš© DB ì„¸ì…˜
        """
        self.is_virtual = is_virtual
        self.dry_run = dry_run
        self.kis_account_no = kis_account_no or os.getenv('KIS_ACCOUNT_NUMBER')
        self.notifier = notifier
        self.filter_threshold = filter_threshold
        
        # Enhanced News Crawler ì´ˆê¸°í™” (4-way filter í¬í•¨)
        self.news_crawler = EnhancedNewsCrawler(api_key=news_api_key)
        
        # RAG-Enhanced Analysis (ì„ íƒì )
        if RAG_AVAILABLE and db_session:
            self.rag_analyzer = RAGEnhancedAnalysis(db_session)
            logger.info("RAG-Enhanced Analysis enabled")
        else:
            self.rag_analyzer = None
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”
        self.scheduler = AsyncIOScheduler()
        self.is_running = False
        
        # ì‹œê°„ëŒ€
        self.us_eastern = pytz.timezone('US/Eastern')
        self.korea = pytz.timezone('Asia/Seoul')
        
        # í†µê³„ (enhanced)
        self.stats = {
            'total_news_crawled': 0,
            'total_news_filtered': 0,  # 4-way í•„í„° í†µê³¼
            'total_signals_generated': 0,
            'total_orders_executed': 0,
            'start_time': None
        }
        
        logger.info(
            f"KISAutoScheduler initialized "
            f"(enhanced={ENHANCED_CRAWLER_AVAILABLE}, rag={RAG_AVAILABLE}, "
            f"kis={KIS_AVAILABLE}, filter={filter_threshold})"
        )
    
    def setup_jobs(self):
        """ìŠ¤ì¼€ì¤„ ì‘ì—… ì„¤ì •"""
        
        # 1. ë‰´ìŠ¤ í¬ë¡¤ë§ + ë§¤ë§¤ ì‚¬ì´í´ (30ë¶„ë§ˆë‹¤, ì¥ ì‹œê°„ë§Œ)
        self.scheduler.add_job(
            self.trading_cycle,
            IntervalTrigger(minutes=30),
            id='trading_cycle',
            name='News Crawling + Trading (Every 30min)'
        )
        
        # 2. ì¥ì „ ë¶„ì„ (í•œêµ­ ì‹œê°„ 22:00 = US 9:00 AM)
        self.scheduler.add_job(
            self.pre_market_analysis,
            CronTrigger(
                day_of_week='mon-fri',
                hour=22,
                minute=0,
                timezone=self.korea
            ),
            id='pre_market_analysis',
            name='Pre-Market Analysis'
        )
        
        # 3. ì¥ ë§ˆê° ë¦¬í¬íŠ¸ (í•œêµ­ ì‹œê°„ 06:00)
        self.scheduler.add_job(
            self.market_close_report,
            CronTrigger(
                day_of_week='tue-sat',
                hour=6,
                minute=0,
                timezone=self.korea
            ),
            id='market_close_report',
            name='Market Close Report'
        )
        
        logger.info("Scheduled jobs configured")
    
    async def trading_cycle(self):
        """ë§¤ë§¤ ì‚¬ì´í´: Enhanced í¬ë¡¤ë§ + 4-way í•„í„°ë§ + RAG"""
        
        # ì¥ ì‹œê°„ ì²´í¬
        if not self._is_market_hours():
            logger.debug("Outside market hours, skipping trading cycle")
            return
        
        logger.info("=" * 70)
        logger.info("TRADING CYCLE STARTED (Enhanced + 4-way Filter)")
        logger.info("=" * 70)
        
        try:
            # Step 1: Enhanced í¬ë¡¤ë§ + íƒœê¹… + 4-way í•„í„°ë§
            logger.info("Step 1: Crawling + Tagging + Filtering...")
            
            if ENHANCED_CRAWLER_AVAILABLE and hasattr(self.news_crawler, 'crawl_and_filter'):
                # 4-way í•„í„° ì‚¬ìš©
                articles = await self.news_crawler.crawl_and_filter(
                    hours=0.5,
                    filter_threshold=self.filter_threshold
                )
                logger.info(f"Filtered: {len(articles)} articles passed 4-way filter")
                self.stats['total_news_filtered'] += len(articles)
            else:
                # fallback: ê¸°ë³¸ í¬ë¡¤ëŸ¬
                articles = await self.news_crawler.crawl_and_tag(hours=0.5)
                logger.info(f"Found {len(articles)} articles (no filter)")
            
            if not articles:
                logger.info("No articles after filtering")
                return
            
            self.stats['total_news_crawled'] += len(articles)
            
            # Step 2: ê° ë‰´ìŠ¤ â†’ RAG ë¶„ì„ â†’ KIS auto-trade
            for article in articles:
                await self._process_article(article)
            
            logger.info(
                f"Trading cycle completed: {len(articles)} articles processed "
                f"(filter pass rate: {100 * len(articles) / max(self.stats['total_news_crawled'], 1):.1f}%)"
            )
        
        except Exception as e:
            logger.error(f"Trading cycle failed: {e}", exc_info=True)
            if self.notifier:
                await self.notifier.send(f"âš ï¸ Trading cycle error: {e}")
    
    async def _process_article(self, article: Dict[str, Any]):
        """
        ë‹¨ì¼ ê¸°ì‚¬ ì²˜ë¦¬: Phase Pipeline â†’ KIS Order
        
        Args:
            article: ë‰´ìŠ¤ ê¸°ì‚¬ dict
        """
        try:
            title = article.get('title', '')
            description = article.get('description', '')
            url = article.get('url', '')
            source = article.get('source', 'Unknown')
            
            logger.info(f"Processing: {title[:60]}...")
            
            # KIS Auto Trade ìš”ì²­ ìƒì„±
            request = KISAutoTradeRequest(
                headline=title,
                body=description or '',
                url=url,
                is_virtual=self.is_virtual,
                dry_run=self.dry_run
            )
            
            # Phase Pipeline ì‹¤í–‰
            if KIS_AVAILABLE:
                result = await kis_auto_trade(request)
                
                # ê²°ê³¼ ë¶„ì„
                analysis = result.analysis
                
                logger.info(
                    f"[{source}] {analysis.final_ticker} {analysis.final_action} "
                    f"(confidence: {analysis.final_confidence:.0%})"
                )
                
                # ì£¼ë¬¸ ì‹¤í–‰ ì—¬ë¶€
                if result.kis_order_executed:
                    self.stats['total_orders_executed'] += 1
                    order_result = result.kis_order_result
                    
                    logger.info(
                        f"âœ… ORDER EXECUTED: {order_result.side} {order_result.symbol} "
                        f"x{order_result.quantity}"
                    )
                    
                    # ì•Œë¦¼ ì „ì†¡
                    if self.notifier:
                        await self.notifier.send(
                            f"ğŸ¤– **KIS Auto Trade**\n\n"
                            f"ğŸ“° {title[:80]}\n"
                            f"ğŸ“Š {order_result.side} {order_result.symbol} x{order_result.quantity}\n"
                            f"ğŸ’° Confidence: {analysis.final_confidence:.0%}\n"
                            f"ğŸ”— {url[:50]}"
                        )
                else:
                    logger.info(f"No order executed (confidence or filters)")
                
                self.stats['total_signals_generated'] += 1
            
            else:
                logger.warning("KIS not available, skipping order execution")
            
            # ê¸°ì‚¬ ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ
            news_id = article.get('id')
            if news_id:
                self.news_crawler.mark_as_processed(news_id)
        
        except Exception as e:
            logger.error(f"Failed to process article: {e}", exc_info=True)
    
    async def pre_market_analysis(self):
        """ì¥ì „ ë¶„ì„"""
        logger.info("=" * 70)
        logger.info("PRE-MARKET ANALYSIS")
        logger.info("=" * 70)
        
        try:
            # ì§€ë‚œ 12ì‹œê°„ ë‰´ìŠ¤ í¬ë¡¤ë§
            logger.info("Crawling overnight news...")
            articles = await self.news_crawler.crawl_latest(hours=12)
            
            if articles:
                logger.info(f"Found {len(articles)} overnight articles")
                
                # ê°„ë‹¨í•œ ìš”ì•½
                summary = f"ğŸŒ… **ì¥ì „ ë¶„ì„**\n\n"
                summary += f"ğŸ“° Overnight News: {len(articles)}ê±´\n"
                summary += f"ğŸ• Market opens in 30 minutes\n\n"
                
                # ìƒìœ„ 3ê°œ í—¤ë“œë¼ì¸
                for i, article in enumerate(articles[:3], 1):
                    summary += f"{i}. {article['title'][:60]}...\n"
                
                if self.notifier:
                    await self.notifier.send(summary)
                else:
                    logger.info(summary)
        
        except Exception as e:
            logger.error(f"Pre-market analysis failed: {e}")
    
    async def market_close_report(self):
        """ì¥ ë§ˆê° ë¦¬í¬íŠ¸"""
        logger.info("=" * 70)
        logger.info("MARKET CLOSE REPORT")
        logger.info("=" * 70)
        
        try:
            # ì˜¤ëŠ˜ì˜ í†µê³„
            report = f"""
ğŸ“Š **ì¼ì¼ ë¦¬í¬íŠ¸ ({datetime.now(self.korea).strftime('%Y-%m-%d')})**

ğŸ“° ë‰´ìŠ¤ í¬ë¡¤ë§: {self.stats['total_news_crawled']}ê±´
ğŸ¤– ì‹œê·¸ë„ ìƒì„±: {self.stats['total_signals_generated']}ê±´
ğŸ’¼ ì£¼ë¬¸ ì‹¤í–‰: {self.stats['total_orders_executed']}ê±´

ëª¨ë“œ: {'ëª¨ì˜íˆ¬ì' if self.is_virtual else 'ì‹¤ì „íˆ¬ì'}
Dry Run: {'ON' if self.dry_run else 'OFF'}

ì˜¤ëŠ˜ë„ ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤! ğŸŒ™
            """
            
            if self.notifier:
                await self.notifier.send(report)
            else:
                logger.info(report)
            
            # í†µê³„ ë¦¬ì…‹ (ì¼ì¼)
            self.stats['total_news_crawled'] = 0
            self.stats['total_signals_generated'] = 0
            self.stats['total_orders_executed'] = 0
        
        except Exception as e:
            logger.error(f"Market close report failed: {e}")
    
    def _is_market_hours(self) -> bool:
        """ë¯¸êµ­ ì¥ ì‹œê°„ í™•ì¸"""
        now = datetime.now(self.us_eastern)
        
        # ì£¼ë§ ì œì™¸
        if now.weekday() >= 5:
            return False
        
        # 9:30 AM ~ 4:00 PM ET
        from datetime import time
        market_open = time(9, 30)
        market_close = time(16, 0)
        current_time = now.time()
        
        return market_open <= current_time <= market_close
    
    async def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        logger.info("=" * 70)
        logger.info("KIS AUTO TRADING SCHEDULER STARTING")
        logger.info("=" * 70)
        
        self.stats['start_time'] = datetime.now()
        
        self.setup_jobs()
        self.scheduler.start()
        self.is_running = True
        
        # ì‹œì‘ ì•Œë¦¼
        start_message = f"""
âœ… **KIS ìë™ë§¤ë§¤ ë´‡ ê°€ë™ë¨**

ğŸ“… {datetime.now(self.korea).strftime('%Y-%m-%d %H:%M:%S KST')}
ğŸ“Š ëª¨ë“œ: {'ëª¨ì˜íˆ¬ì (Virtual)' if self.is_virtual else 'ì‹¤ì „íˆ¬ì (Real)'}
ğŸ§ª Dry Run: {'ON (ë¶„ì„ë§Œ)' if self.dry_run else 'OFF (ì£¼ë¬¸ ì‹¤í–‰)'}
ğŸ“° NewsAPI: {'Enabled' if self.news_crawler.enabled else 'Disabled (Mock)'}
ğŸ’¼ KIS: {'Available' if KIS_AVAILABLE else 'Not Available'}

ìŠ¤ì¼€ì¤„:
â€¢ ë‰´ìŠ¤ í¬ë¡¤ë§: 30ë¶„ë§ˆë‹¤ (ì¥ ì‹œê°„)
â€¢ ì¥ì „ ë¶„ì„: 22:00 KST
â€¢ ì¥ ë§ˆê°: 06:00 KST
        """
        
        if self.notifier:
            await self.notifier.send(start_message)
        
        logger.info(start_message)
        logger.info(f"Scheduled {len(self.scheduler.get_jobs())} jobs")
        
        # ë¬´í•œ ëŒ€ê¸°
        try:
            while self.is_running:
                await asyncio.sleep(1)
        except KeyboardInterrupt:
            logger.info("Received shutdown signal")
            self.stop()
    
    def stop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
        logger.info("Stopping scheduler...")
        self.scheduler.shutdown()
        self.is_running = False
        logger.info("Scheduler stopped")
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ì¡°íšŒ"""
        uptime = None
        if self.stats['start_time']:
            uptime = (datetime.now() - self.stats['start_time']).total_seconds()
        
        return {
            **self.stats,
            'uptime_seconds': uptime,
            'is_running': self.is_running,
            'is_virtual': self.is_virtual,
            'dry_run': self.dry_run
        }


# ============================================================================
# Mock Notifier
# ============================================================================

class MockNotifier:
    """í…ŒìŠ¤íŠ¸ìš© ì•Œë¦¼ í´ë˜ìŠ¤"""
    
    async def send(self, message: str):
        print(f"\n[NOTIFICATION]\n{message}\n")


# ============================================================================
# í…ŒìŠ¤íŠ¸
# ============================================================================

if __name__ == "__main__":
    async def test():
        print("=" * 70)
        print("KIS Auto Scheduler Test")
        print("=" * 70)
        
        # Mock notifier
        notifier = MockNotifier()
        
        # Scheduler ì´ˆê¸°í™”
        scheduler = KISAutoScheduler(
            is_virtual=True,
            dry_run=True,  # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
            notifier=notifier
        )
        
        print(f"\nNewsAPI enabled: {scheduler.news_crawler.enabled}")
        print(f"KIS available: {KIS_AVAILABLE}")
        print(f"Is market hours: {scheduler._is_market_hours()}")
        
        # í•œ ë²ˆ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
        print("\nRunning single trading cycle...")
        await scheduler.trading_cycle()
        
        # í†µê³„ ì¡°íšŒ
        print("\nStats:")
        stats = scheduler.get_stats()
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        print("\n=== Test PASSED! ===")
    
    asyncio.run(test())
