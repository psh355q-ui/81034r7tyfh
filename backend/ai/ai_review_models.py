"""
AI Review Data Models and Repository

ë¡œì»¬ JSON ì €ì¥ìœ¼ë¡œ AI ë¶„ì„ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
"""

import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Optional, Dict, Any
from dataclasses import dataclass, asdict
import hashlib


# ============================================================================
# Data Directory
# ============================================================================

# Docker ì»¨í…Œì´ë„ˆ í˜¸í™˜ ê²½ë¡œ
DATA_DIR = Path("/app/data/ai_reviews")
try:
    DATA_DIR.mkdir(parents=True, exist_ok=True)
except PermissionError:
    DATA_DIR = Path("/tmp/ai_reviews")
    DATA_DIR.mkdir(parents=True, exist_ok=True)


# ============================================================================
# Data Classes
# ============================================================================

@dataclass
class AIAnalysisResult:
    """AI ë¶„ì„ ê²°ê³¼"""
    action: str  # BUY, SELL, HOLD
    conviction: float  # 0.0 ~ 1.0
    reasoning: str
    target_price: Optional[float] = None
    stop_loss: Optional[float] = None
    position_size: float = 0.0
    risk_factors: List[str] = None
    
    def __post_init__(self):
        if self.risk_factors is None:
            self.risk_factors = []


@dataclass
class DetailedReasoning:
    """ìƒì„¸ ë¶„ì„ ê·¼ê±°"""
    technical_analysis: str = ""
    fundamental_analysis: str = ""
    sentiment_analysis: str = ""
    risk_assessment: str = ""


@dataclass
class ModelInfo:
    """AI ëª¨ë¸ ì •ë³´"""
    model_name: str
    tokens_used: int
    response_time_ms: int
    cost_usd: float = 0.0


@dataclass
class DiffFromPrevious:
    """ì´ì „ ë¶„ì„ ëŒ€ë¹„ ë³€ê²½ì‚¬í•­"""
    has_changes: bool
    conviction_change: float = 0.0
    action_changed: bool = False
    reasoning_diff: str = ""


@dataclass
class AIReviewRecord:
    """AI ë¶„ì„ ê¸°ë¡"""
    analysis_id: str
    ticker: str
    timestamp: str
    analysis: AIAnalysisResult
    detailed_reasoning: DetailedReasoning
    model_info: ModelInfo
    diff_from_previous: Optional[DiffFromPrevious] = None
    
    def to_dict(self) -> dict:
        """Convert to dictionary for JSON serialization"""
        data = asdict(self)
        return data
    
    @classmethod
    def from_dict(cls, data: dict) -> 'AIReviewRecord':
        """Create from dictionary"""
        return cls(
            analysis_id=data['analysis_id'],
            ticker=data['ticker'],
            timestamp=data['timestamp'],
            analysis=AIAnalysisResult(**data['analysis']),
            detailed_reasoning=DetailedReasoning(**data['detailed_reasoning']),
            model_info=ModelInfo(**data['model_info']),
            diff_from_previous=DiffFromPrevious(**data['diff_from_previous']) 
                if data.get('diff_from_previous') else None
        )


# ============================================================================
# Repository
# ============================================================================

class AIReviewRepository:
    """
    AI ë¶„ì„ ê²°ê³¼ ì €ì¥ì†Œ
    
    Features:
    - ë¡œì»¬ JSON íŒŒì¼ ì €ì¥
    - í‹°ì»¤ë³„ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
    - ìë™ diff ê³„ì‚°
    - ê²€ìƒ‰ ë° í•„í„°ë§
    """
    
    def __init__(self, data_dir: Path = DATA_DIR):
        self.data_dir = data_dir
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # Index file for quick lookups
        self.index_file = self.data_dir / "index.json"
        self._ensure_index()
    
    def _ensure_index(self):
        """ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±"""
        if not self.index_file.exists():
            self._save_index({
                "total_count": 0,
                "reviews": [],
                "by_ticker": {},
                "last_updated": datetime.utcnow().isoformat()
            })
    
    def _load_index(self) -> dict:
        """ì¸ë±ìŠ¤ íŒŒì¼ ë¡œë“œ"""
        try:
            with open(self.index_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            return {
                "total_count": 0,
                "reviews": [],
                "by_ticker": {},
                "last_updated": datetime.utcnow().isoformat()
            }
    
    def _save_index(self, index: dict):
        """ì¸ë±ìŠ¤ íŒŒì¼ ì €ì¥"""
        index["last_updated"] = datetime.utcnow().isoformat()
        with open(self.index_file, 'w', encoding='utf-8') as f:
            json.dump(index, f, ensure_ascii=False, indent=2)
    
    def _generate_id(self, ticker: str, timestamp: str) -> str:
        """ê³ ìœ  ID ìƒì„±"""
        content = f"{ticker}_{timestamp}"
        return hashlib.sha256(content.encode()).hexdigest()[:16]
    
    def _get_file_path(self, analysis_id: str) -> Path:
        """ë¶„ì„ IDë¡œ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
        return self.data_dir / f"{analysis_id}.json"
    
    def _calculate_diff(self, ticker: str, new_analysis: AIAnalysisResult) -> Optional[DiffFromPrevious]:
        """ì´ì „ ë¶„ì„ê³¼ ë¹„êµ"""
        previous = self.get_latest_by_ticker(ticker)
        
        if not previous:
            return None
        
        prev_analysis = previous.analysis
        
        # ë³€ê²½ ì‚¬í•­ ê³„ì‚°
        action_changed = prev_analysis.action != new_analysis.action
        conviction_change = new_analysis.conviction - prev_analysis.conviction
        
        # ì£¼ìš” ì°¨ì´ì  ì„¤ëª…
        diff_parts = []
        
        if action_changed:
            diff_parts.append(f"íˆ¬ì ì˜ê²¬ ë³€ê²½: {prev_analysis.action} â†’ {new_analysis.action}")
        
        if abs(conviction_change) > 0.1:
            direction = "ìƒìŠ¹" if conviction_change > 0 else "í•˜ë½"
            diff_parts.append(f"í™•ì‹ ë„ {direction}: {conviction_change * 100:.1f}%p")
        
        # ê°€ê²© ëª©í‘œ ë³€ê²½
        if prev_analysis.target_price and new_analysis.target_price:
            price_change = (new_analysis.target_price - prev_analysis.target_price) / prev_analysis.target_price * 100
            if abs(price_change) > 5:
                diff_parts.append(f"ëª©í‘œê°€ ë³€ê²½: ${prev_analysis.target_price:.2f} â†’ ${new_analysis.target_price:.2f} ({price_change:+.1f}%)")
        
        # ìƒˆë¡œìš´ ë¦¬ìŠ¤í¬ ìš”ì¸
        new_risks = set(new_analysis.risk_factors) - set(prev_analysis.risk_factors)
        if new_risks:
            diff_parts.append(f"ìƒˆë¡œìš´ ë¦¬ìŠ¤í¬: {', '.join(new_risks)}")
        
        has_changes = action_changed or abs(conviction_change) > 0.05 or len(diff_parts) > 0
        
        return DiffFromPrevious(
            has_changes=has_changes,
            conviction_change=conviction_change,
            action_changed=action_changed,
            reasoning_diff="\n".join(diff_parts) if diff_parts else "ì£¼ìš” ë³€ê²½ì‚¬í•­ ì—†ìŒ"
        )
    
    def save(self, record: AIReviewRecord) -> str:
        """
        AI ë¶„ì„ ê²°ê³¼ ì €ì¥
        
        Returns:
            analysis_id
        """
        # ìë™ diff ê³„ì‚°
        if record.diff_from_previous is None:
            record.diff_from_previous = self._calculate_diff(record.ticker, record.analysis)
        
        # íŒŒì¼ ì €ì¥
        file_path = self._get_file_path(record.analysis_id)
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(record.to_dict(), f, ensure_ascii=False, indent=2)
        
        # ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        index = self._load_index()
        
        # ìƒˆ ë ˆì½”ë“œ ì •ë³´ ì¶”ê°€
        review_summary = {
            "analysis_id": record.analysis_id,
            "ticker": record.ticker,
            "timestamp": record.timestamp,
            "action": record.analysis.action,
            "conviction": record.analysis.conviction,
            "reasoning_preview": record.analysis.reasoning[:200] + "..." if len(record.analysis.reasoning) > 200 else record.analysis.reasoning,
            "has_changes": record.diff_from_previous.has_changes if record.diff_from_previous else False,
            "model_name": record.model_info.model_name
        }
        
        # ì¤‘ë³µ ì²´í¬ (ê°™ì€ IDê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸)
        existing_idx = next(
            (i for i, r in enumerate(index["reviews"]) if r["analysis_id"] == record.analysis_id),
            None
        )
        
        if existing_idx is not None:
            index["reviews"][existing_idx] = review_summary
        else:
            index["reviews"].insert(0, review_summary)  # ìµœì‹  ìˆœ
            index["total_count"] += 1
        
        # í‹°ì»¤ë³„ ì¸ë±ìŠ¤
        if record.ticker not in index["by_ticker"]:
            index["by_ticker"][record.ticker] = []
        
        if record.analysis_id not in index["by_ticker"][record.ticker]:
            index["by_ticker"][record.ticker].insert(0, record.analysis_id)
        
        self._save_index(index)
        
        return record.analysis_id
    
    def get(self, analysis_id: str) -> Optional[AIReviewRecord]:
        """IDë¡œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        file_path = self._get_file_path(analysis_id)
        
        if not file_path.exists():
            return None
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return AIReviewRecord.from_dict(data)
        except (json.JSONDecodeError, KeyError) as e:
            print(f"Error loading {analysis_id}: {e}")
            return None
    
    def get_latest_by_ticker(self, ticker: str) -> Optional[AIReviewRecord]:
        """í‹°ì»¤ì˜ ìµœì‹  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        index = self._load_index()
        
        ticker_ids = index.get("by_ticker", {}).get(ticker, [])
        
        if not ticker_ids:
            return None
        
        return self.get(ticker_ids[0])
    
    def get_history_by_ticker(self, ticker: str, limit: int = 10) -> List[AIReviewRecord]:
        """í‹°ì»¤ë³„ ë¶„ì„ íˆìŠ¤í† ë¦¬"""
        index = self._load_index()
        
        ticker_ids = index.get("by_ticker", {}).get(ticker, [])[:limit]
        
        records = []
        for analysis_id in ticker_ids:
            record = self.get(analysis_id)
            if record:
                records.append(record)
        
        return records
    
    def list_all(self, limit: int = 50, offset: int = 0) -> Dict[str, Any]:
        """
        ëª¨ë“  ë¶„ì„ ëª©ë¡ ì¡°íšŒ
        
        Returns:
            {
                "total_count": int,
                "today_count": int,
                "avg_conviction": float,
                "changed_count": int,
                "reviews": List[dict]
            }
        """
        index = self._load_index()
        
        reviews = index.get("reviews", [])[offset:offset + limit]
        
        # í†µê³„ ê³„ì‚°
        today = datetime.utcnow().date()
        today_count = sum(
            1 for r in reviews
            if datetime.fromisoformat(r["timestamp"]).date() == today
        )
        
        avg_conviction = (
            sum(r["conviction"] for r in reviews) / len(reviews)
            if reviews else 0
        )
        
        changed_count = sum(1 for r in reviews if r.get("has_changes", False))
        
        return {
            "total_count": index.get("total_count", 0),
            "today_count": today_count,
            "avg_conviction": avg_conviction,
            "changed_count": changed_count,
            "reviews": reviews
        }
    
    def search(self, 
               ticker: Optional[str] = None,
               action: Optional[str] = None,
               min_conviction: Optional[float] = None,
               has_changes_only: bool = False,
               days_back: int = 30,
               limit: int = 50) -> List[dict]:
        """
        ë¶„ì„ ê²°ê³¼ ê²€ìƒ‰
        
        Args:
            ticker: íŠ¹ì • í‹°ì»¤
            action: BUY/SELL/HOLD
            min_conviction: ìµœì†Œ í™•ì‹ ë„
            has_changes_only: ë³€ê²½ì‚¬í•­ ìˆëŠ” ê²ƒë§Œ
            days_back: ìµœê·¼ Nì¼
            limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜
        """
        index = self._load_index()
        reviews = index.get("reviews", [])
        
        cutoff_date = datetime.utcnow() - timedelta(days=days_back)
        
        filtered = []
        for review in reviews:
            if len(filtered) >= limit:
                break
            
            # ë‚ ì§œ í•„í„°
            review_date = datetime.fromisoformat(review["timestamp"])
            if review_date < cutoff_date:
                continue
            
            # í‹°ì»¤ í•„í„°
            if ticker and review["ticker"] != ticker:
                continue
            
            # ì•¡ì…˜ í•„í„°
            if action and review["action"] != action:
                continue
            
            # í™•ì‹ ë„ í•„í„°
            if min_conviction and review["conviction"] < min_conviction:
                continue
            
            # ë³€ê²½ì‚¬í•­ í•„í„°
            if has_changes_only and not review.get("has_changes", False):
                continue
            
            filtered.append(review)
        
        return filtered
    
    def delete(self, analysis_id: str) -> bool:
        """ë¶„ì„ ê²°ê³¼ ì‚­ì œ"""
        file_path = self._get_file_path(analysis_id)
        
        if not file_path.exists():
            return False
        
        # íŒŒì¼ ì‚­ì œ
        file_path.unlink()
        
        # ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        index = self._load_index()
        
        index["reviews"] = [
            r for r in index["reviews"] 
            if r["analysis_id"] != analysis_id
        ]
        
        for ticker in index.get("by_ticker", {}):
            index["by_ticker"][ticker] = [
                aid for aid in index["by_ticker"][ticker]
                if aid != analysis_id
            ]
        
        index["total_count"] = len(index["reviews"])
        self._save_index(index)
        
        return True
    
    def get_statistics(self) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´"""
        index = self._load_index()
        reviews = index.get("reviews", [])
        
        if not reviews:
            return {
                "total": 0,
                "by_action": {},
                "by_ticker": {},
                "avg_conviction": 0,
                "changed_rate": 0
            }
        
        # ì•¡ì…˜ë³„ í†µê³„
        by_action = {}
        for review in reviews:
            action = review["action"]
            by_action[action] = by_action.get(action, 0) + 1
        
        # í‹°ì»¤ë³„ í†µê³„
        by_ticker = {}
        for ticker, ids in index.get("by_ticker", {}).items():
            by_ticker[ticker] = len(ids)
        
        # í™•ì‹ ë„ í‰ê· 
        avg_conviction = sum(r["conviction"] for r in reviews) / len(reviews)
        
        # ë³€ê²½ë¥ 
        changed_count = sum(1 for r in reviews if r.get("has_changes", False))
        changed_rate = changed_count / len(reviews) if reviews else 0
        
        return {
            "total": index.get("total_count", 0),
            "by_action": by_action,
            "by_ticker": dict(sorted(by_ticker.items(), key=lambda x: x[1], reverse=True)[:10]),
            "avg_conviction": avg_conviction,
            "changed_rate": changed_rate
        }


# ============================================================================
# Factory Function for Creating Records
# ============================================================================

def create_ai_review_record(
    ticker: str,
    analysis_result: dict,
    detailed_reasoning: dict,
    model_name: str,
    tokens_used: int,
    response_time_ms: int,
    cost_usd: float = 0.0
) -> AIReviewRecord:
    """
    AI ë¶„ì„ ê²°ê³¼ë¡œë¶€í„° ë ˆì½”ë“œ ìƒì„±
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        analysis_result: {action, conviction, reasoning, target_price, stop_loss, position_size, risk_factors}
        detailed_reasoning: {technical_analysis, fundamental_analysis, sentiment_analysis, risk_assessment}
        model_name: ì‚¬ìš©ëœ ëª¨ë¸ëª…
        tokens_used: ì‚¬ìš©ëœ í† í° ìˆ˜
        response_time_ms: ì‘ë‹µ ì‹œê°„ (ms)
        cost_usd: ë¹„ìš© (USD)
    """
    timestamp = datetime.utcnow().isoformat()
    analysis_id = AIReviewRepository()._generate_id(ticker, timestamp)
    
    return AIReviewRecord(
        analysis_id=analysis_id,
        ticker=ticker,
        timestamp=timestamp,
        analysis=AIAnalysisResult(
            action=analysis_result.get("action", "HOLD"),
            conviction=analysis_result.get("conviction", 0.5),
            reasoning=analysis_result.get("reasoning", ""),
            target_price=analysis_result.get("target_price"),
            stop_loss=analysis_result.get("stop_loss"),
            position_size=analysis_result.get("position_size", 0.0),
            risk_factors=analysis_result.get("risk_factors", [])
        ),
        detailed_reasoning=DetailedReasoning(
            technical_analysis=detailed_reasoning.get("technical_analysis", ""),
            fundamental_analysis=detailed_reasoning.get("fundamental_analysis", ""),
            sentiment_analysis=detailed_reasoning.get("sentiment_analysis", ""),
            risk_assessment=detailed_reasoning.get("risk_assessment", "")
        ),
        model_info=ModelInfo(
            model_name=model_name,
            tokens_used=tokens_used,
            response_time_ms=response_time_ms,
            cost_usd=cost_usd
        )
    )


# ============================================================================
# Example Usage
# ============================================================================

if __name__ == "__main__":
    # ì €ì¥ì†Œ ì´ˆê¸°í™”
    repo = AIReviewRepository()
    
    # ìƒ˜í”Œ ë ˆì½”ë“œ ìƒì„±
    sample_record = create_ai_review_record(
        ticker="AAPL",
        analysis_result={
            "action": "BUY",
            "conviction": 0.85,
            "reasoning": "Appleì˜ ê°•ë ¥í•œ ì‹¤ì ê³¼ AI í†µí•© ì „ëµì´ ì£¼ê°€ ìƒìŠ¹ì„ ì´ëŒ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. iPhone 16 ì‚¬ì´í´ì´ ì˜ˆìƒë³´ë‹¤ ê°•í•˜ê³ , ì„œë¹„ìŠ¤ ë¶€ë¬¸ ì„±ì¥ì´ ì§€ì†ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "target_price": 235.0,
            "stop_loss": 195.0,
            "position_size": 0.08,
            "risk_factors": ["ì¤‘êµ­ ì‹œì¥ ë¶ˆí™•ì‹¤ì„±", "AI ê²½ìŸ ì‹¬í™”", "ê·œì œ ë¦¬ìŠ¤í¬"]
        },
        detailed_reasoning={
            "technical_analysis": "RSI 65ë¡œ ê³¼ë§¤ìˆ˜ ì§ì „, 20ì¼ ì´í‰ì„  ìœ„ì—ì„œ ê°•ì„¸ ìœ ì§€. ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ ê·¼ì²˜ë¡œ ë‹¨ê¸° ì¡°ì • ê°€ëŠ¥ì„± ìˆìœ¼ë‚˜ ì¤‘ê¸° ìƒìŠ¹ ì¶”ì„¸ ìœ íš¨.",
            "fundamental_analysis": "P/E 32.5ë°°ë¡œ ì—­ì‚¬ì  í‰ê· ë³´ë‹¤ ë†’ì§€ë§Œ, EPS ì„±ì¥ë¥  15%ë¥¼ ê³ ë ¤í•˜ë©´ í•©ë¦¬ì . ìˆœí˜„ê¸ˆ ë³´ìœ ê³  $60B, ìì‚¬ì£¼ ë§¤ì… ì§€ì†.",
            "sentiment_analysis": "ê¸°ê´€ íˆ¬ììë“¤ì˜ ë§¤ìˆ˜ì„¸ ì§€ì†. ì• ë„ë¦¬ìŠ¤íŠ¸ ëª©í‘œê°€ í‰ê·  $240. SNS ê°ì„± ê¸ì •ì  75%.",
            "risk_assessment": "ì¤‘êµ­ ë§¤ì¶œ ì˜ì¡´ë„ 20%ê°€ ì§€ì •í•™ì  ë¦¬ìŠ¤í¬. AI PC ì „í™˜ ì§€ì—° ì‹œ ì„±ì¥ ë‘”í™” ê°€ëŠ¥. ë°˜ë…ì  ê·œì œ ê°•í™” ì£¼ì‹œ í•„ìš”."
        },
        model_name="claude-3-5-haiku-latest",
        tokens_used=2500,
        response_time_ms=1234,
        cost_usd=0.0025
    )
    
    # ì €ì¥
    analysis_id = repo.save(sample_record)
    print(f"âœ… Saved: {analysis_id}")
    
    # ì¡°íšŒ
    loaded = repo.get(analysis_id)
    print(f"ğŸ“„ Loaded: {loaded.ticker} - {loaded.analysis.action}")
    
    # ëª©ë¡ ì¡°íšŒ
    all_reviews = repo.list_all(limit=10)
    print(f"ğŸ“Š Total reviews: {all_reviews['total_count']}")
    print(f"ğŸ“ˆ Today: {all_reviews['today_count']}")
    print(f"ğŸ¯ Avg Conviction: {all_reviews['avg_conviction']:.1%}")
    
    # í†µê³„
    stats = repo.get_statistics()
    print(f"\nğŸ“Š Statistics:")
    print(f"  Total: {stats['total']}")
    print(f"  By Action: {stats['by_action']}")
    print(f"  Changed Rate: {stats['changed_rate']:.1%}")
