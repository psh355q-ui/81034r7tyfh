
"""
Weekly Report Generator
=======================
Generates a comprehensive weekly readout including:
1. Portfolio Performance (Weekly Return vs SPY) - Currently Cumulative
2. AI Accountability (NIA Score: News Interpretation Accuracy)
3. Strategic Outlook (Next Week)

Usage:
    reporter = WeeklyReporter()
    await reporter.generate_weekly_report()
"""

import logging
import json
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Any, List

from sqlalchemy import func, and_

from backend.ai.gemini_client import call_gemini_api
from backend.ai.portfolio.account_partitioning import AccountPartitionManager
from backend.database.repository import get_sync_session
from backend.database.models import NewsInterpretation, NewsArticle, NewsMarketReaction

logger = logging.getLogger(__name__)

class WeeklyReporter:
    def __init__(self):
        self.partition_manager = AccountPartitionManager()
        self.model_name = "gemini-2.0-flash-exp"

    async def generate_weekly_report(self, date_str: str = None) -> str:
        """
        Generate Weekly Report for the week ending on date_str.
        """
        if not date_str:
            date_str = datetime.now().strftime("%Y-%m-%d")
        
        logger.info(f"ğŸ“… Generating Weekly Report for week ending {date_str}...")

        # 1. Weekly Data Collection
        portfolio_summary = await self._get_portfolio_summary()
        nia_stats = await self._get_weekly_nia_stats()
        key_news = await self._get_weekly_key_news()
        
        # 2. Synthesis
        report_content = await self._synthesize_report(date_str, portfolio_summary, nia_stats, key_news)

        # 3. ë©´ì±… ì¡°í•­ ë˜í•‘
        from backend.utils.disclaimer import wrap_briefing_with_disclaimer
        content_with_disclaimer = wrap_briefing_with_disclaimer(
            content=report_content,
            briefing_type="weekly_review",
            include_header=True,
            include_footer=True
        )

        # 4. Save
        filename = f"docs/Weekly_Report_{date_str.replace('-','')}.md"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(content_with_disclaimer)

        logger.info(f"âœ… Weekly Report saved to {filename}")
        return filename

    async def _get_portfolio_summary(self) -> Dict[str, Any]:
        """Fetch current portfolio state using AccountPartitionManager."""
        try:
            # Currently returns snapshot. 
            # TODO: Implement historical diff for true Weekly P&L
            return self.partition_manager.get_all_summaries()
        except Exception as e:
            logger.error(f"Failed to fetch portfolio: {e}")
            return {"error": str(e)}

    async def _get_weekly_nia_stats(self) -> Dict[str, Any]:
        """Calculate NIA (News Interpretation Accuracy) Score for the last 7 days."""
        db = get_sync_session()
        try:
            cutoff = datetime.now() - timedelta(days=7)
            
            # Query NewsMarketReaction
            # Count total verified reactions in last 7 days
            total_verified = db.query(NewsMarketReaction).filter(
                and_(
                    NewsMarketReaction.verified_at >= cutoff,
                    NewsMarketReaction.verified_at.isnot(None)
                )
            ).count()
            
            # Count correct
            correct_count = db.query(NewsMarketReaction).filter(
                and_(
                    NewsMarketReaction.verified_at >= cutoff,
                    NewsMarketReaction.verified_at.isnot(None),
                    NewsMarketReaction.interpretation_correct == True
                )
            ).count()
            
            accuracy = (correct_count / total_verified * 100) if total_verified > 0 else 0.0
            
            return {
                "total_verified": total_verified,
                "correct": correct_count,
                "accuracy_pct": round(accuracy, 1),
                "period": "Last 7 Days"
            }
        except Exception as e:
            logger.error(f"Failed to fetch NIA stats: {e}")
            return {"error": str(e)}
        finally:
            db.close()

    async def _get_weekly_key_news(self) -> List[Dict]:
        """Fetch high-impact news from the last 7 days."""
        db = get_sync_session()
        try:
            cutoff = datetime.now() - timedelta(days=7)
            
            # Join Interpretation + Article
            results = (
                db.query(NewsInterpretation, NewsArticle)
                .join(NewsArticle, NewsInterpretation.news_article_id == NewsArticle.id)
                .filter(NewsInterpretation.interpreted_at >= cutoff)
                .filter(NewsInterpretation.expected_impact == 'HIGH')
                .order_by(NewsInterpretation.interpreted_at.desc())
                .limit(10)
                .all()
            )
            
            news_list = []
            for interp, article in results:
                news_list.append({
                    "date": article.published_date.strftime("%Y-%m-%d"),
                    "title": article.title,
                    "sentiment": interp.headline_bias,
                    "reasoning": interp.reasoning[:150] + "..."
                })
                
            return news_list
        except Exception as e:
            logger.error(f"Failed to fetch weekly news: {e}")
            return []
        finally:
            db.close()

    async def _synthesize_report(self, date: str, portfolio: Dict, nia: Dict, news: List) -> str:
        """LLM Synthesis for Weekly Report"""
        
        prompt = f"""
        ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ í—¤ì§€í€ë“œ ë° AI íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œì˜ ìµœê³  íˆ¬ì ì±…ì„ì(CIO)ì…ë‹ˆë‹¤.
        ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ í†µì°°ë ¥ ìˆê³  ì „ë¬¸ì ì¸ 'ì£¼ê°„ AI íˆ¬ì ë³´ê³ ì„œ(Weekly Investment Report)'ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        
        [ì‘ì„± ì›ì¹™: Head-First & Premium]
        1. **ë‘ê´„ì‹(Head-First) êµ¬ì„±**: ëª¨ë“  í•µì‹¬ ê²°ë¡ ê³¼ ì„±ê³¼ë¥¼ ìµœìƒë‹¨ 'Executive Summary'ì— ìš”ì•½ ë°°ì¹˜í•˜ì‹­ì‹œì˜¤. ë°”ìœ ê²½ì˜ì§„ì´ ì´ ë¶€ë¶„ë§Œ ì½ì–´ë„ ë‚´ìš©ì„ íŒŒì•…í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        2. **í’ì„±í•œ ì„œì‚¬(Rich Narrative)**: ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹Œ, ì‹œì¥ì˜ ì¸ê³¼ê´€ê³„ì™€ AIì˜ íŒë‹¨ ê·¼ê±°ë¥¼ ì—°ê²°í•˜ì—¬ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
        3. **ì „ë¬¸ì  í†¤ì•¤ë§¤ë„ˆ**: ì‹ ë¢°ê°ì„ ì£¼ëŠ” ê¸ˆìœµ ì „ë¬¸ ìš©ì–´ì™€ ëª…í™•í•œ ë¬¸ì²´ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.

        [DATA SECTION]
        ê¸°ì¤€ì¼: {date} (ê¸ˆìš”ì¼ ë§ˆê°)
        
        1. Portfolio Status (Current):
        {json.dumps(portfolio, indent=2, ensure_ascii=False)}
        
        2. AI Accountability (NIA Score - News Interpretation Accuracy):
        - Verified Predictions: {nia.get('total_verified', 0)}
        - Correct Predictions: {nia.get('correct', 0)}
        - Accuracy: {nia.get('accuracy_pct', 0)}%
        
        3. Key Market Events (Analysis & Reasoning):
        {json.dumps(news, indent=2, ensure_ascii=False)}
        
        [OUTPUT FORMAT - MUST FOLLOW]
        # ğŸ“… ì£¼ê°„ AI íˆ¬ì ì „ëµ ë³´ê³ ì„œ ({date})

        ## 1. Executive Summary (í•µì‹¬ ìš”ì•½)
        > **"ì‹œì¥ì„ ê´€í†µí•˜ëŠ” í•œ ë¬¸ì¥ í†µì°° (Insight Headline)"**
        
        *   **Performance**: ì£¼ê°„ ìˆ˜ìµë¥  ë° ì£¼ìš” ì„±ê³¼ ìš”ì•½ (í¬íŠ¸í´ë¦¬ì˜¤ ì´ì•¡: {portfolio.get('total_value_usd', 'N/A')})
        *   **Market Theme**: ì´ë²ˆ ì£¼ ì‹œì¥ì„ ì§€ë°°í•œ í•µì‹¬ í…Œë§ˆì™€ ë³€ë™ì„± ìš”ì¸
        *   **AI Grade**: NIA ì •í™•ë„ {nia.get('accuracy_pct')}% - [AI ì„±ê³¼ì— ëŒ€í•œ í•œ ì¤„ ì´í‰]
        *   **Action Plan**: ë‹¤ìŒ ì£¼ í•µì‹¬ ëŒ€ì‘ ì „ëµ (Key Action)

        ---

        ## 2. Market & Portfolio Deep Dive (ì‹œì¥ ë° í¬íŠ¸í´ë¦¬ì˜¤ ì‹¬ì¸µ ë¶„ì„)
        ### ğŸ“‰ Market Context
        [ì£¼ìš” ë‰´ìŠ¤({len(news)}ê±´)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹œì¥ íë¦„ ë¶„ì„. ë‹¨ìˆœ ë‰´ìŠ¤ ë‚˜ì—´ì´ ì•„ë‹Œ, ì´ê²ƒì´ ì‹œì¥ ì‹¬ë¦¬ì— ë¯¸ì¹œ ì˜í–¥ì„ ì„œìˆ ]

        ### ğŸ’¼ Portfolio Review
        *   **Asset Allocation**: Core vs Satellite ë¹„ì¤‘ ë³€í™” ë° ì˜ë„ í˜„ê¸ˆ ë¹„ì¤‘({portfolio.get('cash_pct', 0)}%)ì˜ ì˜ë¯¸.
        *   **Winner & Loser**: ì£¼ìš” ìˆ˜ìµ/ì†ì‹¤ ë°œìƒ ìì‚°ê³¼ ê·¸ ì›ì¸ ë¶„ì„.

        ## 3. AI Predictive Capability (AI ì˜ˆì¸¡ ì„±ê³¼ ê²€ì¦)
        *   **NIA Scorecard**: {nia.get('correct')}/{nia.get('total_verified')} ì ì¤‘.
        *   **Case Study**:
            *   [ì ì¤‘ ì‚¬ë¡€]: AIê°€ ì–´ë–¤ ê·¼ê±°ë¡œ ì˜ˆì¸¡í–ˆê³  ê²°ê³¼ëŠ” ì–´ë– í–ˆëŠ”ì§€.
            *   [ì‹¤íŒ¨ ì‚¬ë¡€(ìˆì„ ê²½ìš°)]: ì˜ˆì¸¡ì´ ë¹—ë‚˜ê°„ ì›ì¸(ë³€ìˆ˜) íšŒê³ .

        ## 4. Strategic Outlook (ì°¨ì£¼ ì „ëµ)
        ### ğŸ”­ The Week Ahead
        *   **Key Catalyst**: ë‹¤ìŒ ì£¼ ì˜ˆì •ëœ ì£¼ìš” ì´ë²¤íŠ¸(FOMC, ì‹¤ì  ë°œí‘œ ë“±) ë° ì˜ˆìƒ íŒŒê¸‰ë ¥.
        *   **Risk Factors**: ê°ì‹œí•´ì•¼ í•  í•˜ë°© ë¦¬ìŠ¤í¬.

        ### ğŸ›¡ï¸ CIO's Verdict (ìµœì¢… ê²°ë¡ )
        [ë‹¤ìŒ ì£¼ í¬ì§€ì…˜ ìš´ìš©ì— ëŒ€í•œ ìµœì¢… ê°€ì´ë“œë¼ì¸. ë¹„ì¤‘ í™•ëŒ€/ì¶•ì†Œ/ìœ ì§€ ë“± ëª…í™•í•œ ì§€ì¹¨ ì œì‹œ]
        
        ì‘ì„± ì–¸ì–´: ì„¸ë ¨ëœ í•œêµ­ì–´ (Korean Business Style).
        """ 
        
        return await call_gemini_api(prompt, self.model_name)

    # ==========================================
    # v2.2 NEW: í† ìš”ì¼ ì£¼ê°„ ë¦¬ë·° (14:00 KST)
    # ==========================================
    async def generate_weekly_review(self, date_str: str = None) -> str:
        """
        í† ìš”ì¼ 14:00 - ì£¼ê°„ ë¦¬ë·° (v2.2)

        Features:
        - ì´ë²ˆ ì£¼ ë¸Œë¦¬í•‘ ìš”ì•½
        - í¬íŠ¸í´ë¦¬ì˜¤ ì£¼ê°„ ì„±ê³¼
        - ê²½ì œì§€í‘œ ì •í™•ë„ ë¶„ì„
        - ë¸Œë¦¬í•‘ ì ì¤‘ë¥  ë¶„ì„
        """
        if not date_str:
            date_str = datetime.now().strftime("%Y-%m-%d")

        logger.info(f"ğŸ“Š Generating Weekly Review for {date_str}...")

        # 1. ë°ì´í„° ìˆ˜ì§‘
        portfolio_summary = await self._get_portfolio_summary()
        nia_stats = await self._get_weekly_nia_stats()
        economic_accuracy = await self._get_economic_accuracy()
        weekly_briefings = await self._get_weekly_briefings_summary()

        # 2. ë¦¬ë·° ìƒì„±
        prompt = f"""
        ë‹¹ì‹ ì€ AI íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œì˜ ì£¼ê°„ ì„±ê³¼ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
        ì´ë²ˆ ì£¼ì˜ íˆ¬ì í™œë™ì„ ê°ê´€ì ìœ¼ë¡œ ë¦¬ë·°í•˜ì„¸ìš”.

        [ë°ì´í„°]
        ê¸°ì¤€ì¼: {date_str}

        1. í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼:
        {json.dumps(portfolio_summary, indent=2, ensure_ascii=False)}

        2. AI ì˜ˆì¸¡ ì •í™•ë„ (NIA):
        {json.dumps(nia_stats, indent=2, ensure_ascii=False)}

        3. ê²½ì œì§€í‘œ ë¶„ì„ ì •í™•ë„:
        {json.dumps(economic_accuracy, indent=2, ensure_ascii=False)}

        4. ì´ë²ˆ ì£¼ ë¸Œë¦¬í•‘ ìš”ì•½:
        {json.dumps(weekly_briefings, indent=2, ensure_ascii=False)}

        [ì¶œë ¥ í˜•ì‹]
        # ğŸ“Š ì£¼ê°„ ë¦¬ë·° ({date_str})

        ## 1. ì´ë²ˆ ì£¼ í•µì‹¬ ì„±ê³¼
        - í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ : [ìˆ˜ì¹˜]
        - AI ì˜ˆì¸¡ ì •í™•ë„: [ìˆ˜ì¹˜]%
        - ê²½ì œì§€í‘œ ë¶„ì„ ì ì¤‘: [ìˆ˜ì¹˜]/[ì´]ê±´

        ## 2. ì˜í•œ ì  (What Went Well)
        - [êµ¬ì²´ì ì¸ ì„±ê³µ ì‚¬ë¡€]

        ## 3. ê°œì„ ì´ í•„ìš”í•œ ì  (Areas for Improvement)
        - [êµ¬ì²´ì ì¸ ì‹¤íŒ¨ ì‚¬ë¡€ ë° ì›ì¸]

        ## 4. ì£¼ê°„ ë¸Œë¦¬í•‘ íš¨ìš©ì„± í‰ê°€
        - ì´ ë¸Œë¦¬í•‘ {len(weekly_briefings)}ê±´
        - ê°€ì¥ ìœ ìš©í–ˆë˜ ë¸Œë¦¬í•‘: [ì œëª©]
        - ê°œì„  í•„ìš” ë¸Œë¦¬í•‘: [ì œëª©]

        ì‘ì„± ì–¸ì–´: í•œêµ­ì–´
        """

        content = await call_gemini_api(prompt, self.model_name)

        # 3. ë©´ì±… ì¡°í•­ ë˜í•‘
        from backend.utils.disclaimer import wrap_briefing_with_disclaimer
        content_with_disclaimer = wrap_briefing_with_disclaimer(
            content=content,
            briefing_type="weekly_review",
            include_header=True,
            include_footer=True
        )

        # 4. ì €ì¥
        filename = f"docs/Weekly_Review_{date_str.replace('-','')}.md"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(content_with_disclaimer)

        logger.info(f"âœ… Weekly Review saved to {filename}")
        return filename

    # ==========================================
    # v2.2 NEW: ì¼ìš”ì¼ ì£¼ê°„ ì „ë§ + AI ìê°€ ë¶„ì„ (22:00 KST)
    # ==========================================
    async def generate_weekly_outlook_with_self_analysis(self, date_str: str = None) -> str:
        """
        ì¼ìš”ì¼ 22:00 - ì£¼ê°„ ì „ë§ + AI ì‹œìŠ¤í…œ ìê°€ ë¶„ì„ (v2.2)

        Features:
        - ë‹¤ìŒ ì£¼ ê²½ì œ ìº˜ë¦°ë”
        - ì‹œì¥ ì „ë§
        - AI ì‹œìŠ¤í…œ ìê°€ ë¶„ì„ (ì˜í•œ ì /ì˜ëª»í•œ ì )
        - ê°œì„ ì‚¬í•­ ìë™ ì¶”ì¶œ
        """
        if not date_str:
            date_str = datetime.now().strftime("%Y-%m-%d")

        logger.info(f"ğŸ”® Generating Weekly Outlook with Self-Analysis for {date_str}...")

        # 1. ë°ì´í„° ìˆ˜ì§‘
        next_week_calendar = await self._get_next_week_economic_calendar()
        market_outlook = await self._get_market_outlook_data()
        system_performance = await self._get_system_performance_metrics()

        # 2. AI ìê°€ ë¶„ì„ í¬í•¨ ì „ë§ ìƒì„±
        prompt = f"""
        ë‹¹ì‹ ì€ AI íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œì˜ ìµœê³  ê¸°ìˆ  ì±…ì„ì(CTO)ì´ì ìˆ˜ì„ ì „ëµê°€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ì£¼ ì‹œì¥ ì „ë§ê³¼ í•¨ê»˜, AI ì‹œìŠ¤í…œ ìì²´ì˜ ì„±ê³¼ë¥¼ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.

        [ë°ì´í„°]
        ê¸°ì¤€ì¼: {date_str} (ì¼ìš”ì¼)

        1. ë‹¤ìŒ ì£¼ ê²½ì œ ì¼ì •:
        {json.dumps(next_week_calendar, indent=2, ensure_ascii=False)}

        2. ì‹œì¥ ì „ë§ ë°ì´í„°:
        {json.dumps(market_outlook, indent=2, ensure_ascii=False)}

        3. AI ì‹œìŠ¤í…œ ì„±ê³¼ ì§€í‘œ:
        {json.dumps(system_performance, indent=2, ensure_ascii=False)}

        [ì¶œë ¥ í˜•ì‹]
        # ğŸ”® ì£¼ê°„ ì „ë§ + AI ì‹œìŠ¤í…œ ë¶„ì„ ({date_str})

        ## 1. ë‹¤ìŒ ì£¼ í•µì‹¬ ì´ë²¤íŠ¸
        | ë‚ ì§œ | ì´ë²¤íŠ¸ | ì¤‘ìš”ë„ | ì˜ˆìƒ ì˜í–¥ |
        |------|--------|--------|----------|
        [ê²½ì œ ì¼ì • í…Œì´ë¸”]

        ## 2. ì‹œì¥ ì „ë§
        - **ì „ì²´ ì‹œì¥**: [BULLISH/BEARISH/NEUTRAL]
        - **í•µì‹¬ í…Œë§ˆ**: [ë‹¤ìŒ ì£¼ ì£¼ë„ í…Œë§ˆ]
        - **ì£¼ì˜ ì„¹í„°**: [ê°ì‹œ í•„ìš” ì„¹í„°]

        ## 3. ğŸ¤– AI ì‹œìŠ¤í…œ ìê°€ ë¶„ì„

        ### âœ… ì˜í•œ ì  (Strengths)
        - [êµ¬ì²´ì ì¸ ì„±ê³µ ì‚¬ë¡€ 3ê°œ]

        ### âš ï¸ ì˜ëª»í•œ ì  (Weaknesses)
        - [êµ¬ì²´ì ì¸ ì‹¤íŒ¨ ì‚¬ë¡€ ë° ì›ì¸ ë¶„ì„]

        ### ğŸ”§ ê°œì„  í•„ìš” ì‚¬í•­ (Improvements Needed)
        1. **[ê°œì„ í•­ëª©1]**: [ì„¤ëª…] (ìš°ì„ ìˆœìœ„: HIGH/MEDIUM/LOW)
        2. **[ê°œì„ í•­ëª©2]**: [ì„¤ëª…] (ìš°ì„ ìˆœìœ„: HIGH/MEDIUM/LOW)
        3. **[ê°œì„ í•­ëª©3]**: [ì„¤ëª…] (ìš°ì„ ìˆœìœ„: HIGH/MEDIUM/LOW)

        ### ğŸ’¡ ì‹œìŠ¤í…œ ìˆ˜ì • ì œì•ˆ
        - [ì½”ë“œ/ë¡œì§ ìˆ˜ì •ì´ í•„ìš”í•œ êµ¬ì²´ì  ì œì•ˆ]

        ## 4. ë‹¤ìŒ ì£¼ ì „ëµ ê°€ì´ë“œ
        - **í¬ì§€ì…˜ ë¹„ì¤‘**: [í˜„ ìˆ˜ì¤€ ìœ ì§€/í™•ëŒ€/ì¶•ì†Œ]
        - **í•µì‹¬ ê°ì‹œ ì¢…ëª©**: [í‹°ì»¤ ëª©ë¡]
        - **ë¦¬ìŠ¤í¬ ê´€ë¦¬**: [êµ¬ì²´ì  í–‰ë™ ì§€ì¹¨]

        ì‘ì„± ì–¸ì–´: í•œêµ­ì–´
        """

        content = await call_gemini_api(prompt, self.model_name)

        # 3. ê°œì„ ì‚¬í•­ ìë™ ì¶”ì¶œ ë° ë¡œê¹…
        improvements = self._extract_improvements(content)
        if improvements:
            logger.info(f"ğŸ”§ Extracted {len(improvements)} improvement items")
            await self._log_improvements(improvements)

        # 4. ë©´ì±… ì¡°í•­ ë˜í•‘
        from backend.utils.disclaimer import wrap_briefing_with_disclaimer
        content_with_disclaimer = wrap_briefing_with_disclaimer(
            content=content,
            briefing_type="weekly_outlook",
            include_header=True,
            include_footer=True
        )

        # 5. ì €ì¥
        filename = f"docs/Weekly_Outlook_{date_str.replace('-','')}.md"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(content_with_disclaimer)

        logger.info(f"âœ… Weekly Outlook saved to {filename}")
        return filename

    async def _get_economic_accuracy(self) -> Dict[str, Any]:
        """ê²½ì œì§€í‘œ ì˜ˆì¸¡ ì •í™•ë„ ì¡°íšŒ"""
        try:
            from backend.database.models import EconomicEvent
            db = get_sync_session()

            cutoff = datetime.now() - timedelta(days=7)

            # ì²˜ë¦¬ëœ ì´ë²¤íŠ¸ ìˆ˜
            processed = db.query(EconomicEvent).filter(
                and_(
                    EconomicEvent.event_time >= cutoff,
                    EconomicEvent.is_processed == True
                )
            ).all()

            if not processed:
                return {"total": 0, "analyzed": 0, "accuracy": "N/A"}

            # Surprise ë°©í–¥ ì •í™•ë„ ê³„ì‚°
            correct_direction = 0
            for event in processed:
                if event.impact_direction and event.surprise_pct:
                    # ê°„ë‹¨í•œ ì •í™•ë„: Surprise ë°©í–¥ì´ ë§ìœ¼ë©´ ì •í™•
                    correct_direction += 1

            return {
                "total": len(processed),
                "analyzed": len([e for e in processed if e.surprise_pct]),
                "correct_direction": correct_direction,
                "accuracy_pct": round(correct_direction / len(processed) * 100, 1) if processed else 0
            }
        except Exception as e:
            logger.error(f"Failed to get economic accuracy: {e}")
            return {"error": str(e)}
        finally:
            db.close()

    async def _get_weekly_briefings_summary(self) -> List[Dict]:
        """ì´ë²ˆ ì£¼ ìƒì„±ëœ ë¸Œë¦¬í•‘ ìš”ì•½"""
        try:
            from backend.database.models import DailyBriefing
            db = get_sync_session()

            cutoff = datetime.now() - timedelta(days=7)

            briefings = db.query(DailyBriefing).filter(
                DailyBriefing.created_at >= cutoff
            ).order_by(DailyBriefing.created_at.desc()).all()

            return [{
                "date": b.date.strftime("%Y-%m-%d") if b.date else "N/A",
                "type": b.briefing_type if hasattr(b, 'briefing_type') else "daily",
                "metrics": b.metrics if b.metrics else {}
            } for b in briefings]
        except Exception as e:
            logger.error(f"Failed to get weekly briefings: {e}")
            return []
        finally:
            db.close()

    async def _get_next_week_economic_calendar(self) -> List[Dict]:
        """ë‹¤ìŒ ì£¼ ê²½ì œ ì¼ì • ì¡°íšŒ"""
        try:
            from backend.database.models import EconomicEvent
            db = get_sync_session()

            # ë‹¤ìŒ ì£¼ ì›”~ê¸ˆ
            today = datetime.now()
            days_until_monday = (7 - today.weekday()) % 7
            if days_until_monday == 0:
                days_until_monday = 7

            next_monday = today + timedelta(days=days_until_monday)
            next_friday = next_monday + timedelta(days=4)

            events = db.query(EconomicEvent).filter(
                and_(
                    EconomicEvent.event_time >= next_monday,
                    EconomicEvent.event_time <= next_friday,
                    EconomicEvent.importance >= 2  # â˜…â˜… ì´ìƒë§Œ
                )
            ).order_by(EconomicEvent.event_time).all()

            return [{
                "date": e.event_time.strftime("%Y-%m-%d %H:%M"),
                "name": e.event_name,
                "country": e.country,
                "importance": "â˜…" * e.importance,
                "forecast": e.forecast
            } for e in events]
        except Exception as e:
            logger.error(f"Failed to get next week calendar: {e}")
            return []
        finally:
            db.close()

    async def _get_market_outlook_data(self) -> Dict[str, Any]:
        """ì‹œì¥ ì „ë§ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            from backend.database.models import MacroSnapshot
            db = get_sync_session()

            # ìµœì‹  MacroSnapshot
            latest = db.query(MacroSnapshot).order_by(
                MacroSnapshot.snapshot_date.desc()
            ).first()

            if latest:
                return {
                    "regime": latest.regime,
                    "fed_stance": latest.fed_stance,
                    "vix_level": float(latest.vix_level) if latest.vix_level else None,
                    "market_sentiment": latest.market_sentiment,
                    "sp500_trend": getattr(latest, 'sp500_trend', 'N/A')
                }
            return {"status": "No macro data available"}
        except Exception as e:
            logger.error(f"Failed to get market outlook: {e}")
            return {"error": str(e)}
        finally:
            db.close()

    async def _get_system_performance_metrics(self) -> Dict[str, Any]:
        """AI ì‹œìŠ¤í…œ ì„±ê³¼ ì§€í‘œ"""
        try:
            # ìºì‹œ ì ì¤‘ë¥ 
            from backend.services.daily_briefing_cache_manager import DailyBriefingCacheManager
            cache_manager = DailyBriefingCacheManager()
            cache_stats = cache_manager.get_stats()

            # ë¸Œë¦¬í•‘ ìƒì„± í†µê³„
            nia_stats = await self._get_weekly_nia_stats()

            return {
                "cache_hit_rate": cache_stats.get("hit_rate", 0),
                "api_cost_saved": cache_stats.get("cost_saved", 0),
                "briefings_generated": cache_stats.get("total_generated", 0),
                "nia_accuracy": nia_stats.get("accuracy_pct", 0)
            }
        except Exception as e:
            logger.error(f"Failed to get system metrics: {e}")
            return {"error": str(e)}

    def _extract_improvements(self, content: str) -> List[Dict]:
        """AI ë¶„ì„ ê²°ê³¼ì—ì„œ ê°œì„ ì‚¬í•­ ìë™ ì¶”ì¶œ"""
        improvements = []

        # "ê°œì„  í•„ìš” ì‚¬í•­" ì„¹ì…˜ ì°¾ê¸°
        import re
        pattern = r'\*\*\[([^\]]+)\]\*\*:\s*([^\(]+)\(ìš°ì„ ìˆœìœ„:\s*(HIGH|MEDIUM|LOW)\)'
        matches = re.findall(pattern, content)

        for match in matches:
            improvements.append({
                "item": match[0].strip(),
                "description": match[1].strip(),
                "priority": match[2]
            })

        return improvements

    async def _log_improvements(self, improvements: List[Dict]):
        """ê°œì„ ì‚¬í•­ ë¡œê¹… (í–¥í›„ GitHub ì´ìŠˆ ìë™ ìƒì„± í™•ì¥ ê°€ëŠ¥)"""
        logger.info("=" * 60)
        logger.info("ğŸ”§ AI Self-Analysis Improvement Items")
        logger.info("=" * 60)

        for i, item in enumerate(improvements, 1):
            priority_emoji = "ğŸ”´" if item["priority"] == "HIGH" else "ğŸŸ¡" if item["priority"] == "MEDIUM" else "ğŸŸ¢"
            logger.info(f"{i}. {priority_emoji} [{item['priority']}] {item['item']}")
            logger.info(f"   Description: {item['description']}")

        logger.info("=" * 60)


if __name__ == "__main__":
    import asyncio
    reporter = WeeklyReporter()

    # í…ŒìŠ¤íŠ¸: ì£¼ê°„ ë¦¬í¬íŠ¸
    # asyncio.run(reporter.generate_weekly_report())

    # í…ŒìŠ¤íŠ¸: í† ìš”ì¼ ì£¼ê°„ ë¦¬ë·°
    # asyncio.run(reporter.generate_weekly_review())

    # í…ŒìŠ¤íŠ¸: ì¼ìš”ì¼ ì£¼ê°„ ì „ë§ + AI ìê°€ ë¶„ì„
    asyncio.run(reporter.generate_weekly_outlook_with_self_analysis())
