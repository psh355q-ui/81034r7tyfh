"""
Global Market Map - ê¸€ë¡œë²Œ ì‹œì¥ ìƒê´€ê´€ê³„ ê·¸ë˜í”„

Phase F2: ê¸€ë¡œë²Œ ë§¤í¬ë¡œ í™•ì¥

ìì‚°/ì„¹í„°/êµ­ê°€ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ì •ì˜í•˜ê³  ì´ë²¤íŠ¸ ì „íŒŒ ê²½ë¡œë¥¼ ì¶”ë¡ 

ì£¼ìš” ê¸°ëŠ¥:
- ìì‚° ê°„ ìƒê´€ê´€ê³„ ì •ì˜ (correlations)
- ì´ë²¤íŠ¸ ì˜í–¥ ê²½ë¡œ íƒìƒ‰ (BFS/DFS)
- ê¸€ë¡œë²Œ ë‚˜ë¹„íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜

ì‘ì„±ì¼: 2025-12-08
ì°¸ì¡°: 10_Ideas_Integration_Plan_v3.md
"""

from typing import Dict, List, Optional, Any, Set, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from collections import deque
import logging
import networkx as nx  # Added for graph support

logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ìì‚° ìœ í˜• ì •ì˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AssetType(str, Enum):
    """ìì‚° ìœ í˜•"""
    CURRENCY = "currency"      # í†µí™”
    BOND = "bond"              # ì±„ê¶Œ
    EQUITY = "equity"          # ì£¼ì‹
    COMMODITY = "commodity"    # ì›ìì¬
    INDEX = "index"            # ì§€ìˆ˜
    SECTOR = "sector"          # ì„¹í„°
    COUNTRY = "country"        # êµ­ê°€
    INDICATOR = "indicator"    # ê²½ì œì§€í‘œ


@dataclass
class MarketNode:
    """ì‹œì¥ ë…¸ë“œ (ìì‚°/ì„¹í„°/ì§€ìˆ˜)"""
    id: str
    name: str
    asset_type: AssetType
    country: Optional[str] = None  # US, JP, CN, EU, KR
    current_value: Optional[float] = None
    change_pct: Optional[float] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "name": self.name,
            "asset_type": self.asset_type.value,
            "country": self.country,
            "current_value": self.current_value,
            "change_pct": self.change_pct,
            "metadata": self.metadata
        }


@dataclass
class Correlation:
    """ìì‚° ê°„ ìƒê´€ê´€ê³„"""
    source: str
    target: str
    coefficient: float  # -1.0 ~ 1.0
    reason: str
    lag_days: int = 0  # ì§€ì—° íš¨ê³¼ (ì¼)
    confidence: float = 0.8
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "source": self.source,
            "target": self.target,
            "coefficient": self.coefficient,
            "reason": self.reason,
            "lag_days": self.lag_days,
            "confidence": self.confidence
        }


@dataclass
class ImpactPath:
    """ì´ë²¤íŠ¸ ì˜í–¥ ê²½ë¡œ"""
    path: List[str]  # ë…¸ë“œ ID ê²½ë¡œ
    total_impact: float  # ëˆ„ì  ì˜í–¥ë„
    reasons: List[str]  # ê° ë‹¨ê³„ ì´ìœ 
    confidence: float
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "path": self.path,
            "total_impact": self.total_impact,
            "reasons": self.reasons,
            "confidence": self.confidence
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Global Market Map í´ë˜ìŠ¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class GlobalMarketMap:
    """
    ê¸€ë¡œë²Œ ì‹œì¥ ìƒê´€ê´€ê³„ ê·¸ë˜í”„
    
    Usage:
        gmap = GlobalMarketMap()
        
        # ì´ë²¤íŠ¸ ì˜í–¥ ë¶„ì„
        paths = gmap.trace_impact("JPY_STRENGTH", -0.5)
        for path in paths:
            print(f"{' -> '.join(path.path)}: {path.total_impact:.2%}")
        
        # íŠ¹ì • ìì‚°ì— ì˜í–¥ì£¼ëŠ” ë…¸ë“œë“¤ ì¡°íšŒ
        sources = gmap.get_impact_sources("KOSPI")
    """
    
    def __init__(self):
        """ì´ˆê¸°í™” ë° ê¸°ë³¸ ìƒê´€ê´€ê³„ ì •ì˜"""
        self.nodes: Dict[str, MarketNode] = {}
        self.correlations: Dict[str, List[Correlation]] = {}  # source -> [correlations]
        self.reverse_correlations: Dict[str, List[Correlation]] = {}  # target -> [correlations]
        self.graph = nx.DiGraph()  # âœ… Added: NetworkX graph for advanced analysis
        
        # ê¸°ë³¸ ë…¸ë“œ ë° ìƒê´€ê´€ê³„ ì •ì˜
        self._setup_default_nodes()
        self._setup_default_correlations()
        
        logger.info(f"GlobalMarketMap initialized: {len(self.nodes)} nodes, {self._count_correlations()} correlations")
    
    def _setup_default_nodes(self):
        """ê¸°ë³¸ ì‹œì¥ ë…¸ë“œ ì„¤ì •"""
        default_nodes = [
            # í†µí™”
            MarketNode("USD_INDEX", "US Dollar Index", AssetType.CURRENCY, "US"),
            MarketNode("JPY_STRENGTH", "Japanese Yen Strength", AssetType.CURRENCY, "JP"),
            MarketNode("CNY_WEAKNESS", "Chinese Yuan Weakness", AssetType.CURRENCY, "CN"),
            MarketNode("EUR_INDEX", "Euro Index", AssetType.CURRENCY, "EU"),
            MarketNode("KRW_INDEX", "Korean Won Index", AssetType.CURRENCY, "KR"),
            
            # ê¸ˆë¦¬/ì±„ê¶Œ
            MarketNode("US_10Y", "US 10-Year Treasury", AssetType.BOND, "US"),
            MarketNode("US_2Y", "US 2-Year Treasury", AssetType.BOND, "US"),
            MarketNode("US_YIELD_CURVE", "US Yield Curve", AssetType.INDICATOR, "US"),
            MarketNode("BOJ_RATE", "BOJ Policy Rate", AssetType.INDICATOR, "JP"),
            MarketNode("ECB_RATE", "ECB Policy Rate", AssetType.INDICATOR, "EU"),
            MarketNode("FED_RATE", "Fed Funds Rate", AssetType.INDICATOR, "US"),
            
            # ì£¼ìš” ì§€ìˆ˜
            MarketNode("SPX", "S&P 500", AssetType.INDEX, "US"),
            MarketNode("NDX", "NASDAQ 100", AssetType.INDEX, "US"),
            MarketNode("VIX", "VIX Volatility", AssetType.INDEX, "US"),
            MarketNode("KOSPI", "KOSPI", AssetType.INDEX, "KR"),
            MarketNode("NIKKEI", "Nikkei 225", AssetType.INDEX, "JP"),
            MarketNode("CSI300", "CSI 300", AssetType.INDEX, "CN"),
            
            # ìœ ë™ì„±
            MarketNode("US_TECH_LIQUIDITY", "US Tech Liquidity", AssetType.INDICATOR, "US"),
            MarketNode("GLOBAL_RISK_APPETITE", "Global Risk Appetite", AssetType.INDICATOR, None),
            
            # ì›ìì¬
            MarketNode("CRUDE_OIL", "Crude Oil (WTI)", AssetType.COMMODITY, None),
            MarketNode("GOLD", "Gold", AssetType.COMMODITY, None),
            MarketNode("COPPER", "Copper", AssetType.COMMODITY, None),
            MarketNode("NATURAL_GAS", "Natural Gas", AssetType.COMMODITY, None),
            
            # ë°˜ë„ì²´
            MarketNode("SEMICONDUCTOR", "Semiconductor Sector", AssetType.SECTOR, "US"),
            MarketNode("AI_CHIPS", "AI Chip Demand", AssetType.SECTOR, None),
            MarketNode("HBM_DEMAND", "HBM Memory Demand", AssetType.SECTOR, "KR"),
            
            # ê¸°íƒ€ ì„¹í„°
            MarketNode("ENERGY_SECTOR", "Energy Sector", AssetType.SECTOR, "US"),
            MarketNode("AIRLINE_SECTOR", "Airline Sector", AssetType.SECTOR, None),
            MarketNode("TECH_SECTOR", "Tech Sector", AssetType.SECTOR, "US"),
            MarketNode("FINANCE_SECTOR", "Financial Sector", AssetType.SECTOR, "US"),
        ]
        
        for node in default_nodes:
            self.nodes[node.id] = node
    
    def _setup_default_correlations(self):
        """ê¸°ë³¸ ìƒê´€ê´€ê³„ ì„¤ì •"""
        default_correlations = [
            # ì—”í™” ê°•ì„¸ ì˜í–¥
            Correlation("JPY_STRENGTH", "US_TECH_LIQUIDITY", -0.8, "Yen carry trade unwind"),
            Correlation("JPY_STRENGTH", "NIKKEI", -0.6, "Export competitiveness decline"),
            Correlation("JPY_STRENGTH", "GLOBAL_RISK_APPETITE", -0.5, "Risk-off signal"),
            
            # ìœ ë™ì„± ì˜í–¥
            Correlation("US_TECH_LIQUIDITY", "NDX", 0.85, "Tech funding dependency"),
            Correlation("US_TECH_LIQUIDITY", "SEMICONDUCTOR", 0.75, "VC funding for chips"),
            Correlation("US_TECH_LIQUIDITY", "AI_CHIPS", 0.7, "AI investment liquidity"),
            
            # ìœ„í—˜ì„ í˜¸ë„ ì˜í–¥
            Correlation("GLOBAL_RISK_APPETITE", "SPX", 0.7, "Risk-on equity rally"),
            Correlation("GLOBAL_RISK_APPETITE", "KOSPI", 0.6, "EM risk sentiment"),
            Correlation("GLOBAL_RISK_APPETITE", "VIX", -0.85, "Fear gauge inverse"),
            Correlation("GLOBAL_RISK_APPETITE", "GOLD", -0.4, "Safe haven unwind"),
            
            # ë‹¬ëŸ¬ ì˜í–¥
            Correlation("USD_INDEX", "GOLD", -0.5, "Dollar-denominated assets"),
            Correlation("USD_INDEX", "CRUDE_OIL", -0.4, "Dollar-priced commodities"),
            Correlation("USD_INDEX", "KRW_INDEX", -0.6, "EM currency pressure"),
            
            # ê¸ˆë¦¬ ì˜í–¥
            Correlation("FED_RATE", "US_10Y", 0.7, "Monetary policy transmission"),
            Correlation("FED_RATE", "USD_INDEX", 0.5, "Interest rate differential"),
            Correlation("FED_RATE", "US_TECH_LIQUIDITY", -0.6, "Higher cost of capital"),
            Correlation("US_10Y", "TECH_SECTOR", -0.5, "DCF valuation impact"),
            Correlation("US_10Y", "FINANCE_SECTOR", 0.6, "NIM expansion"),
            
            # ì›ìœ  ì˜í–¥
            Correlation("CRUDE_OIL", "ENERGY_SECTOR", 0.9, "Revenue increase"),
            Correlation("CRUDE_OIL", "AIRLINE_SECTOR", -0.8, "Fuel cost surge"),
            Correlation("CRUDE_OIL", "NATURAL_GAS", 0.6, "Energy complex correlation"),
            
            # ë°˜ë„ì²´ ì²´ì¸
            Correlation("AI_CHIPS", "SEMICONDUCTOR", 0.8, "AI driving chip demand"),
            Correlation("AI_CHIPS", "HBM_DEMAND", 0.85, "HBM for AI accelerators"),
            Correlation("SEMICONDUCTOR", "KOSPI", 0.5, "Samsung/SK weight"),
            
            # ì¤‘êµ­ ì˜í–¥
            Correlation("CNY_WEAKNESS", "CSI300", -0.4, "Capital outflow fear"),
            Correlation("CNY_WEAKNESS", "COPPER", -0.5, "China demand proxy"),
            Correlation("CSI300", "KOSPI", 0.45, "Trade linkage"),
            
            # VIX ì˜í–¥
            Correlation("VIX", "SPX", -0.75, "Fear vs equity"),
            Correlation("VIX", "GOLD", 0.3, "Flight to safety"),
        ]
        
        for corr in default_correlations:
            self.add_correlation(corr)
    
    def add_node(self, node: MarketNode):
        """ë…¸ë“œ ì¶”ê°€"""
        self.nodes[node.id] = node
        logger.debug(f"Added node: {node.id}")
    
    def add_correlation(self, correlation: Correlation):
        """ìƒê´€ê´€ê³„ ì¶”ê°€"""
        source = correlation.source
        target = correlation.target
        
        if source not in self.correlations:
            self.correlations[source] = []
        self.correlations[source].append(correlation)
        
        if target not in self.reverse_correlations:
            self.reverse_correlations[target] = []
        self.reverse_correlations[target].append(correlation)
    
    def get_node(self, node_id: str) -> Optional[MarketNode]:
        """ë…¸ë“œ ì¡°íšŒ"""
        return self.nodes.get(node_id)
    
    def get_direct_impacts(self, source_id: str) -> List[Correlation]:
        """ì§ì ‘ ì˜í–¥ë°›ëŠ” ë…¸ë“œë“¤ ì¡°íšŒ"""
        return self.correlations.get(source_id, [])
    
    def get_impact_sources(self, target_id: str) -> List[Correlation]:
        """í•´ë‹¹ ë…¸ë“œì— ì˜í–¥ì£¼ëŠ” ì†ŒìŠ¤ë“¤ ì¡°íšŒ"""
        return self.reverse_correlations.get(target_id, [])
    
    def trace_impact(
        self,
        source_id: str,
        initial_shock: float,
        max_depth: int = 4,
        min_impact: float = 0.05
    ) -> List[ImpactPath]:
        """
        ì´ë²¤íŠ¸ ì˜í–¥ ê²½ë¡œ ì¶”ì  (BFS)
        
        Args:
            source_id: ì‹œì‘ ë…¸ë“œ ID
            initial_shock: ì´ˆê¸° ì¶©ê²© (-1.0 ~ 1.0)
            max_depth: ìµœëŒ€ íƒìƒ‰ ê¹Šì´
            min_impact: ìµœì†Œ ì˜í–¥ë„ (ì´ ì´í•˜ëŠ” ë¬´ì‹œ)
            
        Returns:
            ì˜í–¥ ê²½ë¡œ ëª©ë¡
        """
        if source_id not in self.nodes:
            logger.warning(f"Source node not found: {source_id}")
            return []
        
        impact_paths: List[ImpactPath] = []
        visited: Set[Tuple[str, ...]] = set()
        
        # BFS í: (path, cumulative_impact, reasons)
        queue = deque([(
            [source_id],
            initial_shock,
            ["Initial shock"],
            1.0  # confidence
        )])
        
        while queue:
            current_path, current_impact, reasons, confidence = queue.popleft()
            current_node = current_path[-1]
            
            if len(current_path) > max_depth:
                continue
            
            # ì§ì ‘ ì—°ê²°ëœ ë…¸ë“œë“¤ íƒìƒ‰
            for corr in self.get_direct_impacts(current_node):
                next_impact = current_impact * corr.coefficient
                next_confidence = confidence * corr.confidence
                
                # ì˜í–¥ë„ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ìŠ¤í‚µ
                if abs(next_impact) < min_impact:
                    continue
                
                # ìˆœí™˜ ë°©ì§€
                if corr.target in current_path:
                    continue
                
                new_path = current_path + [corr.target]
                path_tuple = tuple(new_path)
                
                if path_tuple in visited:
                    continue
                visited.add(path_tuple)
                
                new_reasons = reasons + [corr.reason]
                
                # ì˜í–¥ ê²½ë¡œ ì €ì¥
                impact_paths.append(ImpactPath(
                    path=new_path,
                    total_impact=next_impact,
                    reasons=new_reasons,
                    confidence=next_confidence
                ))
                
                # ë‹¤ìŒ íƒìƒ‰
                queue.append((new_path, next_impact, new_reasons, next_confidence))
        
        # ì˜í–¥ë„ ìˆœ ì •ë ¬
        impact_paths.sort(key=lambda x: abs(x.total_impact), reverse=True)
        
        return impact_paths
    
    def simulate_event(
        self,
        event_source: str,
        shock: float,
        description: str = ""
    ) -> Dict[str, Any]:
        """
        ì´ë²¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜
        
        Args:
            event_source: ì´ë²¤íŠ¸ ì‹œì‘ ë…¸ë“œ
            shock: ì¶©ê²© í¬ê¸° (-1.0 ~ 1.0)
            description: ì´ë²¤íŠ¸ ì„¤ëª…
            
        Returns:
            ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
        """
        logger.info(f"Simulating event: {event_source} shock={shock:.2f}")
        
        paths = self.trace_impact(event_source, shock)
        
        # ìµœì¢… ì˜í–¥ ì§‘ê³„
        final_impacts: Dict[str, float] = {}
        for path in paths:
            target = path.path[-1]
            if target not in final_impacts:
                final_impacts[target] = 0
            final_impacts[target] += path.total_impact * path.confidence
        
        # ê²°ê³¼ ì •ë¦¬
        sorted_impacts = sorted(
            final_impacts.items(),
            key=lambda x: abs(x[1]),
            reverse=True
        )
        
        result = {
            "event": {
                "source": event_source,
                "shock": shock,
                "description": description,
                "timestamp": datetime.now().isoformat()
            },
            "paths_count": len(paths),
            "affected_nodes": len(final_impacts),
            "top_impacts": [
                {
                    "node": node_id,
                    "impact": impact,
                    "direction": "positive" if impact > 0 else "negative"
                }
                for node_id, impact in sorted_impacts[:10]
            ],
            "detailed_paths": [p.to_dict() for p in paths[:20]]
        }
        
        return result
    
    def get_sector_signals(
        self,
        event_source: str,
        shock: float,
        threshold: float = 0.1
    ) -> Dict[str, str]:
        """
        ì„¹í„°ë³„ ë§¤ë§¤ ì‹œê·¸ë„ ìƒì„±
        
        Args:
            event_source: ì´ë²¤íŠ¸ ì†ŒìŠ¤
            shock: ì¶©ê²© í¬ê¸°
            threshold: ì‹œê·¸ë„ ì„ê³„ê°’
            
        Returns:
            ì„¹í„°ë³„ ì‹œê·¸ë„ (BUY, SELL, HOLD)
        """
        result = self.simulate_event(event_source, shock)
        signals = {}
        
        for item in result["top_impacts"]:
            node_id = item["node"]
            impact = item["impact"]
            node = self.get_node(node_id)
            
            if not node or node.asset_type not in [AssetType.SECTOR, AssetType.INDEX]:
                continue
            
            if impact > threshold:
                signals[node_id] = "BUY"
            elif impact < -threshold:
                signals[node_id] = "SELL"
            else:
                signals[node_id] = "HOLD"
        
        return signals
    
    def _count_correlations(self) -> int:
        """ìƒê´€ê´€ê³„ ìˆ˜ ì¹´ìš´íŠ¸"""
        return sum(len(corrs) for corrs in self.correlations.values())
    
    async def update_market_data(self):
        """
        ì‹¤ì œ ì‹œì¥ ë°ì´í„° ì—…ë°ì´íŠ¸ (Yahoo Finance)
        """
        try:
            import yfinance as yf
            
            # Key Market Indicators Mapping
            # Node ID: YFinance Ticker
            ticker_map = {
                "SPX": "^GSPC",
                "NDX": "^NDX",
                "VIX": "^VIX",
                "KOSPI": "^KS11",
                "NIKKEI": "^N225",
                "CSI300": "000300.SS",
                "USD_INDEX": "DX-Y.NYB",
                "US_10Y": "^TNX",
                "CRUDE_OIL": "CL=F",
                "GOLD": "GC=F",
                "COPPER": "HG=F",
                "NATURAL_GAS": "NG=F",
                "EUR_INDEX": "EURUSD=X",
                "KRW_INDEX": "KRW=X",
                "JPY_STRENGTH": "JPY=X" # Higher means weaker JPY vs USD usually, need to inverse for strength logic if needed
            }
            
            tickers = list(ticker_map.values())
            data = yf.Tickers(" ".join(tickers))
            
            updated_count = 0
            
            for node_id, ticker in ticker_map.items():
                try:
                    info = data.tickers[ticker].fast_info
                    price = info.last_price
                    prev_close = info.previous_close
                    
                    if price and prev_close:
                        change_pct = ((price - prev_close) / prev_close) # decimal format
                        
                        # Special handling for VIX (absolute change might be more relevant, but sticking to pct for consistency)
                        
                        # Update Node
                        if node_id in self.nodes:
                            self.nodes[node_id].current_value = price
                            self.nodes[node_id].change_pct = change_pct
                            self.nodes[node_id].metadata["last_updated"] = datetime.now().isoformat()
                            updated_count += 1
                            
                except Exception as e:
                    logger.debug(f"Failed to fetch {node_id} ({ticker}): {e}")
            
            logger.info(f"Updated {updated_count} market nodes with real data")
            return updated_count
            
        except ImportError:
            logger.warning("yfinance not installed, skipping real data update")
            return 0
        except Exception as e:
            logger.error(f"Market data update error: {e}")
            return 0

    def get_summary(self) -> Dict[str, Any]:
        """ë§µ ìš”ì•½"""
        return {
            "nodes": len(self.nodes),
            "correlations": self._count_correlations(),
            "node_types": {
                asset_type.value: sum(1 for n in self.nodes.values() if n.asset_type == asset_type)
                for asset_type in AssetType
            },
            "countries": list(set(
                n.country for n in self.nodes.values() if n.country
            ))
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Global Singleton
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_global_market_map: Optional[GlobalMarketMap] = None


def get_global_market_map() -> GlobalMarketMap:
    """GlobalMarketMap ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤"""
    global _global_market_map
    if _global_market_map is None:
        _global_market_map = GlobalMarketMap()
    return _global_market_map


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í…ŒìŠ¤íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    gmap = GlobalMarketMap()
    
    print("=== Global Market Map Test ===\n")
    print(f"Summary: {gmap.get_summary()}\n")
    
    # ì‹œë‚˜ë¦¬ì˜¤ 1: ì¼ë³¸ BOJ ê¸ˆë¦¬ ì¸ìƒ (ì—”í™” ê°•ì„¸)
    print("="*60)
    print("Scenario: BOJ Rate Hike -> JPY Strength")
    print("="*60)
    
    result = gmap.simulate_event(
        event_source="JPY_STRENGTH",
        shock=-0.5,  # 50% ê°•ì„¸
        description="BOJ surprises with rate hike"
    )
    
    print(f"\nAffected nodes: {result['affected_nodes']}")
    print(f"Total paths: {result['paths_count']}")
    print("\nTop Impacts:")
    for item in result["top_impacts"][:8]:
        direction = "ğŸ“ˆ" if item["impact"] > 0 else "ğŸ“‰"
        print(f"  {direction} {item['node']}: {item['impact']:.1%}")
    
    # ì‹œê·¸ë„ ìƒì„±
    print("\nSector Signals:")
    signals = gmap.get_sector_signals("JPY_STRENGTH", -0.5)
    for sector, signal in signals.items():
        print(f"  {sector}: {signal}")
    
    # ì‹œë‚˜ë¦¬ì˜¤ 2: ìœ ê°€ ê¸‰ë“±
    print("\n" + "="*60)
    print("Scenario: Oil Price Surge")
    print("="*60)
    
    signals = gmap.get_sector_signals("CRUDE_OIL", 0.3)
    for sector, signal in signals.items():
        print(f"  {sector}: {signal}")
