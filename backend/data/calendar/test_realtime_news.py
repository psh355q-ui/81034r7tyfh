"""
ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
23:30 ë°œìƒ ë‰´ìŠ¤ (6ë¶„ ì „) ìˆ˜ì§‘ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
"""
import asyncio
import sys
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

from backend.data.calendar.google_news_collector import GoogleNewsRSSCollector


async def test_realtime_news():
    print("=" * 70)
    print("  ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸")
    print("  ëŒ€ìƒ: 23:30 ASML/EUV ë‰´ìŠ¤ (ì•½ 6ë¶„ ì „)")
    print("=" * 70)
    print()
    
    collector = GoogleNewsRSSCollector()
    
    # ê²€ìƒ‰ í‚¤ì›Œë“œ ëª©ë¡
    queries = [
        "ASML EUV",
        "ASML ì¤‘êµ­",
        "ASML 2025",
        "EUV lithography",
        "ASML export",
    ]
    
    print(f"í˜„ì¬ ì‹œê°: {datetime.now().strftime('%H:%M:%S')}")
    print(f"ëª©í‘œ ì‹œê°: 23:30 (ì•½ 6ë¶„ ì „)")
    print()
    
    for query in queries:
        print(f"ğŸ” ê²€ìƒ‰: '{query}'")
        print("-" * 70)
        
        # ì§€ë‚œ 1ì‹œê°„ ë‚´ ë‰´ìŠ¤ ê²€ìƒ‰
        articles = await collector.search_news(query, hours_back=1)
        
        if articles:
            print(f"   âœ… Found {len(articles)} articles\n")
            
            for i, article in enumerate(articles[:5], 1):
                pub_time = article['published_at']
                minutes_ago = (datetime.now() - pub_time).total_seconds() / 60
                
                # 23:30 ê·¼ì²˜ ì²´í¬ (Â±10ë¶„)
                if 23 <= pub_time.hour <= 23 and 20 <= pub_time.minute <= 40:
                    marker = "â­ TARGET!"
                else:
                    marker = ""
                
                print(f"   {i}. {marker} {article['title'][:60]}...")
                print(f"      â”œâ”€ Source: {article['source']}")
                print(f"      â”œâ”€ Time: {pub_time.strftime('%H:%M')} ({int(minutes_ago)}ë¶„ ì „)")
                print(f"      â””â”€ Link: {article['link'][:50]}...")
                print()
        else:
            print(f"   âŒ No articles found\n")
    
    # í•œêµ­ ë‰´ìŠ¤ ê²€ìƒ‰ (ì´ë¯¸ì§€ê°€ í•œêµ­ì–´)
    print("=" * 70)
    print("  í•œêµ­ ë‰´ìŠ¤ ì†ŒìŠ¤ ê²€ìƒ‰")
    print("=" * 70)
    print()
    
    korean_queries = [
        "ASML",
        "ë°˜ë„ì²´ ì¥ë¹„",
        "EUV",
    ]
    
    for query in korean_queries:
        # í•œê¸€ ê²€ìƒ‰ (hl=ko)
        url = f"https://news.google.com/rss/search?q={query}&hl=ko&gl=KR&ceid=KR:ko"
        
        print(f"ğŸ” í•œêµ­ì–´ ê²€ìƒ‰: '{query}'")
        
        try:
            import aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.get(url) as resp:
                    if resp.status == 200:
                        from xml.etree import ElementTree as ET
                        xml = await resp.text()
                        root = ET.fromstring(xml)
                        items = root.findall('.//item')
                        
                        print(f"   âœ… Found {len(items)} articles")
                        
                        for i, item in enumerate(items[:3], 1):
                            title = item.find('title').text if item.find('title') is not None else ''
                            pub_date = item.find('pubDate').text if item.find('pubDate') is not None else ''
                            
                            print(f"   {i}. {title[:60]}...")
                            print(f"      â””â”€ {pub_date}")
                        print()
        except Exception as e:
            print(f"   âŒ Error: {e}\n")


if __name__ == "__main__":
    asyncio.run(test_realtime_news())
