"""
Forex Factoryì™€ Google Newsë¡œ ìœŒë¦¬ì—„ìŠ¤ ë°œì–¸ ê²€ìƒ‰
(NEWS API í‚¤ ë¶ˆí•„ìš”)
"""
import asyncio
import aiohttp
from bs4 import BeautifulSoup
from datetime import datetime


async def search_forex_factory():
    """Forex Factoryì—ì„œ Fed ì´ë²¤íŠ¸ ê²€ìƒ‰"""
    
    print("=" * 70)
    print("  Forex Factory - Fed ì´ë²¤íŠ¸ ê²€ìƒ‰")
    print("=" * 70)
    print()
    
    url = "https://www.forexfactory.com/calendar"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.get(url) as resp:
                if resp.status != 200:
                    print(f"âŒ Error: {resp.status}")
                    return
                
                html = await resp.text()
        
        soup = BeautifulSoup(html, 'html.parser')
        
        # ìº˜ë¦°ë” í–‰ ì°¾ê¸°
        rows = soup.find_all('tr', class_='calendar__row')
        
        print(f"ğŸ“Š Found {len(rows)} calendar events\n")
        
        fed_events = []
        for row in rows:
            # ì´ë²¤íŠ¸ ì œëª©
            title_elem = row.find('span', class_='calendar__event-title')
            if not title_elem:
                continue
            
            title = title_elem.text.strip()
            
            # Fed ê´€ë ¨ë§Œ
            if not any(keyword in title.lower() for keyword in ['fed', 'fomc', 'williams', 'powell', 'yellen']):
                continue
            
            # ì‹œê°„
            time_elem = row.find('td', class_='calendar__time')
            time_str = time_elem.text.strip() if time_elem else 'Unknown'
            
            # ì¤‘ìš”ë„
            impact_elem = row.find('span', class_='calendar__impact')
            impact_class = impact_elem.get('class', []) if impact_elem else []
            
            if 'high' in ' '.join(impact_class) or 'red' in ' '.join(impact_class):
                importance = "ğŸ”´ High"
            elif 'medium' in ' '.join(impact_class):
                importance = "ğŸŸ  Medium"
            else:
                importance = "ğŸŸ¡ Low"
            
            # ì‹¤ì œê°’ (ë°œí‘œëœ ê²½ìš°)
            actual_elem = row.find('span', class_='calendar__actual')
            actual = actual_elem.text.strip() if actual_elem and actual_elem.text.strip() else "â³ Pending"
            
            fed_events.append({
                'title': title,
                'time': time_str,
                'importance': importance,
                'actual': actual
            })
        
        if fed_events:
            print(f"âœ… Fed ê´€ë ¨ ì´ë²¤íŠ¸: {len(fed_events)}ê°œ\n")
            
            for i, event in enumerate(fed_events, 1):
                print(f"{i}. {event['title']}")
                print(f"   â”œâ”€ Time: {event['time']}")
                print(f"   â”œâ”€ Importance: {event['importance']}")
                print(f"   â””â”€ Status: {event['actual']}")
                print()
        else:
            print("âŒ No Fed events found today")
            print()
    
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()


async def search_google_news():
    """Google News RSSë¡œ Fed ë‰´ìŠ¤ ê²€ìƒ‰"""
    
    print("=" * 70)
    print("  Google News - Fed/Williams ê²€ìƒ‰")
    print("=" * 70)
    print()
    
    queries = [
        "Williams Federal Reserve",
        "Fed Williams speech",
        "John Williams NY Fed"
    ]
    
    for query in queries:
        print(f"ğŸ” ê²€ìƒ‰: '{query}'")
        print("-" * 70)
        
        try:
            # Google News RSS URL
            url = f"https://news.google.com/rss/search?q={query.replace(' ', '+')}&hl=en-US&gl=US&ceid=US:en"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url) as resp:
                    if resp.status != 200:
                        print(f"   âŒ Error: {resp.status}\n")
                        continue
                    
                    xml = await resp.text()
            
            # XML íŒŒì‹±
            from xml.etree import ElementTree as ET
            root = ET.fromstring(xml)
            
            items = root.findall('.//item')
            
            if items:
                print(f"   âœ… Found: {len(items)} articles\n")
                
                for i, item in enumerate(items[:5], 1):  # ìƒìœ„ 5ê°œë§Œ
                    title = item.find('title').text if item.find('title') is not None else 'No title'
                    link = item.find('link').text if item.find('link') is not None else ''
                    pub_date = item.find('pubDate').text if item.find('pubDate') is not None else ''
                    
                    print(f"   {i}. {title}")
                    print(f"      â”œâ”€ Published: {pub_date}")
                    print(f"      â””â”€ Link: {link[:60]}...")
                    print()
            else:
                print(f"   âŒ No articles found\n")
        
        except Exception as e:
            print(f"   âŒ Error: {e}\n")


async def main():
    print("\nğŸ” ìœŒë¦¬ì—„ìŠ¤ ë°œì–¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ë¬´ë£Œ ì†ŒìŠ¤)\n")
    
    # 1. Forex Factory
    await search_forex_factory()
    
    # 2. Google News
    await search_google_news()
    
    print("=" * 70)
    print("  ê²°ë¡ ")
    print("=" * 70)
    print()
    print("âœ… Forex Factory:")
    print("   - ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ (20ì´ˆ-1ë¶„)")
    print("   - Fed ì´ë²¤íŠ¸ ì¼ì •í‘œ ì œê³µ")
    print("   - ë¬´ë£Œ, ë¬´ì œí•œ")
    print()
    print("âœ… Google News RSS:")
    print("   - ë‰´ìŠ¤ ê¸°ì‚¬ ê²€ìƒ‰")
    print("   - 5-15ë¶„ ì§€ì—°")
    print("   - ë¬´ë£Œ, ë¬´ì œí•œ")
    print()
    print("ğŸ’¡ ê¶Œì¥ ì¡°í•©:")
    print("   1. Forex Factory - ë°œí‘œ ì‹œê° ì¶”ì  (ê°€ì¥ ë¹ ë¦„)")
    print("   2. Google News - ë°œì–¸ ë‚´ìš© ìƒì„¸")
    print("   3. Twitter API - ì‹¤ì‹œê°„ ë°˜ì‘ (ì˜µì…˜)")


if __name__ == "__main__":
    asyncio.run(main())
