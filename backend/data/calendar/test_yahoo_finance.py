"""
Yahoo Finance ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
RSS + ì§ì ‘ ìŠ¤í¬ë˜í•‘
"""
import asyncio
import aiohttp
from bs4 import BeautifulSoup
from datetime import datetime
from xml.etree import ElementTree as ET


async def test_yahoo_finance_rss():
    """Yahoo Finance RSS í…ŒìŠ¤íŠ¸"""
    print("=" * 70)
    print("  1. Yahoo Finance RSS Feed")
    print("=" * 70)
    print()
    
    # Yahoo Finance RSS URL
    rss_url = "https://finance.yahoo.com/news/rss"
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(rss_url) as resp:
                print(f"Status: {resp.status}")
                
                if resp.status != 200:
                    print("âŒ Failed to access RSS")
                    return
                
                xml = await resp.text()
        
        # XML íŒŒì‹±
        root = ET.fromstring(xml)
        items = root.findall('.//item')
        
        print(f"âœ… Found {len(items)} articles in RSS\n")
        
        for i, item in enumerate(items[:10], 1):
            title_elem = item.find('title')
            link_elem = item.find('link')
            pub_date_elem = item.find('pubDate')
            
            title = title_elem.text if title_elem is not None else ''
            link = link_elem.text if link_elem is not None else ''
            pub_date = pub_date_elem.text if pub_date_elem is not None else ''
            
            # ASML, EUV, China ì²´í¬
            if any(keyword in title.upper() for keyword in ['ASML', 'EUV', 'CHINA', 'SEMICONDUCTOR']):
                marker = "â­ "
            else:
                marker = "   "
            
            print(f"{marker}{i}. {title[:60]}...")
            print(f"       â””â”€ {pub_date}")
            print(f"       â””â”€ {link[:50]}...")
            print()
    
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()


async def test_yahoo_finance_article():
    """Yahoo Finance ì§ì ‘ ê¸°ì‚¬ ì ‘ê·¼ í…ŒìŠ¤íŠ¸"""
    print("=" * 70)
    print("  2. Yahoo Finance ì§ì ‘ ê¸°ì‚¬ ì ‘ê·¼")
    print("=" * 70)
    print()
    
    # ì‚¬ìš©ìê°€ ì œê³µí•œ URL
    article_url = "https://finance.yahoo.com/news/exclusive-china-built-manhattan-project-141758929.html"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.get(article_url) as resp:
                print(f"Status: {resp.status}")
                
                if resp.status != 200:
                    print("âŒ Failed to access article")
                    return
                
                html = await resp.text()
        
        soup = BeautifulSoup(html, 'html.parser')
        
        # ì œëª© ì¶”ì¶œ
        title = soup.find('h1')
        if title:
            print(f"\nâœ… Article Title:")
            print(f"   {title.get_text(strip=True)}\n")
        
        # ë°œí–‰ ì‹œê°„ ì¶”ì¶œ
        time_elem = soup.find('time')
        if time_elem:
            print(f"ğŸ“… Published:")
            print(f"   {time_elem.get_text(strip=True)}")
            print(f"   DateTime: {time_elem.get('datetime', 'N/A')}\n")
        
        # ë³¸ë¬¸ ì¼ë¶€ ì¶”ì¶œ
        article_body = soup.find('div', class_='caas-body')
        if not article_body:
            article_body = soup.find('article')
        
        if article_body:
            paragraphs = article_body.find_all('p')[:3]
            print(f"ğŸ“° Content Preview:")
            for p in paragraphs:
                text = p.get_text(strip=True)
                if text and len(text) > 20:
                    print(f"   {text[:100]}...")
            print()
        
        print("âœ… Yahoo Finance ê¸°ì‚¬ ì ‘ê·¼ ì„±ê³µ!")
        print("   - ì œëª©, ì‹œê°„, ë³¸ë¬¸ ëª¨ë‘ ì¶”ì¶œ ê°€ëŠ¥")
        print("   - RSSë³´ë‹¤ ë” ë¹ ë¥¼ ìˆ˜ ìˆìŒ")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()


async def test_yahoo_finance_search():
    """Yahoo Finance ê²€ìƒ‰ í˜ì´ì§€ í…ŒìŠ¤íŠ¸"""
    print()
    print("=" * 70)
    print("  3. Yahoo Finance ë‰´ìŠ¤ ê²€ìƒ‰")
    print("=" * 70)
    print()
    
    # Yahoo Finance ë‰´ìŠ¤ ë©”ì¸
    news_url = "https://finance.yahoo.com/topic/stock-market-news"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.get(news_url) as resp:
                print(f"Status: {resp.status}")
                
                if resp.status != 200:
                    print("âŒ Failed")
                    return
                
                html = await resp.text()
        
        soup = BeautifulSoup(html, 'html.parser')
        
        # ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ì°¾ê¸°
        headlines = soup.find_all('h3')
        
        print(f"\nâœ… Found {len(headlines)} headlines\n")
        
        for i, h3 in enumerate(headlines[:10], 1):
            title = h3.get_text(strip=True)
            link_elem = h3.find('a')
            
            # ASML ì²´í¬
            if any(keyword in title.upper() for keyword in ['ASML', 'EUV', 'CHINA']):
                marker = "â­ "
            else:
                marker = "   "
            
            print(f"{marker}{i}. {title[:60]}...")
            if link_elem:
                print(f"       â””â”€ {link_elem.get('href', '')[:50]}...")
            print()
    
    except Exception as e:
        print(f"âŒ Error: {e}")


async def main():
    print("\nğŸ” Yahoo Finance ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸")
    print(f"í˜„ì¬ ì‹œê°: {datetime.now().strftime('%H:%M:%S')}\n")
    
    # 1. RSS Feed
    await test_yahoo_finance_rss()
    
    # 2. ì§ì ‘ ê¸°ì‚¬
    await test_yahoo_finance_article()
    
    # 3. ê²€ìƒ‰
    await test_yahoo_finance_search()
    
    print()
    print("=" * 70)
    print("  ê²°ë¡ ")
    print("=" * 70)
    print()
    print("âœ… Yahoo Finance:")
    print("   - RSS Feed ì œê³µ (ë¬´ë£Œ)")
    print("   - ì§ì ‘ ê¸°ì‚¬ ì ‘ê·¼ ê°€ëŠ¥")
    print("   - ê²€ìƒ‰ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ê°€ëŠ¥")
    print("   - ì‹¤ì‹œê°„ì„± ë†’ìŒ (5ë¶„ ì´ë‚´)")
    print("   - bot ì°¨ë‹¨ ê°€ëŠ¥ì„± ë‚®ìŒ")
    print()
    print("ğŸ’¡ ê¶Œì¥: Google Newsì™€ í•¨ê»˜ ì‚¬ìš©")


if __name__ == "__main__":
    asyncio.run(main())
