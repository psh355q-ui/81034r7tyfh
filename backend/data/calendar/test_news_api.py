"""
NEWS APIë¡œ ìœŒë¦¬ì—„ìŠ¤ ë°œì–¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
"""
import asyncio
import aiohttp
from datetime import datetime, timedelta
import os
from pathlib import Path
from dotenv import load_dotenv

# .env íŒŒì¼ ê²½ë¡œ ëª…ì‹œ
env_path = Path(__file__).parent.parent.parent.parent / '.env'
load_dotenv(env_path)


async def search_williams_news():
    """NEWS APIë¡œ ìœŒë¦¬ì—„ìŠ¤ ë°œì–¸ ê²€ìƒ‰"""
    
    api_key = os.getenv('NEWS_API_KEY', '')  # ìˆ˜ì •ë¨
    
    if not api_key:
        print("âŒ NEWS_API_KEY not found in .env")
        print("   Get free key at: https://newsapi.org/")
        return
    
    print("=" * 70)
    print("  NEWS API ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: Williams Fed Speech")
    print("=" * 70)
    print()
    
    # ê²€ìƒ‰ ì¿¼ë¦¬ë“¤
    queries = [
        "Williams Federal Reserve",
        "Williams Fed speech",
        "John Williams NY Fed",
        "Federal Reserve Williams",
    ]
    
    for query in queries:
        print(f"ğŸ” ê²€ìƒ‰: '{query}'")
        print("-" * 70)
        
        try:
            url = "https://newsapi.org/v2/everything"
            params = {
                'q': query,
                'from': (datetime.now() - timedelta(hours=2)).isoformat(),
                'to': datetime.now().isoformat(),
                'language': 'en',
                'sortBy': 'publishedAt',
                'apiKey': api_key,
                'pageSize': 5
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as resp:
                    if resp.status != 200:
                        print(f"   âŒ API Error: {resp.status}")
                        data = await resp.json()
                        print(f"   {data.get('message', 'Unknown error')}")
                        continue
                    
                    data = await resp.json()
            
            articles = data.get('articles', [])
            total = data.get('totalResults', 0)
            
            if articles:
                print(f"   âœ… Found: {total} articles (showing top 5)\n")
                
                for i, article in enumerate(articles, 1):
                    title = article.get('title', 'No title')
                    source = article.get('source', {}).get('name', 'Unknown')
                    published = article.get('publishedAt', '')
                    url = article.get('url', '')
                    
                    # ì‹œê°„ íŒŒì‹±
                    try:
                        pub_time = datetime.fromisoformat(published.replace('Z', '+00:00'))
                        time_ago = (datetime.now() - pub_time.replace(tzinfo=None)).total_seconds() / 60
                        time_str = f"{int(time_ago)}ë¶„ ì „" if time_ago < 60 else f"{int(time_ago/60)}ì‹œê°„ ì „"
                    except:
                        time_str = published
                    
                    print(f"   {i}. {title}")
                    print(f"      â”œâ”€ Source: {source}")
                    print(f"      â”œâ”€ Time: {time_str}")
                    print(f"      â””â”€ URL: {url[:60]}...")
                    print()
            else:
                print(f"   âŒ No articles found")
                print()
        
        except Exception as e:
            print(f"   âŒ Error: {e}")
            print()
    
    # ì¶”ê°€: ìµœê·¼ Fed ê´€ë ¨ ë‰´ìŠ¤
    print("=" * 70)
    print("  ìµœê·¼ Fed ê´€ë ¨ ëª¨ë“  ë‰´ìŠ¤ (ì§€ë‚œ 2ì‹œê°„)")
    print("=" * 70)
    print()
    
    try:
        url = "https://newsapi.org/v2/everything"
        params = {
            'q': 'Federal Reserve OR Fed OR FOMC',
            'from': (datetime.now() - timedelta(hours=2)).isoformat(),
            'to': datetime.now().isoformat(),
            'language': 'en',
            'sortBy': 'publishedAt',
            'apiKey': api_key,
            'pageSize': 10
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    articles = data.get('articles', [])
                    
                    if articles:
                        print(f"âœ… Found: {len(articles)} Fed-related articles\n")
                        
                        for i, article in enumerate(articles, 1):
                            title = article.get('title', 'No title')
                            source = article.get('source', {}).get('name', 'Unknown')
                            published = article.get('publishedAt', '')
                            
                            try:
                                pub_time = datetime.fromisoformat(published.replace('Z', '+00:00'))
                                time_ago = (datetime.now() - pub_time.replace(tzinfo=None)).total_seconds() / 60
                                time_str = f"{int(time_ago)}ë¶„ ì „"
                            except:
                                time_str = published
                            
                            # Williams ì–¸ê¸‰ ì²´í¬
                            williams_mentioned = 'williams' in title.lower()
                            marker = "â­" if williams_mentioned else ""
                            
                            print(f"{marker}{i}. {title}")
                            print(f"   â””â”€ {source} | {time_str}")
                            print()
                    else:
                        print("âŒ No Fed-related news in last 2 hours")
    
    except Exception as e:
        print(f"âŒ Error: {e}")
    
    print()
    print("ğŸ’¡ NEWS API íŠ¹ì§•:")
    print("   - ë¬´ë£Œ: 100 requests/day")
    print("   - ì§€ì—°: ë³´í†µ 5-15ë¶„")
    print("   - ì»¤ë²„ë¦¬ì§€: ì „ ì„¸ê³„ ì£¼ìš” ì–¸ë¡ ")
    print("   - í•œê³„: ì‹¤ì‹œê°„ì„±ì´ ë‚®ìŒ, Forex Factoryê°€ ë” ë¹ ë¦„")


if __name__ == "__main__":
    asyncio.run(search_williams_news())
