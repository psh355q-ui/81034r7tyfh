"""
SEC ë¶„ì„ ê²°ê³¼ ìºì‹±

ë¶„ì„ ë¹„ìš© ì ˆê°ì„ ìœ„í•œ ìºì‹± ì‹œìŠ¤í…œ

Author: AI Trading System
Date: 2025-11-22
"""

import json
import hashlib
from pathlib import Path
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

from backend.core.models.sec_analysis_models import (
    SECAnalysisResult,
    SECAnalysisCache,
    RiskFactor,
    RedFlag,
    FinancialTrend,
    ManagementTone,
    RiskLevel,
    SentimentTone,
    RedFlagType
)

logger = logging.getLogger(__name__)


class SECAnalysisCache:
    """
    SEC ë¶„ì„ ê²°ê³¼ ìºì‹œ ê´€ë¦¬
    
    Features:
    - íŒŒì¼ ê¸°ë°˜ ìºì‹œ (JSON)
    - 90ì¼ TTL (10-K/10-QëŠ” ë¶„ê¸°ë§ˆë‹¤ë§Œ ì—…ë°ì´íŠ¸)
    - ìºì‹œ í‚¤: ticker + filing_type + fiscal_period
    """
    
    def __init__(self, cache_dir: Optional[Path] = None):
        """
        Args:
            cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: data/sec_analysis_cache)
        """
        self.cache_dir = cache_dir or Path("data/sec_analysis_cache")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"SEC Analysis Cache initialized: {self.cache_dir}")
    
    def _get_cache_key(
        self,
        ticker: str,
        filing_type: str,
        fiscal_period: str
    ) -> str:
        """
        ìºì‹œ í‚¤ ìƒì„±
        
        Args:
            ticker: ì£¼ì‹ í‹°ì»¤
            filing_type: ê³µì‹œ ìœ í˜• (10-K, 10-Q)
            fiscal_period: íšŒê³„ ê¸°ê°„ (FY2024, Q3 2024 ë“±)
            
        Returns:
            ìºì‹œ í‚¤ (MD5 í•´ì‹œ)
        """
        key_str = f"{ticker}_{filing_type}_{fiscal_period}".upper()
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def _get_cache_file(self, cache_key: str) -> Path:
        """ìºì‹œ íŒŒì¼ ê²½ë¡œ"""
        return self.cache_dir / f"{cache_key}.json"
    
    def get(
        self,
        ticker: str,
        filing_type: str,
        fiscal_period: str
    ) -> Optional[SECAnalysisResult]:
        """
        ìºì‹œì—ì„œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
        
        Args:
            ticker: ì£¼ì‹ í‹°ì»¤
            filing_type: ê³µì‹œ ìœ í˜•
            fiscal_period: íšŒê³„ ê¸°ê°„
            
        Returns:
            SECAnalysisResult ë˜ëŠ” None (ìºì‹œ ì—†ìŒ/ë§Œë£Œ)
        """
        cache_key = self._get_cache_key(ticker, filing_type, fiscal_period)
        cache_file = self._get_cache_file(cache_key)
        
        if not cache_file.exists():
            logger.debug(f"Cache miss: {ticker} {filing_type} {fiscal_period}")
            return None
        
        try:
            # ìºì‹œ íŒŒì¼ ì½ê¸°
            with open(cache_file, 'r') as f:
                data = json.load(f)
            
            # ë§Œë£Œ í™•ì¸
            cached_at = datetime.fromisoformat(data["cached_at"])
            ttl_days = data.get("ttl_days", 90)
            
            if datetime.now() > cached_at + timedelta(days=ttl_days):
                logger.debug(f"Cache expired: {ticker} {filing_type} {fiscal_period}")
                cache_file.unlink()  # ì‚­ì œ
                return None
            
            # ë¶„ì„ ê²°ê³¼ ë³µì›
            result = self._deserialize_result(data["analysis"])
            
            logger.info(
                f"Cache hit: {ticker} {filing_type} {fiscal_period} "
                f"(cached {(datetime.now() - cached_at).days} days ago)"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Failed to load cache: {e}")
            return None
    
    def set(
        self,
        result: SECAnalysisResult,
        ttl_days: int = 90
    ):
        """
        ë¶„ì„ ê²°ê³¼ ìºì‹œ ì €ì¥
        
        Args:
            result: ë¶„ì„ ê²°ê³¼
            ttl_days: ìºì‹œ ìœ íš¨ ê¸°ê°„ (ê¸°ë³¸ 90ì¼)
        """
        cache_key = self._get_cache_key(
            result.ticker,
            result.filing_type,
            result.fiscal_period
        )
        cache_file = self._get_cache_file(cache_key)
        
        try:
            # ìºì‹œ ë°ì´í„° ìƒì„±
            cache_data = {
                "cache_key": cache_key,
                "ticker": result.ticker,
                "filing_type": result.filing_type,
                "fiscal_period": result.fiscal_period,
                "cached_at": datetime.now().isoformat(),
                "ttl_days": ttl_days,
                "analysis": self._serialize_result(result)
            }
            
            # íŒŒì¼ ì €ì¥
            with open(cache_file, 'w') as f:
                json.dump(cache_data, f, indent=2)
            
            logger.info(f"Cached: {result.ticker} {result.filing_type} {result.fiscal_period}")
            
        except Exception as e:
            logger.error(f"Failed to save cache: {e}")
    
    def invalidate(
        self,
        ticker: str,
        filing_type: str,
        fiscal_period: str
    ):
        """
        ìºì‹œ ë¬´íš¨í™” (ì‚­ì œ)
        
        Args:
            ticker: ì£¼ì‹ í‹°ì»¤
            filing_type: ê³µì‹œ ìœ í˜•
            fiscal_period: íšŒê³„ ê¸°ê°„
        """
        cache_key = self._get_cache_key(ticker, filing_type, fiscal_period)
        cache_file = self._get_cache_file(cache_key)
        
        if cache_file.exists():
            cache_file.unlink()
            logger.info(f"Cache invalidated: {ticker} {filing_type} {fiscal_period}")
    
    def clear_all(self):
        """ëª¨ë“  ìºì‹œ ì‚­ì œ"""
        count = 0
        for cache_file in self.cache_dir.glob("*.json"):
            cache_file.unlink()
            count += 1
        
        logger.info(f"Cleared {count} cache files")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„"""
        cache_files = list(self.cache_dir.glob("*.json"))
        
        total_size = sum(f.stat().st_size for f in cache_files)
        
        return {
            "total_files": len(cache_files),
            "total_size_mb": total_size / (1024 * 1024),
            "cache_dir": str(self.cache_dir)
        }
    
    def _serialize_result(self, result: SECAnalysisResult) -> Dict[str, Any]:
        """SECAnalysisResult â†’ JSON ë”•ì…”ë„ˆë¦¬"""
        return {
            "ticker": result.ticker,
            "filing_type": result.filing_type,
            "fiscal_period": result.fiscal_period,
            "analysis_date": result.analysis_date.isoformat(),
            "overall_risk_level": result.overall_risk_level.value,
            "overall_risk_score": result.overall_risk_score,
            "investment_signal": result.investment_signal,
            "risk_factors": [
                {
                    "category": rf.category,
                    "title": rf.title,
                    "description": rf.description,
                    "severity": rf.severity.value,
                    "impact_score": rf.impact_score,
                    "likelihood_score": rf.likelihood_score,
                    "is_new": rf.is_new
                }
                for rf in result.risk_factors
            ],
            "red_flags": [
                {
                    "flag_type": rf.flag_type.value,
                    "severity": rf.severity.value,
                    "description": rf.description,
                    "detected_in_section": rf.detected_in_section,
                    "quotes": rf.quotes,
                    "action_required": rf.action_required
                }
                for rf in result.red_flags
            ],
            "financial_trends": [
                {
                    "metric": ft.metric,
                    "current_value": ft.current_value,
                    "prior_value": ft.prior_value,
                    "change_percent": ft.change_percent,
                    "trend": ft.trend,
                    "interpretation": ft.interpretation
                }
                for ft in result.financial_trends
            ],
            "management_tone": {
                "overall_sentiment": result.management_tone.overall_sentiment.value,
                "sentiment_score": result.management_tone.sentiment_score,
                "confidence_level": result.management_tone.confidence_level,
                "key_phrases": result.management_tone.key_phrases,
                "tone_change_vs_prior": result.management_tone.tone_change_vs_prior,
                "concerns_mentioned": result.management_tone.concerns_mentioned,
                "opportunities_mentioned": result.management_tone.opportunities_mentioned
            } if result.management_tone else None,
            "executive_summary": result.executive_summary,
            "key_takeaways": result.key_takeaways,
            "model_used": result.model_used,
            "tokens_used": result.tokens_used,
            "analysis_cost": result.analysis_cost,
            "confidence_score": result.confidence_score
        }
    
    def _deserialize_result(self, data: Dict[str, Any]) -> SECAnalysisResult:
        """JSON ë”•ì…”ë„ˆë¦¬ â†’ SECAnalysisResult"""
        # Risk Factors
        risk_factors = [
            RiskFactor(
                category=rf["category"],
                title=rf["title"],
                description=rf["description"],
                severity=RiskLevel(rf["severity"]),
                impact_score=rf["impact_score"],
                likelihood_score=rf["likelihood_score"],
                is_new=rf.get("is_new", False)
            )
            for rf in data.get("risk_factors", [])
        ]
        
        # Red Flags
        red_flags = [
            RedFlag(
                flag_type=RedFlagType(rf["flag_type"]),
                severity=RiskLevel(rf["severity"]),
                description=rf["description"],
                detected_in_section=rf["detected_in_section"],
                quotes=rf.get("quotes", []),
                action_required=rf.get("action_required", False)
            )
            for rf in data.get("red_flags", [])
        ]
        
        # Financial Trends
        financial_trends = [
            FinancialTrend(
                metric=ft["metric"],
                current_value=ft.get("current_value"),
                prior_value=ft.get("prior_value"),
                change_percent=ft.get("change_percent"),
                trend=ft["trend"],
                interpretation=ft["interpretation"]
            )
            for ft in data.get("financial_trends", [])
        ]
        
        # Management Tone
        management_tone = None
        if data.get("management_tone"):
            mt = data["management_tone"]
            management_tone = ManagementTone(
                overall_sentiment=SentimentTone(mt["overall_sentiment"]),
                sentiment_score=mt["sentiment_score"],
                confidence_level=mt["confidence_level"],
                key_phrases=mt.get("key_phrases", []),
                tone_change_vs_prior=mt.get("tone_change_vs_prior"),
                concerns_mentioned=mt.get("concerns_mentioned", []),
                opportunities_mentioned=mt.get("opportunities_mentioned", [])
            )
        
        # ê²°ê³¼ ìƒì„±
        return SECAnalysisResult(
            ticker=data["ticker"],
            filing_type=data["filing_type"],
            fiscal_period=data["fiscal_period"],
            analysis_date=datetime.fromisoformat(data["analysis_date"]),
            overall_risk_level=RiskLevel(data["overall_risk_level"]),
            overall_risk_score=data["overall_risk_score"],
            investment_signal=data["investment_signal"],
            risk_factors=risk_factors,
            red_flags=red_flags,
            financial_trends=financial_trends,
            management_tone=management_tone,
            executive_summary=data["executive_summary"],
            key_takeaways=data["key_takeaways"],
            model_used=data["model_used"],
            tokens_used=data["tokens_used"],
            analysis_cost=data["analysis_cost"],
            confidence_score=data["confidence_score"]
        )


# ============================================
# ìºì‹± ë˜í¼ (Analyzer í†µí•©ìš©)
# ============================================

class CachedSECAnalyzer:
    """
    ìºì‹± ê¸°ëŠ¥ì´ í†µí•©ëœ SEC Analyzer
    
    ìë™ìœ¼ë¡œ ìºì‹œë¥¼ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ë¶„ì„ í›„ ìºì‹œ ì €ì¥
    """
    
    def __init__(
        self,
        analyzer,  # SECAnalyzer ì¸ìŠ¤í„´ìŠ¤
        cache: Optional[SECAnalysisCache] = None
    ):
        """
        Args:
            analyzer: SECAnalyzer ì¸ìŠ¤í„´ìŠ¤
            cache: SECAnalysisCache ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒ)
        """
        self.analyzer = analyzer
        self.cache = cache or SECAnalysisCache()
    
    async def analyze_ticker(
        self,
        request  # SECAnalysisRequest
    ) -> SECAnalysisResult:
        """
        ìºì‹± ê¸°ëŠ¥ì´ í†µí•©ëœ ë¶„ì„
        
        1. ìºì‹œ í™•ì¸
        2. ìˆìœ¼ë©´ ë°˜í™˜
        3. ì—†ìœ¼ë©´ ë¶„ì„ í›„ ìºì‹œ ì €ì¥
        """
        # force_refreshë©´ ìºì‹œ ë¬´ì‹œ
        if not request.force_refresh:
            # ìºì‹œ í™•ì¸ (fiscal_periodëŠ” ì•„ì§ ëª¨ë¦„)
            # ì¼ë‹¨ ìµœì‹  ê³µì‹œ ì¡°íšŒ í•„ìš”
            pass
        
        # ë¶„ì„ ì‹¤í–‰
        result = await self.analyzer.analyze_ticker(request)
        
        # ìºì‹œ ì €ì¥
        self.cache.set(result)
        
        return result


# ============================================
# í…ŒìŠ¤íŠ¸
# ============================================

if __name__ == "__main__":
    from backend.core.models.sec_analysis_models import SECAnalysisResult
    
    # ìƒ˜í”Œ ê²°ê³¼ ìƒì„±
    sample_result = SECAnalysisResult(
        ticker="AAPL",
        filing_type="10-K",
        fiscal_period="FY2024",
        overall_risk_level=RiskLevel.MEDIUM,
        overall_risk_score=0.5,
        investment_signal="HOLD",
        executive_summary="Sample summary",
        key_takeaways=["Takeaway 1", "Takeaway 2"],
        model_used="claude-sonnet-4.5",
        tokens_used=10000,
        analysis_cost=0.05,
        confidence_score=0.85
    )
    
    # ìºì‹œ í…ŒìŠ¤íŠ¸
    cache = SECAnalysisCache()
    
    print("=== Cache Test ===\n")
    
    # ì €ì¥
    cache.set(sample_result)
    print(f"âœ… Saved to cache")
    
    # ì¡°íšŒ
    cached = cache.get("AAPL", "10-K", "FY2024")
    if cached:
        print(f"âœ… Retrieved from cache")
        print(f"   Risk: {cached.overall_risk_level.value}")
        print(f"   Signal: {cached.investment_signal}")
    
    # í†µê³„
    stats = cache.get_cache_stats()
    print(f"\nğŸ“Š Cache Stats:")
    print(f"   Files: {stats['total_files']}")
    print(f"   Size: {stats['total_size_mb']:.2f} MB")
