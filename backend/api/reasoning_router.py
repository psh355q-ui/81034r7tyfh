from fastapi import APIRouter, HTTPException, Depends
from typing import Optional
from pydantic import BaseModel
import logging

from backend.ai.reasoning.engine import reasoning_engine
from backend.ai.reasoning.models import MarketThesis
from backend.ai.skills.common.logging_decorator import log_endpoint

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/reasoning", tags=["Deep Reasoning"])

class AnalyzeRequest(BaseModel):
    ticker: str
    news_context: str
    technical_summary: dict = {"rsi": 50, "trend": "Unknown"} # Placeholder default
    use_mock: bool = False  # Add mock mode support
    enable_macro_check: bool = False  # ë§¤í¬ë¡œ ì •í•©ì„± ì²´í¬
    enable_skeptic: bool = False  # ë°˜ë°•ë…¼ë¦¬ì¶”ê°€

@router.post("/analyze")
@log_endpoint("reasoning", "system")
async def analyze_ticker_manually(request: AnalyzeRequest):
    """
    Trigger Deep Reasoning on a ticker with provided context (Manual/Dev Mode).
    
    Now includes auto-save to database with source='deep_reasoning'
    
    Optional advanced features:
    - enable_macro_check: Add macro consistency check
    - enable_skeptic: Add skeptic challenge (ë°˜ë°•ë…¼ë¦¬)
    """
    if not reasoning_engine:
        raise HTTPException(status_code=503, detail="Reasoning Engine not initialized (Check API Key)")

    # Base analysis
    thesis = await reasoning_engine.analyze_ticker(
        ticker=request.ticker,
        news_context=request.news_context,
        technical_data=request.technical_summary,
        use_mock=request.use_mock
    )
    
    if not thesis:
        raise HTTPException(status_code=500, detail="Failed to generate thesis")
    
    # ğŸ’¾ Save to database (Phase 2: Signal Generator Integration)
    if thesis.direction in ["BUY", "SELL", "HOLD"]:  # Save ALL for history
        try:
            from backend.database.models import TradingSignal as DBTradingSignal
            from backend.database.repository import get_sync_session
            from datetime import datetime
            import inspect
            
            db = get_sync_session()
            
            # Handle if get_sync_session returns a generator (safety check)
            if inspect.isgenerator(db):
                db = next(db)
            
            try:
                # Ensure we have a valid session
                if not hasattr(db, "add"):
                     logger.error(f"Invalid DB session object type: {type(db)}")
                     raise ValueError("Invalid DB session")

                signal = DBTradingSignal(
                    analysis_id=None,  # Deep Reasoning is independent
                    ticker=request.ticker,
                    action=thesis.direction,
                    signal_type="DEEP_REASONING",  # Correct signal type
                    confidence=thesis.final_confidence_score,
                    reasoning=thesis.summary,
                    source="deep_reasoning",  # ğŸ†• Source tracking
                    generated_at=datetime.now()
                )
                db.add(signal)
                db.commit()
                db.refresh(signal)
                
                logger.info(f"ğŸ“Š Deep Reasoning signal saved: {request.ticker} {thesis.direction} (ID: {signal.id})")
            
            except Exception as db_error:
                logger.error(f"Failed to save Deep Reasoning signal: {db_error}")
                # Don't fail the request if DB save fails
            finally:
                if hasattr(db, "close"):
                    db.close()
        
        except Exception as import_error:
            logger.error(f"Failed to import DB models or session: {import_error}")
    
    # Prepare response
    response = thesis.dict()
    
    # Optional: Macro Consistency Check
    if request.enable_macro_check:
        if request.use_mock:
            # Mock macro warning
            response["macro_warning"] = """# ğŸ“Š ë§¤í¬ë¡œ ì •í•©ì„± ì²´í¬ ë¦¬í¬íŠ¸ (Mock)

## 1. ğŸŸ¡ ì •ì±… ëª¨ìˆœ (Policy Contradiction)

**ì‹¬ê°ë„**: MEDIUM (ì ìˆ˜: 60%)

**ëª¨ìˆœ ì„¤ëª…**: GDP ì „ë§ì€ ìƒí–¥ë˜ì—ˆìœ¼ë‚˜ ê¸ˆë¦¬ ê²½ë¡œëŠ” í•˜í–¥ë˜ì—ˆìŠµë‹ˆë‹¤.

**ë°ì´í„°**:
- gdp_forecast_change: 0.5 (UP)
- rate_path_change: -0.3 (DOWN)

**ê°€ëŠ¥í•œ ì„¤ëª…**:
- Fedì˜ ì •ì±… ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í˜¼ë€
- ì„ ê±°ë¥¼ ì•ë‘” ì •ì¹˜ì  ì••ë ¥
- ê¸€ë¡œë²Œ ìš”ì¸ (ë‹¤ë¥¸ ì¤‘ì•™ì€í–‰ ì™„í™”)

**ì—­ì‚¬ì  ì„ ë¡€**:
- 2023ë…„ SVB ì‚¬íƒœ: ê¸´ì¶•ê³¼ ìœ ë™ì„± ê³µê¸‰ ë™ì‹œ ì§„í–‰

**ì‹œì¥ ì˜í–¥**: ì •ì±… ë¶ˆí™•ì‹¤ì„± ì¦ê°€, ë‹¬ëŸ¬ ì•½ì„¸

---
"""
            response["macro_contradictions_count"] = 1
        else:
            try:
                from backend.ai.reasoning.macro_consistency_checker import MacroConsistencyChecker
                
                macro_checker = MacroConsistencyChecker()
                # Dummy macro data for now (in production, fetch real data)
                macro_data = {
                    "gdp_growth": 2.3,
                    "fed_rate_change": -0.25,
                    "unemployment_rate": 3.7,
                    "cpi_yoy": 3.2,
                    "vix": 13.5,
                    "credit_spread": 1.2,
                }
                
                contradictions = await macro_checker.detect_contradictions(macro_data)
                
                if contradictions:
                    macro_report = macro_checker.format_report_korean(contradictions)
                    response["macro_warning"] = macro_report
                    response["macro_contradictions_count"] = len(contradictions)
                    logger.info(f"Macro check: {len(contradictions)} contradictions found")
                else:
                    response["macro_warning"] = "âœ… í˜„ì¬ ê°ì§€ëœ ë§¤í¬ë¡œ ëª¨ìˆœì´ ì—†ìŠµë‹ˆë‹¤."
                    response["macro_contradictions_count"] = 0
            except Exception as e:
                logger.error(f"Macro check failed: {e}")
                response["macro_warning"] = f"ë§¤í¬ë¡œ ì²´í¬ ì‹¤íŒ¨: {str(e)}"
    
    # Optional: Skeptic Challenge
    if request.enable_skeptic:
        if request.use_mock:
            # Mock skeptic challenge
            ticker_name = request.ticker
            response["skeptic_challenge"] = f"""# ğŸ˜ˆ íšŒì˜ë¡ ì  ë¶„ì„ (Skeptic Challenge) - Mock

## {ticker_name}ì— ëŒ€í•œ ë°˜ëŒ€ ì˜ê²¬

### ğŸ”´ ì£¼ìš” ì•½ì  (Critical Weaknesses)

1. **ê³¼ëŒ€í‰ê°€ëœ ì„±ì¥ ê¸°ëŒ€**
   - í˜„ì¬ ë°¸ë¥˜ì—ì´ì…˜ì€ ì™„ë²½í•œ ì‹¤í–‰ì„ ì „ì œë¡œ í•¨
   - ê²½ìŸìë“¤ì˜ ê¸°ìˆ  ì¶”ê²© ì†ë„ê°€ ì˜ˆìƒë³´ë‹¤ ë¹ ë¦„
   - ì‹œì¥ì´ ê°„ê³¼í•œ ì‹¤í–‰ ë¦¬ìŠ¤í¬ ì¡´ì¬

2. **ë§¤í¬ë¡œ í™˜ê²½ ì•…í™” ê°€ëŠ¥ì„±**
   - ê¸ˆë¦¬ ì¸í•˜ ì§€ì—° ì‹œ ì„±ì¥ì£¼ ì „ë°˜ íƒ€ê²©
   - ê²½ê¸° ë‘”í™” ì‹œ ì†Œë¹„ì ì§€ì¶œ ê°ì†Œ
   - ë‹¬ëŸ¬ ê°•ì„¸ ì‹œ í•´ì™¸ ë§¤ì¶œ íƒ€ê²©

3. **ìˆ¨ê²¨ì§„ êµ¬ì¡°ì  ë¬¸ì œ**
   - ê·œì œ ë¦¬ìŠ¤í¬ ê³¼ì†Œí‰ê°€
   - ê²½ì˜ì§„ì˜ ê³¼ì‹  ê°€ëŠ¥ì„±
   - ë‹¨ê¸° ì‹¤ì  ì••ë°• ì¦ê°€

### ğŸ’¡ íšŒì˜ì  ì‹œë‚˜ë¦¬ì˜¤

ë§Œì•½ ë‹¤ìŒ ë¶„ê¸° ì‹¤ì ì´ ê¸°ëŒ€ì¹˜ë¥¼ 10% ë°‘ëŒë©´:
- ì£¼ê°€ 20% ì¡°ì • ê°€ëŠ¥
- ì‹œì¥ ì„¼í‹°ë¨¼íŠ¸ ê¸‰ê²©íˆ ì•…í™”
- ê¸°ìˆ ì  ì§€ì§€ì„  ë¶•ê´´ ìœ„í—˜

### ğŸ¯ ì¶”ì²œì‚¬í•­: ğŸŸ¡ CAUTION (ì‹ ì¤‘ ì ‘ê·¼)

**ì´ìœ **: Bull CaseëŠ” íƒ€ë‹¹í•˜ë‚˜, ì‹œì¥ì´ ê°„ê³¼í•œ ë¦¬ìŠ¤í¬ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.
"""
            response["skeptic_recommendation"] = "CAUTION"
        else:
            try:
                from backend.ai.reasoning.skeptic_agent import SkepticAgent
                
                skeptic = SkepticAgent()
                
                # Prepare consensus analysis dict for SkepticAgent
                consensus_analysis = {
                    "action": thesis.direction,
                    "confidence": thesis.final_confidence_score,
                    "reasoning": thesis.summary
                }
                
                skeptic_analysis = await skeptic.analyze(
                    ticker=request.ticker,
                    consensus_analysis=consensus_analysis,
                    market_data={}
                )
                
                skeptic_report = skeptic.format_report_korean(skeptic_analysis)
                response["skeptic_challenge"] = skeptic_report
                response["skeptic_recommendation"] = skeptic_analysis.recommendation.value
                logger.info(f"Skeptic analysis: {skeptic_analysis.recommendation}")
            except Exception as e:
                logger.error(f"Skeptic analysis failed: {e}")
                response["skeptic_challenge"] = f"íšŒì˜ë¡ ì  ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        
    return response

@router.get("/health")
@log_endpoint("reasoning", "system")
def health_check():
    return {"status": "active", "engine": "ready" if reasoning_engine else "disabled"}


@router.get("/history")
@log_endpoint("reasoning", "history")
def get_analysis_history(limit: int = 20):
    """
    Get recent Deep Reasoning analysis history from database.
    """
    try:
        from backend.database.repository import get_sync_session
        from backend.database.models import TradingSignal as DBTradingSignal
        from sqlalchemy import desc
        import inspect
        
        db = get_sync_session()
        if inspect.isgenerator(db):
            db = next(db)
            
        try:
            # Fetch signals created by deep_reasoning
            signals = (
                db.query(DBTradingSignal)
                .filter(DBTradingSignal.source == "deep_reasoning")
                .order_by(desc(DBTradingSignal.generated_at))
                .limit(limit)
                .all()
            )
            
            # Format response
            history = []
            for s in signals:
                history.append({
                    "id": s.id,
                    "ticker": s.ticker,
                    "action": s.action,
                    "confidence": s.confidence,
                    "reasoning": s.reasoning,
                    "date": s.generated_at.isoformat() if s.generated_at else None,
                    "type": s.signal_type
                })
                
            return history
            
        except Exception as e:
            logger.error(f"Failed to fetch history: {e}")
            raise HTTPException(status_code=500, detail=str(e))
        finally:
            if hasattr(db, "close"):
                db.close()
                
    except Exception as e:
        logger.error(f"Database error: {e}")
        return []
