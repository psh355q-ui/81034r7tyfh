"""
News Poller Service

Features:
- Periodic RSS Crawling (5 min interval)
- Keyword Pre-filtering (save AI tokens)
- Triggering Deep Reasoning Agent for critical events
"""

import asyncio
import logging
from datetime import datetime
from typing import List

from sqlalchemy.orm import Session

from backend.data.rss_crawler import RSSCrawler
from backend.data.news_analyzer import NewsDeepAnalyzer
from backend.ai.reasoning.deep_reasoning_agent import DeepReasoningAgent
from backend.data.news_models import SessionLocal, NewsArticle, NewsAnalysis
from backend.database.models import TradingSignal

logger = logging.getLogger(__name__)

# Trigger Keywords (Pre-filter)
# Ïù¥ ÌÇ§ÏõåÎìúÍ∞Ä Ìè¨Ìï®Îêú Îâ¥Ïä§Îßå AI Î∂ÑÏÑùÏùÑ ÏàòÌñâÌïòÏó¨ ÎπÑÏö© Ï†àÍ∞ê
CRITICAL_KEYWORDS = [
    "war", "invasion", "military", "conflict", "attack",
    "sanction", "embargo", "ban",
    "crisis", "shortage", "collapse", "bankrupt",
    "rate hike", "inflation", "cpi", "fomc",
    "oil", "semiconductor", "chip", "taiwan", "china"
]

class NewsPoller:
    def __init__(self):
        self.is_running = False
        self.interval_seconds = 300  # 5 minutes
        self.deep_agent = DeepReasoningAgent()
        
    async def start(self):
        """Start the polling loop"""
        if self.is_running:
            return
        
        self.is_running = True
        logger.info("üì∞ NewsPoller started (Interval: 5m)")
        
        while self.is_running:
            try:
                await self.poll_and_process()
            except Exception as e:
                logger.error(f"‚ùå NewsPoller Loop Error: {e}", exc_info=True)
            
            await asyncio.sleep(self.interval_seconds)

    def stop(self):
        self.is_running = False
        logger.info("üì∞ NewsPoller stopped")

    async def poll_and_process(self):
        """Single polling cycle"""
        db = SessionLocal()
        try:
            crawler = RSSCrawler(db)
            analyzer = NewsDeepAnalyzer(db)
            
            # 1. Crawl all enabled feeds
            logger.info("üï∑Ô∏è Crawling RSS feeds...")
            # Running synchronous crawler in a thread to avoid blocking the event loop
            new_articles = await asyncio.to_thread(crawler.crawl_all_feeds)
            
            if not new_articles:
                logger.info("No new articles found.")
                return

            logger.info(f"‚ú® Found {len(new_articles)} new articles.")

            # 2. Filter & Analyze
            for article in new_articles:
                matched_keywords = self._check_keywords(article)
                
                if matched_keywords:
                    logger.info(f"üîé Keyword Match [{', '.join(matched_keywords)}]: {article.title}")
                    
                    # 3. AI Deep Analysis (NewsDeepAnalyzer)
                    analysis = await analyzer.analyze_article(article.id)
                    
                    # 4. If Urgent/Critical -> Trigger Deep Reasoning (The Brain)
                    if analysis and analysis.urgency in ["high", "critical"]:
                        logger.warning(f"üß† High Urgency Event Detected! Triggering DeepReasoningAgent...")
                        
                        await self._trigger_deep_reasoning(
                            db, 
                            article, 
                            matched_keywords, 
                            analysis
                        )
                else:
                    pass
                    # logger.debug(f"Skipping (No keywords): {article.title}")
                    
        finally:
            db.close()

    def _check_keywords(self, article: NewsArticle) -> List[str]:
        """Check if article matches critical keywords"""
        text_to_check = (f"{article.title} {article.summary or ''}").lower()
        matches = [k for k in CRITICAL_KEYWORDS if k in text_to_check]
        return matches

    async def _trigger_deep_reasoning(self, db: Session, article: NewsArticle, keywords: List[str], analysis: NewsAnalysis):
        """Deep Reasoning Agent Ìò∏Ï∂ú Î∞è ÏãúÍ∑∏ÎÑê ÏÉùÏÑ±"""
        try:
            # Í∏∞Î≥∏ Ï†ïÎ≥¥ Íµ¨ÏÑ±
            base_info = {
                "title": article.title,
                "summary": article.summary,
                "published_at": str(article.published_date),
                "source": article.source,
                "initial_analysis": {
                    "urgency": analysis.urgency,
                    "sentiment": analysis.sentiment_overall,
                    "impact": analysis.market_impact_short
                }
            }

            # Í≤∞Ï†ï: Event Type (Îã®Ïàú ÌÇ§ÏõåÎìú Í∏∞Î∞ò Îß§Ìïë for MVP)
            event_type = "GEOPOLITICS"
            if any(k in keywords for k in ["semiconductor", "chip", "taiwan"]):
                event_type = "CHIP_WAR"

            # Deep Reasoning Ïã§Ìñâ
            result = await self.deep_agent.analyze_event(event_type, keywords, base_info)
            
            if result.get("status") == "SUCCESS":
                action_plan = result.get("action_plan", {})
                action = action_plan.get("action", "HOLD")
                
                if action != "HOLD":
                    # Signal ÏÉùÏÑ± & Ï†ÄÏû•
                    signal = TradingSignal(
                        ticker="MARKET" if event_type=="GEOPOLITICS" else "NVDA", # MVP Simplification
                        action=action,
                        signal_type="DEEP_REASONING",
                        confidence=action_plan.get("confidence", 0.0),
                        reason=f"Event: {article.title[:50]}... | {action_plan.get('reasoning')}",
                        generated_at=datetime.utcnow(),
                        # meta_data=result # Postgres model might not have meta_data column yet or use JSON
                    )
                    db.add(signal)
                    db.commit()
                    logger.info(f"üö® DeepReasoning Signal Created: {action} (Conf: {signal.confidence})")
            
        except Exception as e:
            logger.error(f"‚ùå DeepReasoning Trigger Failed: {e}", exc_info=True)
