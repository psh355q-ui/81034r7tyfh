"""
News Poller Service

Features:
- Periodic RSS Crawling (5 min interval)
- Keyword Pre-filtering (save AI tokens)
- Triggering Deep Reasoning Agent for critical events
"""

import asyncio
import logging
from datetime import datetime
from typing import List

from sqlalchemy.orm import Session

from backend.data.rss_crawler import RSSCrawler
from backend.data.news_analyzer import NewsDeepAnalyzer
from backend.ai.reasoning.deep_reasoning_agent import DeepReasoningAgent
from backend.data.news_models import SessionLocal, NewsArticle, NewsAnalysis
from backend.database.models import TradingSignal

logger = logging.getLogger(__name__)

# Trigger Keywords (Pre-filter)
# ì´ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë‰´ìŠ¤ë§Œ AI ë¶„ì„ì„ ìˆ˜í–‰í•˜ì—¬ ë¹„ìš© ì ˆê°
CRITICAL_KEYWORDS = [
    "war", "invasion", "military", "conflict", "attack",
    "sanction", "embargo", "ban",
    "crisis", "shortage", "collapse", "bankrupt",
    "rate hike", "inflation", "cpi", "fomc",
    "oil", "semiconductor", "chip", "taiwan", "china"
]

class NewsPoller:
    def __init__(self):
        self.is_running = False
        self.interval_seconds = 300  # 5 minutes
        self.deep_agent = DeepReasoningAgent()
        self._last_triggered = {}  # Cache for debouncing events
        
    async def start(self):
        """Start the polling loop"""
        if self.is_running:
            return
        
        self.is_running = True
        logger.info("ğŸ“° NewsPoller started (Interval: 5m)")
        
        while self.is_running:
            try:
                await self.poll_and_process()
            except Exception as e:
                logger.error(f"âŒ NewsPoller Loop Error: {e}", exc_info=True)
            
            await asyncio.sleep(self.interval_seconds)

    def stop(self):
        self.is_running = False
        logger.info("ğŸ“° NewsPoller stopped")

    async def poll_and_process(self):
        """Single polling cycle"""
        db = SessionLocal()
        try:
            crawler = RSSCrawler(db)
            analyzer = NewsDeepAnalyzer(db)
            
            # 1. Crawl all enabled feeds
            logger.info("ğŸ•·ï¸ Crawling RSS feeds...")
            # Running synchronous crawler in a thread to avoid blocking the event loop
            new_articles = await asyncio.to_thread(crawler.crawl_all_feeds)
            
            if not new_articles:
                logger.info("No new articles found.")
                return

            logger.info(f"âœ¨ Found {len(new_articles)} new articles.")

            # 2. Filter & Analyze
            for article in new_articles:
                matched_keywords = self._check_keywords(article)
                
                if matched_keywords:
                    logger.info(f"ğŸ” Keyword Match [{', '.join(matched_keywords)}]: {article.title}")
                    
                    # 3. AI Deep Analysis (NewsDeepAnalyzer)
                    analysis = await asyncio.to_thread(analyzer.analyze_article, article)
                    
                    # 4. If Urgent/Critical -> Trigger Deep Reasoning (The Brain)
                    if analysis and analysis.urgency in ["high", "critical"]:
                        logger.warning(f"ğŸ§  High Urgency Event Detected! Triggering DeepReasoningAgent...")
                        
                        await self._trigger_deep_reasoning(
                            db, 
                            article, 
                            matched_keywords, 
                            analysis
                        )
                else:
                    pass
                    # logger.debug(f"Skipping (No keywords): {article.title}")
                    
        finally:
            db.close()

    def _check_keywords(self, article: NewsArticle) -> List[str]:
        """Check if article matches critical keywords"""
        text_to_check = (f"{article.title} {article.summary or ''}").lower()
        matches = [k for k in CRITICAL_KEYWORDS if k in text_to_check]
        return matches

    async def _trigger_deep_reasoning(self, db: Session, article: NewsArticle, keywords: List[str], analysis: NewsAnalysis):
        """Deep Reasoning Agent í˜¸ì¶œ ë° ì‹œê·¸ë„ ìƒì„± (with Debouncing)"""
        try:
            # ê²°ì •: Event Type (ë‹¨ìˆœ í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤í•‘ for MVP)
            event_type = "GEOPOLITICS"
            if any(k in keywords for k in ["semiconductor", "chip", "taiwan"]):
                event_type = "CHIP_WAR"

            # Debouncing Check: 1ì‹œê°„ ë‚´ ë™ì¼ ìœ í˜• ì´ë²¤íŠ¸ ë¬´ì‹œ
            last_time = self._last_triggered.get(event_type)
            if last_time and (datetime.utcnow() - last_time).total_seconds() < 3600:
                logger.info(f"â³ Debouncing: Skipping Deep Reasoning for {event_type} (Last run: {last_time})")
                return

            # ê¸°ë³¸ ì •ë³´ êµ¬ì„±
            base_info = {
                "title": article.title,
                "summary": article.summary,
                "published_at": str(article.published_date),
                "source": article.source,
                "initial_analysis": {
                    "urgency": analysis.urgency,
                    "sentiment": analysis.sentiment_overall,
                    "impact": analysis.market_impact_short
                }
            }

            # Deep Reasoning ì‹¤í–‰
            result = await self.deep_agent.analyze_event(event_type, keywords, base_info)
            
            # Update debounce timestamp check
            self._last_triggered[event_type] = datetime.utcnow()
            
            if result.get("status") == "SUCCESS":
                action_plan = result.get("action_plan", {})
                action = action_plan.get("action", "HOLD")
                
                if action != "HOLD":
                    # Signal ìƒì„± & ì €ì¥
                    signal = TradingSignal(
                        ticker="MARKET" if event_type=="GEOPOLITICS" else "NVDA", # MVP Simplification
                        action=action,
                        signal_type="DEEP_REASONING",
                        confidence=action_plan.get("confidence", 0.0),
                        reasoning=f"Event: {article.title[:50]}... | {action_plan.get('reasoning')}", # Fixed field name
                        source="news_poller", # Fixed source
                        generated_at=datetime.utcnow(),
                        # meta_data=result # Postgres model might not have meta_data column yet or use JSON
                    )
                    
                    # Safe DB Add with error handling
                    try:
                       db.add(signal)
                       db.commit()
                       logger.info(f"ğŸš¨ DeepReasoning Signal Created: {action} (Conf: {signal.confidence})")
                    except Exception as db_e:
                       logger.error(f"Failed to save signal: {db_e}")
                       db.rollback()
            
        except Exception as e:
            logger.error(f"âŒ DeepReasoning Trigger Failed: {e}", exc_info=True)
