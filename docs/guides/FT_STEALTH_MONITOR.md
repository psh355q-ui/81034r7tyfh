# FT Stealth Monitor - ì‚¬ìš© ê°€ì´ë“œ

ë°±ì•…ê´€ ì—°ì„¤ ë“± ì¤‘ìš” ë‰´ìŠ¤ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ìŠ¤í…”ìŠ¤ í¬ë¡¤ëŸ¬ì…ë‹ˆë‹¤.

## ì£¼ìš” ê¸°ëŠ¥

### ğŸ•µï¸ ìŠ¤í…”ìŠ¤ ëª¨ë“œ
- **User-Agent ë¡œí…Œì´ì…˜**: 5ê°€ì§€ ì‹¤ì œ ë¸Œë¼ìš°ì € User-Agent ëœë¤ ì‚¬ìš©
- **ëœë¤ ë”œë ˆì´**: ì •í™•íˆ 3ë¶„ì´ ì•„ë‹Œ 2.5~3.5ë¶„ ì‚¬ì´ ëœë¤ ê°„ê²©
- **ë¸Œë¼ìš°ì € í—¤ë” ìŠ¤í‘¸í•‘**: Accept, Referer, DNT ë“± ì‹¤ì œ ë¸Œë¼ìš°ì € í—¤ë” ëª¨ë°©
- **ì½˜í…ì¸  ë³€ê²½ ê°ì§€**: SHA-256 í•´ì‹œë¡œ ì½˜í…ì¸  ë³€ê²½ ê°ì§€

### ğŸ“° ìë™ ì €ì¥
- DBì— ìë™ ì €ì¥ (ì¤‘ë³µ ì œê±°)
- ì½˜í…ì¸  ë³€ê²½ ì‹œì—ë§Œ ì—…ë°ì´íŠ¸
- ë©”íƒ€ íƒœê·¸ ìš°ì„  ì¶”ì¶œ (Open Graph, description)

### ğŸ”” ì‹¤ì‹œê°„ ì•Œë¦¼
- ì½˜í…ì¸  ë³€ê²½ ì‹œ ì½œë°± í•¨ìˆ˜ í˜¸ì¶œ
- AI ë¶„ì„ íŒŒì´í”„ë¼ì¸ íŠ¸ë¦¬ê±° ê°€ëŠ¥

## ë¹ ë¥¸ ì‹œì‘

### 1. ë°°ì¹˜ íŒŒì¼ë¡œ ì‹¤í–‰ (ê¶Œì¥)

```bash
# í¬ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (ì½˜ì†” ì°½ì—ì„œ)
6_FT_ëª¨ë‹ˆí„°ë§_ì‹œì‘.bat

# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
6_FT_ëª¨ë‹ˆí„°ë§_ë°±ê·¸ë¼ìš´ë“œ.bat
```

### 2. Pythonìœ¼ë¡œ ì§ì ‘ ì‹¤í–‰

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™”
venv\Scripts\activate

# ë‹¨ì¼ URL ëª¨ë‹ˆí„°ë§
python backend/scripts/monitor_ft.py

# ì—¬ëŸ¬ URL ë™ì‹œ ëª¨ë‹ˆí„°ë§
python backend/scripts/monitor_ft.py multi
```

### 3. ì¤‘ì§€ ë°©ë²•

- **í¬ê·¸ë¼ìš´ë“œ**: `Ctrl+C`
- **ë°±ê·¸ë¼ìš´ë“œ**: ì‘ì—… ê´€ë¦¬ìì—ì„œ `python.exe` í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ

## ì‚¬ìš© ì˜ˆì‹œ

### ë‹¨ì¼ URL ëª¨ë‹ˆí„°ë§

```python
from backend.data.collectors.stealth_web_crawler import StealthWebCrawler

# ì½œë°± í•¨ìˆ˜ ì •ì˜ (ìƒˆ ì½˜í…ì¸  ë°œê²¬ ì‹œ)
def on_new_content(data):
    print(f"ìƒˆ ì½˜í…ì¸  ë°œê²¬: {data['title']}")
    # ì—¬ê¸°ì„œ AI ë¶„ì„ íŠ¸ë¦¬ê±°

# í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
crawler = StealthWebCrawler(
    url="https://www.ft.com/content/1369a45e-e39b-4aaa-a347-b1800da7fd31",
    interval_minutes=3.0,      # 3ë¶„ ê°„ê²©
    variance_minutes=0.5,      # Â±30ì´ˆ ëœë¤
    callback=on_new_content
)

# ëª¨ë‹ˆí„°ë§ ì‹œì‘
await crawler.start_monitoring()
```

### ì—¬ëŸ¬ URL ë™ì‹œ ëª¨ë‹ˆí„°ë§

```python
from backend.data.collectors.stealth_web_crawler import MultiSiteMonitor

monitor = MultiSiteMonitor()

# ì‚¬ì´íŠ¸ ì¶”ê°€
monitor.add_site(
    url="https://www.ft.com/content/...",
    interval_minutes=3.0,
    callback=on_new_content
)

monitor.add_site(
    url="https://www.reuters.com/...",
    interval_minutes=5.0,
    callback=on_new_content
)

# ëª¨ë“  ì‚¬ì´íŠ¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘
await monitor.start_all()
```

## ì„¤ì • ì˜µì…˜

### StealthWebCrawler íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|--------|------|
| `url` | í•„ìˆ˜ | ëª¨ë‹ˆí„°ë§í•  URL |
| `interval_minutes` | 3.0 | ê¸°ë³¸ í¬ë¡¤ë§ ê°„ê²© (ë¶„) |
| `variance_minutes` | 0.5 | ëœë¤ í¸ì°¨ (Â±ê°’, ë¶„) |
| `proxy` | None | í”„ë¡ì‹œ ì„œë²„ (ì˜ˆ: "http://proxy:8080") |
| `callback` | None | ìƒˆ ì½˜í…ì¸  ë°œê²¬ ì‹œ í˜¸ì¶œí•  í•¨ìˆ˜ |

### User-Agent ëª©ë¡

ì‹œìŠ¤í…œì´ ì‚¬ìš©í•˜ëŠ” 5ê°€ì§€ ì‹¤ì œ ë¸Œë¼ìš°ì € User-Agent:

1. Chrome on Windows
2. Chrome on Mac
3. Firefox on Windows
4. Safari on Mac
5. Edge on Windows

## ë¡œê·¸ í™•ì¸

### ì‹¤ì‹œê°„ ë¡œê·¸ ë³´ê¸°

```bash
# Windows
type logs\ft_monitor.log

# ì‹¤ì‹œê°„ tail (PowerShell)
Get-Content logs\ft_monitor.log -Wait
```

### ë¡œê·¸ ë ˆë²¨

- `INFO`: í¬ë¡¤ë§ ì‹¤í–‰, ì½˜í…ì¸  ë³€ê²½ ê°ì§€
- `DEBUG`: ì½˜í…ì¸  ë³€ê²½ ì—†ìŒ (í•´ì‹œ ë™ì¼)
- `WARNING`: HTTP ì—ëŸ¬, DB ì €ì¥ ì‹¤íŒ¨
- `ERROR`: í¬ë¡¤ë§ ì‹¤íŒ¨, ì˜ˆì™¸ ë°œìƒ

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. HTTP 403 Forbidden

í”„ë¦¬ë¯¸ì—„ ì‚¬ì´íŠ¸ê°€ ì°¨ë‹¨í•œ ê²½ìš°:

```python
# í”„ë¡ì‹œ ì‚¬ìš©
crawler = StealthWebCrawler(
    url="...",
    proxy="http://proxy.example.com:8080"
)
```

### 2. Timeout ì—ëŸ¬

ë„¤íŠ¸ì›Œí¬ê°€ ëŠë¦° ê²½ìš°, ì†ŒìŠ¤ ì½”ë“œì—ì„œ timeout ê°’ ì¦ê°€:

```python
# stealth_web_crawler.py ì—ì„œ
timeout = aiohttp.ClientTimeout(total=60)  # 30 â†’ 60ì´ˆ
```

### 3. ì½˜í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨

ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë‹¤ë¥¸ ê²½ìš°, `_fetch_content()` ë©”ì„œë“œì—ì„œ selector ìˆ˜ì •:

```python
# íŠ¹ì • í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ì¶”ì¶œ
article = soup.find('div', class_='article-body')
```

### 4. DB ì €ì¥ ì‹¤íŒ¨

ì¤‘ë³µ ì½˜í…ì¸ ì¸ ê²½ìš° ì •ìƒ (ê²½ê³ ë§Œ í‘œì‹œ):

```
WARNING: Failed to save article (duplicate?): ...
```

## ê³ ê¸‰ ì„¤ì •

### AI ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì—°ë™

`backend/scripts/monitor_ft.py`ì˜ `on_new_content()` í•¨ìˆ˜ì—ì„œ:

```python
def on_new_content(data: dict):
    # AI ë¶„ì„ íŠ¸ë¦¬ê±°
    from backend.ai.intelligence.enhanced_news_pipeline import EnhancedNewsPipeline

    pipeline = EnhancedNewsPipeline()
    await pipeline.process_urgent_news(data)

    # íŠ¸ë ˆì´ë”© ì‹œê·¸ë„ ìƒì„±
    from backend.ai.mvp.war_room_mvp import WarRoomMVP

    war_room = WarRoomMVP()
    decision = await war_room.make_decision(
        news_context=data['content']
    )
```

### ìŠ¤ì¼€ì¤„ëŸ¬ í†µí•©

`backend/automation/scheduler.py`ì— ì¶”ê°€:

```python
def setup_schedules(self):
    # ê¸°ì¡´ ìŠ¤ì¼€ì¤„...

    # FT ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ì‹œìŠ¤í…œ ì‹œì‘ ì‹œ)
    schedule.every().day.at("00:00").do(self.start_ft_monitoring)
```

### í”„ë¡ì‹œ ì‚¬ìš©

í™˜ê²½ë³€ìˆ˜ë¡œ í”„ë¡ì‹œ ì„¤ì •:

```bash
# .envì— ì¶”ê°€
FT_MONITOR_PROXY=http://proxy.example.com:8080
```

```python
# monitor_ft.pyì—ì„œ ì½ê¸°
proxy = os.getenv('FT_MONITOR_PROXY')
crawler = StealthWebCrawler(url=url, proxy=proxy)
```

## ë³´ì•ˆ ë° ì£¼ì˜ì‚¬í•­

### âš ï¸ ë²•ì  ê³ ë ¤ì‚¬í•­

- **ì´ìš© ì•½ê´€ í™•ì¸**: í¬ë¡¤ë§ ì „ ì‚¬ì´íŠ¸ ì´ìš© ì•½ê´€(Terms of Service) í™•ì¸
- **robots.txt í™•ì¸**: í¬ë¡¤ë§ì´ í—ˆìš©ëœ ê²½ë¡œì¸ì§€ í™•ì¸
- **Rate Limiting**: ê³¼ë„í•œ ìš”ì²­ìœ¼ë¡œ ì„œë²„ì— ë¶€ë‹´ ì£¼ì§€ ì•Šê¸°
- **ì €ì‘ê¶Œ**: í¬ë¡¤ë§í•œ ì½˜í…ì¸ ì˜ ì €ì‘ê¶Œ ì¤€ìˆ˜

### ğŸ”’ ê°œì¸ì •ë³´ ë³´í˜¸

- User-Agent ë¡œí…Œì´ì…˜ìœ¼ë¡œ ê°œì¸ ì‹ë³„ ë°©ì§€
- ì¿ í‚¤ ì €ì¥ ì•ˆ í•¨ (ì„¸ì…˜ë§ˆë‹¤ ìƒˆë¡œ ì‹œì‘)
- í”„ë¡ì‹œ ì‚¬ìš© ì‹œ ìµëª…ì„± ë³´ì¥

### ğŸ“Š ìœ¤ë¦¬ì  í¬ë¡¤ë§

- **ìµœì†Œ ê°„ê²©**: 3ë¶„ ì´ìƒ (ì„œë²„ ë¶€ë‹´ ìµœì†Œí™”)
- **í—¤ë” í¬í•¨**: ì‹¤ì œ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ í–‰ë™
- **ì—ëŸ¬ ì²˜ë¦¬**: 403/429 ì‘ë‹µ ì‹œ ìë™ ì¤‘ì§€
- **ìºì‹±**: ë™ì¼ ì½˜í…ì¸ ëŠ” ì¤‘ë³µ ì €ì¥í•˜ì§€ ì•ŠìŒ

## ì„±ëŠ¥ ìµœì í™”

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

- **ë‹¨ì¼ URL**: ~50MB
- **10ê°œ URL ë™ì‹œ**: ~200MB
- **100ê°œ URL ë™ì‹œ**: ~1GB

### CPU ì‚¬ìš©ëŸ‰

- í¬ë¡¤ë§ ì¤‘: ~5-10%
- ëŒ€ê¸° ì¤‘: ~0%

### ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰

- í‰ê·  í˜ì´ì§€ í¬ê¸°: 200KB~1MB
- ì‹œê°„ë‹¹ íŠ¸ë˜í”½: ~20MB (3ë¶„ ê°„ê²© ê¸°ì¤€)

## FAQ

### Q: ë°±ì•…ê´€ ìœ íŠœë¸Œ ì˜ìƒë„ í¬ë¡¤ë§ ê°€ëŠ¥í•œê°€ìš”?

A: ë„¤, `yt-dlp`ê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì˜ìƒ í¬ë¡¤ëŸ¬ëŠ” ë³„ë„ë¡œ êµ¬í˜„ í•„ìš”:

```python
# backend/data/collectors/youtube_monitor.py ìƒì„± í•„ìš”
import yt_dlp

# ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¼ ëª¨ë‹ˆí„°ë§
ydl_opts = {'format': 'best'}
with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    info = ydl.extract_info(youtube_url, download=False)
```

### Q: ë‹¤ë¥¸ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ë„ ì¶”ê°€ ê°€ëŠ¥í•œê°€ìš”?

A: ë„¤, `MultiSiteMonitor`ë¡œ ì—¬ëŸ¬ ì‚¬ì´íŠ¸ ë™ì‹œ ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥í•©ë‹ˆë‹¤:

```python
monitor.add_site("https://www.reuters.com/...")
monitor.add_site("https://www.bloomberg.com/...")
monitor.add_site("https://www.wsj.com/...")
```

### Q: í¬ë¡¤ë§ ê°„ê²©ì„ ë” ì§§ê²Œ í•  ìˆ˜ ìˆë‚˜ìš”?

A: ê°€ëŠ¥í•˜ì§€ë§Œ ë¹„ê¶Œì¥. 1ë¶„ ì´í•˜ëŠ” ì„œë²„ì— ë¶€ë‹´ì„ ì£¼ê³  ì°¨ë‹¨ë  ìœ„í—˜ì´ ë†’ìŠµë‹ˆë‹¤.

### Q: VPNì´ í•„ìš”í•œê°€ìš”?

A: ì¼ë°˜ì ìœ¼ë¡œ ë¶ˆí•„ìš”í•˜ì§€ë§Œ, ì§€ì—­ ì œí•œ ì½˜í…ì¸ ëŠ” VPN/í”„ë¡ì‹œê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ë‹¤ìŒ ë‹¨ê³„

### 1. AI ë¶„ì„ ì—°ë™

[backend/api/intelligence_router.py](../backend/api/intelligence_router.py)ì™€ ì—°ë™í•˜ì—¬ ì‹¤ì‹œê°„ ë¶„ì„

### 2. ì•Œë¦¼ ì‹œìŠ¤í…œ

Discord/Telegram ë´‡ìœ¼ë¡œ ì¤‘ìš” ë‰´ìŠ¤ ì•Œë¦¼

### 3. íŠ¸ë ˆì´ë”© ìë™í™”

War Room MVPì™€ ì—°ë™í•˜ì—¬ ìë™ íŠ¸ë ˆì´ë”© ê²°ì •

### 4. ëŒ€ì‹œë³´ë“œ í†µí•©

í”„ë¡ íŠ¸ì—”ë“œì— ì‹¤ì‹œê°„ í¬ë¡¤ë§ ìƒíƒœ í‘œì‹œ

## ì°¸ê³  ìë£Œ

- [aiohttp ë¬¸ì„œ](https://docs.aiohttp.org/)
- [BeautifulSoup ë¬¸ì„œ](https://www.crummy.com/software/BeautifulSoup/)
- [Repository Pattern](../../backend/database/repository.py)
- [ë‰´ìŠ¤ í¬ë¡¤ëŸ¬](../../backend/news/news_crawler.py)

---

**ì‘ì„±ì¼**: 2026-01-21
**ë²„ì „**: 1.0.0
**ë¬¸ì˜**: AI Trading System Team
