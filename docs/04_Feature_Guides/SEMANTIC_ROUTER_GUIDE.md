# Semantic Router ê°€ì´ë“œ

## ê°œìš”

**Semantic Router**ëŠ” AI Trading Systemì˜ í† í° ì‚¬ìš©ëŸ‰ì„ ìµœì í™”í•˜ëŠ” 3ë‹¨ê³„ ë¼ìš°íŒ… ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### í•µì‹¬ ëª©í‘œ

- **í† í° ì‚¬ìš©ëŸ‰ 83% ì ˆê°**: 3,800 í† í°/ìš”ì²­ â†’ 650 í† í°/ìš”ì²­
- **ë¹„ìš© 72% ì ˆê°**: $330/ì›” â†’ $94/ì›” (1,000 ìš”ì²­/ì¼ ê¸°ì¤€)
- **ë™ì  ë„êµ¬ ì„ íƒ**: í•„ìš”í•œ ë„êµ¬ë§Œ ë¡œë“œ
- **ìµœì  ëª¨ë¸ ë¼ìš°íŒ…**: Intentì— ë§ëŠ” AI ëª¨ë¸ ìë™ ì„ íƒ

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
ì‚¬ìš©ì ì…ë ¥
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: Intent Classification                 â”‚
â”‚ - ê·œì¹™ ê¸°ë°˜ íŒ¨í„´ ë§¤ì¹­ (ë¬´ë£Œ, ë¹ ë¦„)               â”‚
â”‚ - ë˜ëŠ” Local LLM (ì„ íƒì )                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    Intent: news_analysis
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 2: Tool Group Selection                  â”‚
â”‚ - Intent â†’ Tool Groups ë§¤í•‘                    â”‚
â”‚ - í•„ìš”í•œ ë„êµ¬ë§Œ ë¡œë“œ (í‰ê·  5ê°œ vs ì „ì²´ 30ê°œ)     â”‚
â”‚ - Tool Definition ìºì‹±                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    Tool Groups: [News, Gemini]
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 3: Model Selection                       â”‚
â”‚ - Intent ê¸°ë°˜ ìµœì  ëª¨ë¸ ì„ íƒ                     â”‚
â”‚ - ë¹„ìš©/ì„±ëŠ¥ ê· í˜•                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    Model: gemini-1.5-flash
    â†“
API ìš”ì²­ ì‹¤í–‰
```

---

## ì£¼ìš” ê¸°ëŠ¥

### 1. Intent Classification

ì‚¬ìš©ì ì…ë ¥ì„ 7ê°€ì§€ Intentë¡œ ë¶„ë¥˜:

| Intent | ì„¤ëª… | ì˜ˆì‹œ |
|--------|------|------|
| `news_analysis` | ë‰´ìŠ¤/ê¸°ì‚¬ ë¶„ì„ | "ì‚¼ì„±ì „ì ìµœê·¼ ë‰´ìŠ¤ ë¶„ì„í•´ì¤˜" |
| `trading_execution` | ë§¤ë§¤ ì‹¤í–‰ | "ì‚¼ì„±ì „ì 10ì£¼ ë§¤ìˆ˜í•´ì¤˜" |
| `strategy_generation` | ì „ëµ ìƒì„±/ë°±í…ŒìŠ¤íŠ¸ | "ì´ë™í‰ê·  ì „ëµ ë§Œë“¤ì–´ì¤˜" |
| `market_research` | ì‹œì¥/ê¸°ì—… ì¡°ì‚¬ | "ë°˜ë„ì²´ ì‚°ì—… ë¶„ì„í•´ì¤˜" |
| `portfolio_management` | í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ | "ë‚´ ê³„ì¢Œ ì”ê³  í™•ì¸í•´ì¤˜" |
| `data_query` | ë°ì´í„° ì¡°íšŒ | "ì‚¼ì„±ì „ì í˜„ì¬ê°€ëŠ”?" |
| `general_query` | ì¼ë°˜ ì§ˆë¬¸ | "ì•ˆë…•í•˜ì„¸ìš”" |

### 2. Tool Group Selection

Intentì— ë”°ë¼ í•„ìš”í•œ Tool Groupsë§Œ ì„ íƒ:

```python
Intent.NEWS_ANALYSIS â†’ [
    "MarketData.News",      # ë‰´ìŠ¤ ê²€ìƒ‰/ìˆ˜ì§‘
    "Intelligence.Gemini"   # ë‰´ìŠ¤ ë¶„ì„
]

Intent.TRADING_EXECUTION â†’ [
    "Trading.KIS",          # KIS API ì£¼ë¬¸
    "Trading.Order",        # ì£¼ë¬¸ ê´€ë¦¬
    "Trading.Risk"          # ë¦¬ìŠ¤í¬ ê´€ë¦¬
]
```

**í† í° ì ˆê° íš¨ê³¼**:
- í˜„ì¬: 30ê°œ ë„êµ¬ Ã— 100í† í° = 3,000 í† í°
- ìµœì í™”: 5ê°œ ë„êµ¬ Ã— 100í† í° = 500 í† í°
- **ì ˆê°: 2,500 í† í° (83%)**

### 3. Model Selection

Intentë³„ ìµœì  AI ëª¨ë¸ ìë™ ì„ íƒ:

| Intent | ëª¨ë¸ | ì´ìœ  |
|--------|------|------|
| `news_analysis` | Gemini 1.5 Flash | ë‰´ìŠ¤ ë¶„ì„ íŠ¹í™”, ì €ë ´ |
| `trading_execution` | GPT-4o Mini | ë¹ ë¥¸ ì‘ë‹µ, ì•ˆì •ì„± |
| `strategy_generation` | GPT-4o | ê³ í’ˆì§ˆ ì „ëµ ìƒì„± |
| `market_research` | Claude Sonnet 4.5 | ê¸´ ì»¨í…ìŠ¤íŠ¸, ì‹¬ì¸µ ë¶„ì„ |
| `data_query` | Local LLM (Llama 3.2) | ê°„ë‹¨í•œ ì¿¼ë¦¬, ë¬´ë£Œ |

### 4. Tool Definition Caching

ë„êµ¬ ì •ì˜ë¥¼ ìºì‹±í•˜ì—¬ ì¤‘ë³µ ì „ì†¡ ë°©ì§€:

```python
# ì²« ìš”ì²­
tools = get_tools_for_intent(Intent.NEWS_ANALYSIS)  # 5ê°œ ë„êµ¬
cache_key = cache_tools(tools)  # "a3f8c2e9..."

# ì´í›„ ìš”ì²­ (ê°™ì€ Intent)
cached_tools = get_cached_tools(cache_key)  # ìºì‹œì—ì„œ ë¡œë“œ
# í† í° 90% ì ˆê°!
```

**ìºì‹œ íˆíŠ¸ ì‹œ ì ˆê°**:
- ì›ë³¸: 500 í† í°
- ìºì‹œ: 50 í† í°
- **ì ˆê°: 450 í† í° (90%)**

---

## ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ ì‚¬ìš©

```python
from backend.routing import SemanticRouter

# ë¼ìš°í„° ìƒì„±
router = SemanticRouter(
    use_local_llm_for_intent=False,  # Local LLM ì‚¬ìš© ì—¬ë¶€
    enable_caching=True,             # ìºì‹± í™œì„±í™”
    prefer_low_cost=False,           # ì €ë¹„ìš© ëª¨ë“œ
)

# ë¼ìš°íŒ… ì‹¤í–‰
result = await router.route("ì‚¼ì„±ì „ì ìµœê·¼ ë‰´ìŠ¤ ë¶„ì„í•´ì¤˜")

print(f"Intent: {result.intent}")
print(f"Model: {result.provider}/{result.model}")
print(f"Tools: {result.tool_count}ê°œ")
print(f"Estimated Tokens: {result.estimated_tokens}")
print(f"Estimated Cost: ${result.estimated_cost_usd:.6f}")
```

### ë¼ìš°íŒ… ê²°ê³¼ í™œìš©

```python
# ë¼ìš°íŒ… ê²°ê³¼ë¡œ AI API í˜¸ì¶œ
if result.provider == "openai":
    from openai import AsyncOpenAI
    client = AsyncOpenAI()

    response = await client.chat.completions.create(
        model=result.model,
        messages=[
            {"role": "system", "content": "You are a trading assistant."},
            {"role": "user", "content": user_input}
        ],
        tools=result.tools,  # ì„ íƒëœ ë„êµ¬ë§Œ ì „ì†¡
        max_tokens=result.model_config["max_tokens"],
        temperature=result.model_config["temperature"],
    )

elif result.provider == "gemini":
    # Gemini API í˜¸ì¶œ
    ...
```

### ì €ë¹„ìš© ëª¨ë“œ

ë¹„ìš©ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤:

```python
router = SemanticRouter(prefer_low_cost=True)

result = await router.route("ë³µì¡í•œ ì „ëµ ë§Œë“¤ì–´ì¤˜")
# ì¼ë°˜ ëª¨ë“œ: GPT-4o ($$$)
# ì €ë¹„ìš© ëª¨ë“œ: GPT-4o Mini ($)
```

### Local LLM for Intent Classification

ë¡œì»¬ LLMìœ¼ë¡œ Intent ë¶„ë¥˜ (ì™„ì „ ë¬´ë£Œ):

```python
# Ollama ì‹¤í–‰ í•„ìš”
# docker-compose up -d local-llm

router = SemanticRouter(use_local_llm_for_intent=True)
result = await router.route("ì‚¼ì„±ì „ì ë‰´ìŠ¤ ë¶„ì„í•´ì¤˜")
# Intent ë¶„ë¥˜ ë¹„ìš©: $0 (ë¬´ë£Œ!)
```

### í†µê³„ ì¡°íšŒ

```python
stats = router.get_statistics()

print(f"Total Routes: {stats['total_routes']}")
print(f"Tokens Saved: {stats['total_tokens_saved']:,}")
print(f"Cache Hit Rate: {stats['cache_stats']['hit_rate'] * 100:.1f}%")
```

---

## í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
cd D:\code\ai-trading-system
python -m backend.routing.test_semantic_router

# ì˜ˆìƒ ì¶œë ¥:
# âœ… Single route test passed!
# âœ… Batch routing test passed!
# âœ… Caching effect test passed!
# âœ… Low cost mode test passed!
# âœ… Statistics test passed!
#
# ğŸ’° Total Savings (1,000 requests/day):
#   Tokens: 2,500,000 (83%)
#   Cost: $236/month (72%)
```

---

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ì‹œë‚˜ë¦¬ì˜¤: í•˜ë£¨ 1,000 ìš”ì²­

| ë©”íŠ¸ë¦­ | ìµœì í™” ì „ | ìµœì í™” í›„ | ì ˆê° |
|--------|----------|----------|------|
| **í† í°/ìš”ì²­** | 3,800 | 650 | 83% |
| **ì¼ì¼ í† í°** | 3,800,000 | 650,000 | 83% |
| **ì¼ì¼ ë¹„ìš©** | $11.00 | $3.13 | 72% |
| **ì›”ê°„ ë¹„ìš©** | $330 | $94 | **$236 ì ˆê°** |
| **ì—°ê°„ ë¹„ìš©** | $3,960 | $1,128 | **$2,832 ì ˆê°** |

### ìºì‹± íš¨ê³¼

| ìš”ì²­ ìœ í˜• | í† í° | ë¹„ìš© | ì ˆê°ë¥  |
|----------|------|------|--------|
| ìºì‹œ ë¯¸ìŠ¤ (ì²« ìš”ì²­) | 500 | $0.00125 | 0% |
| ìºì‹œ íˆíŠ¸ (ì´í›„ ìš”ì²­) | 50 | $0.000125 | 90% |

**ìºì‹œ íˆíŠ¸ìœ¨ 80% ê°€ì • ì‹œ**:
- 200 ìš”ì²­ (ìºì‹œ ë¯¸ìŠ¤) Ã— 500 í† í° = 100,000 í† í°
- 800 ìš”ì²­ (ìºì‹œ íˆíŠ¸) Ã— 50 í† í° = 40,000 í† í°
- **ì´í•©: 140,000 í† í° (vs 500,000 í† í°) â†’ 72% ì ˆê°**

---

## í†µí•© ê°€ì´ë“œ

### FastAPI í†µí•©

```python
# backend/main.py
from fastapi import FastAPI
from backend.routing import get_semantic_router

app = FastAPI()
router = get_semantic_router(enable_caching=True)

@app.post("/api/chat")
async def chat(user_input: str):
    # ë¼ìš°íŒ…
    routing_result = await router.route(user_input)

    # AI API í˜¸ì¶œ (ì„ íƒëœ ëª¨ë¸ê³¼ ë„êµ¬ ì‚¬ìš©)
    response = await call_ai_api(
        provider=routing_result.provider,
        model=routing_result.model,
        tools=routing_result.tools,
        user_input=user_input,
    )

    return {
        "response": response,
        "routing": {
            "intent": routing_result.intent,
            "model": routing_result.model,
            "tokens": routing_result.estimated_tokens,
            "cost": routing_result.estimated_cost_usd,
        }
    }
```

### ì‹ í˜¸ ìƒì„± íŒŒì´í”„ë¼ì¸ í†µí•©

```python
# backend/services/signal_pipeline.py
from backend.routing import get_semantic_router

class SignalPipeline:
    def __init__(self):
        self.router = get_semantic_router(enable_caching=True)

    async def process_latest_news(self):
        # ë‰´ìŠ¤ ì¡°íšŒ
        news = get_unanalyzed_news()

        for article in news:
            # ìë™ ë¼ìš°íŒ… (ë‰´ìŠ¤ ë¶„ì„ â†’ Gemini)
            routing = await self.router.route(
                f"ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•´ì¤˜: {article.title}"
            )

            # Geminië¡œ ë¶„ì„ (ì €ë¹„ìš©)
            analysis = await analyze_with_gemini(article, routing.tools)

            # ì‹ í˜¸ ìƒì„±
            signal = self.generate_signal(analysis)
```

---

## í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env

# OpenAI
OPENAI_API_KEY=sk-...

# Gemini
GEMINI_API_KEY=...

# Claude
CLAUDE_API_KEY=sk-ant-...

# Semantic Router ì„¤ì •
SEMANTIC_ROUTER_USE_LOCAL_LLM=false      # Local LLM ì‚¬ìš©
SEMANTIC_ROUTER_ENABLE_CACHING=true      # ìºì‹± í™œì„±í™”
SEMANTIC_ROUTER_PREFER_LOW_COST=false    # ì €ë¹„ìš© ëª¨ë“œ
SEMANTIC_ROUTER_CACHE_TTL_HOURS=24       # ìºì‹œ ìœ íš¨ ì‹œê°„
```

---

## Local LLM ì„¤ì • (ì„ íƒì )

Intent ë¶„ë¥˜ë¥¼ ë¡œì»¬ LLMìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì™„ì „ ë¬´ë£Œ ë¼ìš°íŒ…:

### 1. Ollama ì„¤ì¹˜

```bash
# Docker Composeì— ì¶”ê°€
docker-compose up -d local-llm
```

### 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
docker exec -it ai-trading-local-llm ollama pull llama3.2:3b
# ë˜ëŠ”
docker exec -it ai-trading-local-llm ollama pull phi-3-mini
```

### 3. SemanticRouterì—ì„œ í™œì„±í™”

```python
router = SemanticRouter(use_local_llm_for_intent=True)
# Intent ë¶„ë¥˜ ë¹„ìš©: $0 (ë¬´ë£Œ!)
```

### ëª¨ë¸ ë¹„êµ

| ëª¨ë¸ | í¬ê¸° | VRAM | ì‘ë‹µ ì‹œê°„ | ì •í™•ë„ |
|------|------|------|----------|--------|
| Llama 3.2 3B | 3GB | 4GB | ~500ms | 85% |
| Phi-3 Mini | 2GB | 3GB | ~300ms | 80% |
| TinyLlama 1.1B | 1GB | 2GB | ~200ms | 70% |

**ê¶Œì¥**: Llama 3.2 3B (ì •í™•ë„ ìµœê³ )

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Q: ìºì‹œ íˆíŠ¸ìœ¨ì´ ë‚®ì•„ìš”

**A**: Intentê°€ ë‹¤ì–‘í•˜ë©´ ìºì‹œ íˆíŠ¸ìœ¨ì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

í•´ê²°:
```python
# ìºì‹œ TTL ëŠ˜ë¦¬ê¸°
from backend.utils.tool_cache import get_tool_cache

cache = get_tool_cache()
cache.ttl = timedelta(hours=48)  # 24ì‹œê°„ â†’ 48ì‹œê°„
```

### Q: Local LLMì´ ì—°ê²° ì•ˆ ë¼ìš”

**A**: Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸:

```bash
# ìƒíƒœ í™•ì¸
docker ps | grep local-llm

# ë¡œê·¸ í™•ì¸
docker logs ai-trading-local-llm

# ì¬ì‹œì‘
docker-compose restart local-llm
```

### Q: Intent ë¶„ë¥˜ê°€ ì •í™•í•˜ì§€ ì•Šì•„ìš”

**A**: ê·œì¹™ ê¸°ë°˜ íŒ¨í„´ ì¶”ê°€ ë˜ëŠ” Local LLM í™œì„±í™”:

```python
# íŒ¨í„´ ì¶”ê°€
from backend.routing.intent_classifier import IntentClassifier

classifier = IntentClassifier()
classifier.INTENT_PATTERNS[Intent.NEWS_ANALYSIS].append(r"ìƒˆë¡œìš´.*ë‰´ìŠ¤")

# ë˜ëŠ” Local LLM ì‚¬ìš©
router = SemanticRouter(use_local_llm_for_intent=True)
```

---

## ë‹¤ìŒ ë‹¨ê³„

1. **Skill Layer êµ¬í˜„**: Tool Groupsë¥¼ ì‹¤ì œ Skillë¡œ êµ¬í˜„
2. **Docker Sandbox ë¶„ë¦¬**: ë³´ì•ˆ ê°•í™”ë¥¼ ìœ„í•œ 3ê³„ì¸µ ë¶„ë¦¬
3. **Code Model Pattern**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìµœì í™”
4. **MCP Gateway**: ë™ì  ë„êµ¬ ë¡œë”© (ì„ íƒì )

ìì„¸í•œ ë‚´ìš©ì€ [ARCHITECTURE_INTEGRATION_PLAN.md](./ARCHITECTURE_INTEGRATION_PLAN.md)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

---

## ì°¸ê³  ìë£Œ

- [OpenAI Prompt Caching](https://platform.openai.com/docs/guides/prompt-caching)
- [Gemini API Pricing](https://ai.google.dev/pricing)
- [Claude API Pricing](https://www.anthropic.com/pricing)
- [Ollama Documentation](https://ollama.ai/docs)

---

## ë¼ì´ì„ ìŠ¤

MIT License

---

**ë¬¸ì˜**: AI Trading System Team
