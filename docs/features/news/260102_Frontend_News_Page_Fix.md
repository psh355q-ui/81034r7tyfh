# í”„ë¡ íŠ¸ì—”ë“œ ë‰´ìŠ¤ í˜ì´ì§€ ì˜¤ë¥˜ ìˆ˜ì • (2026-01-02)

## ë¬¸ì œ ìƒí™©

ë‰´ìŠ¤ í˜ì´ì§€(`http://localhost:3002/news`)ì—ì„œ 500 Internal Server Error ë°œìƒ
- API ì—”ë“œí¬ì¸íŠ¸: `/api/news/articles?actionable_only=true`
- í”„ë¡ íŠ¸ì—”ë“œê°€ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•¨

## ë°œê²¬ëœ ì˜¤ë¥˜

### 1. NewsArticle ëª¨ë¸ ì†ì„±ëª… ë¶ˆì¼ì¹˜

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
AttributeError: type object 'NewsArticle' has no attribute 'published_at'.
Did you mean: 'published_date'?
```

**ì›ì¸:**
- ì½”ë“œì—ì„œ `NewsArticle.published_at` ì‚¬ìš©
- ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ì€ `published_date` ì •ì˜

**ìœ„ì¹˜:**
- `backend/data/news_analyzer.py` (3ê³³)

### 2. GroundingSearchLog ëª¨ë¸ ì†ì„±ëª… ë¶ˆì¼ì¹˜

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
AttributeError: type object 'GroundingSearchLog' has no attribute 'created_at'
AttributeError: type object 'GroundingSearchLog' has no attribute 'cost_usd'
```

**ì›ì¸:**
- ì½”ë“œì—ì„œ `created_at`, `cost_usd` ì‚¬ìš©
- ì‹¤ì œ ëª¨ë¸ì€ `search_date`, `estimated_cost` ì •ì˜

**ìœ„ì¹˜:**
- `backend/api/emergency_router.py` (7ê³³)

### 3. ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ë¯¸ìƒì„±

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
sqlite3.OperationalError: no such column: news_articles.content
```

**ì›ì¸:**
- PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì— ë‰´ìŠ¤ ê´€ë ¨ í…Œì´ë¸”ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ
- SQLAlchemy ORMì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸”ì„ ì¡°íšŒí•˜ë ¤ ì‹œë„

---

## í•´ê²° ë°©ë²•

### 1. NewsArticle ì†ì„±ëª… ìˆ˜ì •

**íŒŒì¼:** `backend/data/news_analyzer.py`

**ìˆ˜ì • ë‚´ìš©:**

#### Line 402 - get_analyzed_articles()
```python
# BEFORE
return query.order_by(NewsArticle.published_at.desc()).limit(limit).all()

# AFTER
return query.order_by(NewsArticle.published_date.desc()).limit(limit).all()
```

#### Line 422 - get_ticker_news()
```python
# BEFORE
"published_at": article.published_at.isoformat() if article.published_at else None,

# AFTER
"published_at": article.published_date.isoformat() if article.published_date else None,
```

#### Line 438 - get_high_impact_news()
```python
# BEFORE
.order_by(NewsArticle.published_at.desc())

# AFTER
.order_by(NewsArticle.published_date.desc())
```

---

### 2. GroundingSearchLog ì†ì„±ëª… ìˆ˜ì •

**íŒŒì¼:** `backend/api/emergency_router.py`

**ìˆ˜ì • ë‚´ìš©:**

#### Line 124 - get_grounding_count_today()
```python
# BEFORE
func.date(GroundingSearchLog.created_at) == date.today()

# AFTER
func.date(GroundingSearchLog.search_date) == date.today()
```

#### Line 158 - track_grounding_search()
```python
# BEFORE
log = GroundingSearchLog(
    ticker=ticker.upper(),
    search_query=f"latest news about {ticker.upper()} stock",
    results_count=results_count,
    cost_usd=cost,
    emergency_trigger=emergency_trigger,
    was_emergency=emergency_trigger is not None
)

# AFTER
log = GroundingSearchLog(
    ticker=ticker.upper(),
    search_query=f"latest news about {ticker.upper()} stock",
    results_count=results_count,
    estimated_cost=cost,  # âœ… CHANGED
    emergency_trigger=emergency_trigger,
    was_emergency=emergency_trigger is not None
)
```

#### Lines 198, 201 - get_grounding_usage() (Today's usage)
```python
# BEFORE
today_data = db.query(
    func.count(GroundingSearchLog.id).label('count'),
    func.sum(GroundingSearchLog.cost_usd).label('cost'),
    func.count(func.distinct(GroundingSearchLog.ticker)).label('tickers')
).filter(
    func.date(GroundingSearchLog.created_at) == today
).first()

# AFTER
today_data = db.query(
    func.count(GroundingSearchLog.id).label('count'),
    func.sum(GroundingSearchLog.estimated_cost).label('cost'),  # âœ… CHANGED
    func.count(func.distinct(GroundingSearchLog.ticker)).label('tickers')
).filter(
    func.date(GroundingSearchLog.search_date) == today  # âœ… CHANGED
).first()
```

#### Lines 208, 211-212 - get_grounding_usage() (Month's usage)
```python
# BEFORE
month_data = db.query(
    func.count(GroundingSearchLog.id).label('count'),
    func.sum(GroundingSearchLog.cost_usd).label('cost'),
    func.count(func.distinct(GroundingSearchLog.ticker)).label('tickers')
).filter(
    extract('year', GroundingSearchLog.created_at) == now.year,
    extract('month', GroundingSearchLog.created_at) == now.month
).first()

# AFTER
month_data = db.query(
    func.count(GroundingSearchLog.id).label('count'),
    func.sum(GroundingSearchLog.estimated_cost).label('cost'),  # âœ… CHANGED
    func.count(func.distinct(GroundingSearchLog.ticker)).label('tickers')
).filter(
    extract('year', GroundingSearchLog.search_date) == now.year,  # âœ… CHANGED
    extract('month', GroundingSearchLog.search_date) == now.month  # âœ… CHANGED
).first()
```

#### Lines 269-270 - get_monthly_cost_report()
```python
# BEFORE
searches = db.query(GroundingSearchLog).filter(
    extract('year', GroundingSearchLog.created_at) == year,
    extract('month', GroundingSearchLog.created_at) == month
).all()

# AFTER
searches = db.query(GroundingSearchLog).filter(
    extract('year', GroundingSearchLog.search_date) == year,  # âœ… CHANGED
    extract('month', GroundingSearchLog.search_date) == month  # âœ… CHANGED
).all()
```

#### Line 283 - get_monthly_cost_report() (Cost calculation)
```python
# BEFORE
total_cost = sum(s.cost_usd for s in searches)

# AFTER
total_cost = sum(s.estimated_cost for s in searches)  # âœ… CHANGED
```

---

### 3. ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±

**í™˜ê²½:**
- PostgreSQL 5433 í¬íŠ¸ (localhost)
- ë°ì´í„°ë² ì´ìŠ¤: `ai_trading`
- ì‚¬ìš©ì: `postgres`

**ìƒì„± ìŠ¤í¬ë¦½íŠ¸:**
```python
from backend.database.models import Base, NewsArticle, NewsAnalysis, NewsTickerRelevance, AnalysisResult, GroundingSearchLog
from sqlalchemy import create_engine
import os
from dotenv import load_dotenv

load_dotenv()

db_url = f"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}"
engine = create_engine(db_url)

# Create all news-related tables
news_tables = [
    ('NewsArticle', NewsArticle),
    ('NewsAnalysis', NewsAnalysis),
    ('NewsTickerRelevance', NewsTickerRelevance),
    ('AnalysisResult', AnalysisResult),
    ('GroundingSearchLog', GroundingSearchLog),
]

for table_name, model_class in news_tables:
    model_class.__table__.create(bind=engine, checkfirst=True)
    print(f'âœ… {table_name} table ready')
```

**ìƒì„±ëœ í…Œì´ë¸”:**
1. âœ… `news_articles` (19ê°œ ì»¬ëŸ¼)
   - id, title, **content**, url, source, **published_date**, crawled_at, content_hash, author, summary
   - embedding, tags, tickers, sentiment_score, sentiment_label, source_category, metadata, processed_at, embedding_model

2. âœ… `news_analysis`
   - article_id (FK), sentiment_overall, impact_magnitude, trading_actionable, etc.

3. âœ… `news_ticker_relevance`
   - article_id (FK), ticker, relevance_score, sentiment_for_ticker

4. âœ… `analysis_results`
   - article_id (FK), agent_name, analysis_data, confidence_score, etc.

5. âœ… `grounding_search_log`
   - ticker, search_query, results_count, **search_date**, **estimated_cost**, emergency_trigger, was_emergency

---

## ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ ì •ì˜ (ì°¸ê³ )

### NewsArticle (models.py:66-95)
```python
class NewsArticle(Base):
    __tablename__ = 'news_articles'

    id = Column(Integer, primary_key=True, autoincrement=True)
    title = Column(String(500), nullable=False)
    content = Column(Text, nullable=False)  # âœ… EXISTS
    url = Column(String(1000), nullable=False, unique=True)
    source = Column(String(100), nullable=False)
    published_date = Column(DateTime, nullable=False)  # âœ… NOT published_at
    crawled_at = Column(DateTime, nullable=False, default=datetime.now)
    content_hash = Column(String(64), nullable=False, unique=True, index=True)
    author = Column(String(200), nullable=True)
    summary = Column(Text, nullable=True)

    # NLP & Embedding Fields
    embedding = Column(ARRAY(Float), nullable=True)
    tags = Column(ARRAY(String), nullable=True)
    tickers = Column(ARRAY(String), nullable=True)
    sentiment_score = Column(Float, nullable=True)
    sentiment_label = Column(String(20), nullable=True)
    source_category = Column(String(50), nullable=True)
    metadata_ = Column("metadata", JSONB, nullable=True)
    processed_at = Column(DateTime, nullable=True)
    embedding_model = Column(String(100), nullable=True)
```

### GroundingSearchLog (models.py:300-315)
```python
class GroundingSearchLog(Base):
    __tablename__ = 'grounding_search_log'

    id = Column(Integer, primary_key=True, autoincrement=True)
    ticker = Column(String(20), nullable=False, index=True)
    search_query = Column(Text, nullable=False)
    results_count = Column(Integer, nullable=False, default=0)
    search_date = Column(DateTime, nullable=False, default=datetime.now, index=True)  # âœ… NOT created_at
    estimated_cost = Column(Float, nullable=False, default=0.0)  # âœ… NOT cost_usd
    emergency_trigger = Column(String(100), nullable=True)
    was_emergency = Column(Boolean, nullable=False, default=False)

    # Metadata
    user_id = Column(String(100), nullable=True)
    session_id = Column(String(100), nullable=True)
```

---

## ìˆ˜ì • íŒŒì¼ ìš”ì•½

### ìˆ˜ì •ëœ íŒŒì¼ (2ê°œ)
1. `backend/data/news_analyzer.py`
   - Line 402: `published_at` â†’ `published_date`
   - Line 422: `published_at` â†’ `published_date`
   - Line 438: `published_at` â†’ `published_date`

2. `backend/api/emergency_router.py`
   - Line 124: `created_at` â†’ `search_date`
   - Line 158: `cost_usd` â†’ `estimated_cost`
   - Line 198: `cost_usd` â†’ `estimated_cost`
   - Line 201: `created_at` â†’ `search_date`
   - Line 208: `cost_usd` â†’ `estimated_cost`
   - Line 211-212: `created_at` â†’ `search_date` (2ê³³)
   - Line 269-270: `created_at` â†’ `search_date` (2ê³³)
   - Line 283: `cost_usd` â†’ `estimated_cost`

### ë³€ê²½ ì—†ìŒ
- `backend/database/models.py` - ëª¨ë¸ ì •ì˜ëŠ” ì´ë¯¸ ì˜¬ë°”ë¦„
- `backend/api/news_router.py` - ì—”ë“œí¬ì¸íŠ¸ëŠ” ì •ìƒ

---

## ê²€ì¦ ê²°ê³¼

### 1. ì½”ë“œ ìˆ˜ì • ê²€ì¦
```bash
# news_analyzer.py í™•ì¸
grep -n "published_at\|published_date" backend/data/news_analyzer.py

# emergency_router.py í™•ì¸
grep -n "created_at\|search_date\|cost_usd\|estimated_cost" backend/api/emergency_router.py
```

âœ… ëª¨ë“  ì†ì„±ëª…ì´ ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì •ë¨

### 2. ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ê²€ì¦
```python
import psycopg2
conn = psycopg2.connect(host='localhost', port=5433, user='postgres', password='Qkqhdi1!', database='ai_trading')
cursor = conn.cursor()

cursor.execute("SELECT column_name FROM information_schema.columns WHERE table_name='news_articles' ORDER BY ordinal_position")
columns = [row[0] for row in cursor.fetchall()]

print(f"âœ… news_articles table has {len(columns)} columns")
print(f"   content column: {'âœ… EXISTS' if 'content' in columns else 'âŒ MISSING'}")
print(f"   published_date column: {'âœ… EXISTS' if 'published_date' in columns else 'âŒ MISSING'}")
```

**ê²°ê³¼:**
```
âœ… news_articles table has 19 columns
   content column: âœ… EXISTS
   published_date column: âœ… EXISTS
```

### 3. API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
```bash
# ë‰´ìŠ¤ ëª©ë¡ ì¡°íšŒ (actionable_only=false)
curl http://localhost:8001/api/news/articles?limit=50&hours=24&actionable_only=false

# ë‰´ìŠ¤ ëª©ë¡ ì¡°íšŒ (actionable_only=true)
curl http://localhost:8001/api/news/articles?limit=50&hours=24&actionable_only=true

# Emergency ìƒíƒœ í™•ì¸
curl http://localhost:8001/api/emergency/status

# Grounding ì‚¬ìš©ëŸ‰ í™•ì¸
curl http://localhost:8001/api/emergency/grounding/usage
```

âœ… ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸ ì •ìƒ ì‘ë™

---

## ì¬ë°œ ë°©ì§€ ë°©ì•ˆ

### 1. íƒ€ì… ì²´í¬ ê°•í™”
```python
# backend/data/news_analyzer.py
from typing import List, Dict, Any
from backend.database.models import NewsArticle

def get_analyzed_articles(db: Session, limit: int, sentiment: str = None, actionable_only: bool = False) -> List[NewsArticle]:
    """íƒ€ì… íŒíŠ¸ë¥¼ ëª…ì‹œí•˜ì—¬ IDEì—ì„œ ìë™ì™„ì„± ì§€ì›"""
    # ...
```

### 2. ëª¨ë¸ ì†ì„± ìƒìˆ˜í™”
```python
# backend/database/models.py
class NewsArticle(Base):
    __tablename__ = 'news_articles'

    # Column constants for autocomplete
    COLUMN_PUBLISHED_DATE = 'published_date'  # NOT published_at
    COLUMN_CONTENT = 'content'

    published_date = Column(DateTime, nullable=False)
    content = Column(Text, nullable=False)
```

### 3. í†µí•© í…ŒìŠ¤íŠ¸ ì¶”ê°€
```python
# backend/tests/test_news_api.py
def test_news_articles_api():
    """ë‰´ìŠ¤ API ì—”ë“œí¬ì¸íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸"""
    response = client.get("/api/news/articles?limit=10&actionable_only=true")
    assert response.status_code == 200
    data = response.json()
    assert isinstance(data, list)
```

### 4. ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ìë™í™”
```bash
# Alembic ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ê°œì„ 
cd backend
python -m alembic revision --autogenerate -m "Add news tables"
python -m alembic upgrade head
```

---

## ì°¸ê³  ìë£Œ

### ê´€ë ¨ íŒŒì¼
- `backend/database/models.py` - ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ ì •ì˜
- `backend/data/news_analyzer.py` - ë‰´ìŠ¤ ë¶„ì„ ë¡œì§
- `backend/api/news_router.py` - ë‰´ìŠ¤ API ë¼ìš°í„°
- `backend/api/emergency_router.py` - Emergency ìƒíƒœ API

### ê´€ë ¨ ë¬¸ì„œ
- `docs/260101_Claude_Features_Analysis.md` - Claude ì‹ ê¸°ëŠ¥ ë¶„ì„
- `docs/260102_War_Room_MVP_Skills_Migration_Plan.md` - War Room MVP Skills ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš

### í™˜ê²½ ì„¤ì •
- `.env` - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´
  - `DB_HOST=localhost`
  - `DB_PORT=5433`
  - `DB_NAME=ai_trading`
  - `DB_USER=postgres`
  - `DB_PASSWORD=Qkqhdi1!`

---

## íƒ€ì„ë¼ì¸

| ì‹œê°„ | ì‘ì—… | ìƒíƒœ |
|------|------|------|
| 11:30 | ë‰´ìŠ¤ í˜ì´ì§€ 500 ì˜¤ë¥˜ ë°œê²¬ | âŒ |
| 11:35 | NewsArticle.published_at ì˜¤ë¥˜ ì‹ë³„ | ğŸ” |
| 11:40 | news_analyzer.py 3ê³³ ìˆ˜ì • ì™„ë£Œ | âœ… |
| 11:45 | GroundingSearchLog ì˜¤ë¥˜ ì‹ë³„ | ğŸ” |
| 11:50 | emergency_router.py 7ê³³ ìˆ˜ì • ì™„ë£Œ | âœ… |
| 11:55 | ë°±ì—”ë“œ ì¬ì‹œì‘ í›„ DB í…Œì´ë¸” ë¯¸ìƒì„± ë°œê²¬ | âŒ |
| 12:00 | PostgreSQL ì—°ê²° í™•ì¸ (port 5433) | âœ… |
| 12:05 | ë‰´ìŠ¤ ê´€ë ¨ í…Œì´ë¸” 5ê°œ ìƒì„± ì™„ë£Œ | âœ… |
| 12:10 | ë°±ì—”ë“œ ì¬ì‹œì‘ ë° ê²€ì¦ ì™„ë£Œ | âœ… |
| 12:15 | í”„ë¡ íŠ¸ì—”ë“œ ë‰´ìŠ¤ í˜ì´ì§€ ì •ìƒ ì‘ë™ | âœ… |

---

## ìµœì¢… ìƒíƒœ

### âœ… í•´ê²° ì™„ë£Œ
- [x] NewsArticle ì†ì„±ëª… ë¶ˆì¼ì¹˜ ìˆ˜ì • (3ê³³)
- [x] GroundingSearchLog ì†ì„±ëª… ë¶ˆì¼ì¹˜ ìˆ˜ì • (7ê³³)
- [x] PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± (5ê°œ)
- [x] ë°±ì—”ë“œ API ì •ìƒ ì‘ë™ í™•ì¸
- [x] í”„ë¡ íŠ¸ì—”ë“œ ë‰´ìŠ¤ í˜ì´ì§€ ì •ìƒ í‘œì‹œ

### ğŸ‰ ì„±ê³µ ê¸°ì¤€ ì¶©ì¡±
- âœ… `/api/news/articles` ì—”ë“œí¬ì¸íŠ¸ 200 OK
- âœ… `/api/emergency/status` ì—”ë“œí¬ì¸íŠ¸ ì •ìƒ
- âœ… `/api/emergency/grounding/usage` ì—”ë“œí¬ì¸íŠ¸ ì •ìƒ
- âœ… í”„ë¡ íŠ¸ì—”ë“œ ë‰´ìŠ¤ í˜ì´ì§€ ë¡œë”© ì„±ê³µ
- âœ… ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì¼ì¹˜

---

## ì¶”ê°€ ê°œì„ : ë‰´ìŠ¤ ë‚ ì§œ í‘œì‹œ ê¸°ëŠ¥ (2026-01-02 13:00)

### ìš”êµ¬ì‚¬í•­
ë‰´ìŠ¤ ëª©ë¡ì—ì„œ RSS í¬ë¡¤ë§ìœ¼ë¡œ ë°›ì•„ì˜¨ ë‰´ìŠ¤ì˜ ì •í™•í•œ ë‚ ì§œ/ì‹œê°„ì„ í‘œì‹œí•˜ì—¬ ë‚˜ì¤‘ì— í™•ì¸í•˜ê¸° í¸í•˜ë„ë¡ ê°œì„ 

### êµ¬í˜„ ë‚´ìš©

#### 1. ë‚ ì§œ í¬ë§·íŒ… í•¨ìˆ˜ ì¶”ê°€

**íŒŒì¼:** `frontend/src/services/newsService.ts`

**ì¶”ê°€ëœ í•¨ìˆ˜:**

```typescript
/**
 * ì •í™•í•œ ë‚ ì§œ/ì‹œê°„ í¬ë§·íŒ…
 * ì˜ˆ: "2026-01-02 11:30"
 */
export const formatDateTime = (dateString: string): string => {
  const date = new Date(dateString);
  const year = date.getFullYear();
  const month = String(date.getMonth() + 1).padStart(2, '0');
  const day = String(date.getDate()).padStart(2, '0');
  const hours = String(date.getHours()).padStart(2, '0');
  const minutes = String(date.getMinutes()).padStart(2, '0');

  return `${year}-${month}-${day} ${hours}:${minutes}`;
};

/**
 * í•œêµ­ì–´ ë‚ ì§œ í¬ë§·íŒ…
 * ì˜ˆ: "2026ë…„ 1ì›” 2ì¼ ì˜¤ì „ 11:30"
 */
export const formatDateTimeKorean = (dateString: string): string => {
  const date = new Date(dateString);
  const year = date.getFullYear();
  const month = date.getMonth() + 1;
  const day = date.getDate();
  const hours = date.getHours();
  const minutes = String(date.getMinutes()).padStart(2, '0');
  const ampm = hours < 12 ? 'ì˜¤ì „' : 'ì˜¤í›„';
  const displayHours = hours % 12 || 12;

  return `${year}ë…„ ${month}ì›” ${day}ì¼ ${ampm} ${displayHours}:${minutes}`;
};
```

#### 2. ë‰´ìŠ¤ ëª©ë¡ í™”ë©´ ì—…ë°ì´íŠ¸

**íŒŒì¼:** `frontend/src/pages/NewsAggregation.tsx`

**ë³€ê²½ ì „:**
```tsx
<span>{article.published_at ? getTimeAgo(article.published_at) : 'ë‚ ì§œ ì—†ìŒ'}</span>
```

**ë³€ê²½ í›„:**
```tsx
{article.published_at ? (
  <span
    title={formatDateTimeKorean(article.published_at)}
    className="cursor-help"
  >
    {getTimeAgo(article.published_at)} ({formatDateTimeKorean(article.published_at)})
  </span>
) : (
  <span>ë‚ ì§œ ì—†ìŒ</span>
)}
```

#### 3. í‘œì‹œ í˜•ì‹

**ìƒëŒ€ ì‹œê°„ + ì •í™•í•œ ë‚ ì§œ í•¨ê»˜ í‘œì‹œ:**
- "3ì‹œê°„ ì „ (2026ë…„ 1ì›” 2ì¼ ì˜¤ì „ 11:30)"
- "1ì¼ ì „ (2026ë…„ 1ì›” 1ì¼ ì˜¤í›„ 2:15)"
- "12ë¶„ ì „ (2026ë…„ 1ì›” 2ì¼ ì˜¤í›„ 12:48)"

**íˆ´íŒ ê¸°ëŠ¥:**
- ë‚ ì§œ í…ìŠ¤íŠ¸ì— ë§ˆìš°ìŠ¤ ì˜¤ë²„ ì‹œ ì •í™•í•œ ë‚ ì§œ íˆ´íŒ í‘œì‹œ
- `cursor-help` í´ë˜ìŠ¤ë¡œ ë¬¼ìŒí‘œ ì»¤ì„œ í‘œì‹œ

### ì‚¬ìš©ì ê²½í—˜ ê°œì„ 

1. âœ… **ìƒëŒ€ ì‹œê°„ ìœ ì§€**: "3ì‹œê°„ ì „" ê°™ì€ ì§ê´€ì ì¸ í‘œí˜„ ìœ ì§€
2. âœ… **ì •í™•í•œ ë‚ ì§œ ì¶”ê°€**: ê´„í˜¸ ì•ˆì— ì •í™•í•œ ë‚ ì§œ/ì‹œê°„ í‘œì‹œ
3. âœ… **í•œêµ­ì–´ í¬ë§·**: "2026ë…„ 1ì›” 2ì¼ ì˜¤ì „ 11:30" í˜•ì‹ìœ¼ë¡œ ì½ê¸° ì‰½ê²Œ
4. âœ… **íˆ´íŒ ì§€ì›**: ë§ˆìš°ìŠ¤ ì˜¤ë²„ ì‹œ ì •í™•í•œ ë‚ ì§œ ì¬í™•ì¸ ê°€ëŠ¥

### ì¥ì 

- **ì •ë³´ ì œê³µ**: ë‰´ìŠ¤ê°€ ì–¸ì œ ë°œí–‰ë˜ì—ˆëŠ”ì§€ ì •í™•íˆ ì•Œ ìˆ˜ ìˆìŒ
- **ê²€ìƒ‰ í¸ì˜ì„±**: íŠ¹ì • ë‚ ì§œ/ì‹œê°„ëŒ€ì˜ ë‰´ìŠ¤ ì°¾ê¸° ìš©ì´
- **íˆìŠ¤í† ë¦¬ ì¶”ì **: ê³¼ê±° ë‰´ìŠ¤ í™•ì¸ ì‹œ ì •í™•í•œ ì‹œì  íŒŒì•… ê°€ëŠ¥
- **UX ê°œì„ **: ìƒëŒ€ ì‹œê°„ê³¼ ì ˆëŒ€ ì‹œê°„ ëª¨ë‘ ì œê³µí•˜ì—¬ ì‚¬ìš©ì ì„ íƒê¶Œ ì œê³µ

### ìˆ˜ì • íŒŒì¼ ìš”ì•½

1. âœ… `frontend/src/services/newsService.ts`
   - `formatDateTime()` í•¨ìˆ˜ ì¶”ê°€
   - `formatDateTimeKorean()` í•¨ìˆ˜ ì¶”ê°€

2. âœ… `frontend/src/pages/NewsAggregation.tsx`
   - `formatDateTimeKorean` import ì¶”ê°€
   - ArticleItem ì»´í¬ë„ŒíŠ¸ ë‚ ì§œ í‘œì‹œ ê°œì„ 

---

**ì‘ì„±ì¼:** 2026-01-02
**ì‘ì„±ì:** AI Trading System Development Team
**ê´€ë ¨ ì´ìŠˆ:** Frontend News Page 500 Error + Date Display Enhancement
**ìš°ì„ ìˆœìœ„:** P0 (Critical - Production Blocker) â†’ P1 (Enhancement)
**ìƒíƒœ:** âœ… Resolved + Enhanced
