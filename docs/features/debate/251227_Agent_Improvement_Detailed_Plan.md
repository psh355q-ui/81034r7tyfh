# Agent ê°œì„  ìƒì„¸ ê³„íšì„œ

**ì‘ì„±ì¼**: 2025-12-27
**ëª©ì **: ê° Agentì˜ êµ¬ì²´ì ì¸ ê°œì„  ë°©í–¥ê³¼ êµ¬í˜„ ë°©ë²• ì •ë¦¬
**ì°¸ê³ **: 251227_Agent_Analysis_Report.md ê¸°ë°˜

---

## ğŸ“‹ ëª©ì°¨

1. [News Agent ê°œì„ ](#1-news-agent-ê°œì„ )
2. [Trader Agent ê°œì„ ](#2-trader-agent-ê°œì„ )
3. [Risk Agent ê°œì„ ](#3-risk-agent-ê°œì„ )
4. [Macro Agent ê°œì„ ](#4-macro-agent-ê°œì„ )
5. [Institutional Agent ê°œì„ ](#5-institutional-agent-ê°œì„ )
6. [Analyst Agent ê°œì„ ](#6-analyst-agent-ê°œì„ )
7. [ChipWar Agent ê°œì„ ](#7-chipwar-agent-ê°œì„ )
8. [êµ¬í˜„ ìš°ì„ ìˆœìœ„](#8-êµ¬í˜„-ìš°ì„ ìˆœìœ„)

---

## 1. News Agent ê°œì„ 

### âœ… ì™„ë£Œëœ ê°œì„  (2025-12-27)

#### ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„
```python
def _analyze_temporal_trend(self, news_summaries: List[Dict]) -> Dict[str, Any]:
    """
    ë‰´ìŠ¤ë¥¼ ì‹œê°„ëŒ€ë³„ë¡œ ë¶„ì„í•˜ì—¬ ê°ì„± ë³€í™” ì¶”ì 

    Returns:
        - trend: IMPROVING/DETERIORATING/STABLE
        - recent_sentiment: ìµœê·¼ 3ì¼ í‰ê·  ê°ì„±
        - older_sentiment: 4-15ì¼ í‰ê·  ê°ì„±
        - sentiment_change: ë³€í™”ëŸ‰
        - risk_trajectory: INCREASING/DECREASING/NEUTRAL
    """
```

**íš¨ê³¼**:
- ë‹¨ìˆœ ìŠ¤ëƒ…ìƒ·ì´ ì•„ë‹Œ **íŠ¸ë Œë“œ ê¸°ë°˜ íŒë‹¨**
- ìœ„í—˜ë„ê°€ ì¦ê°€í•˜ëŠ”ì§€ ê°ì†Œí•˜ëŠ”ì§€ ëª…í™•í•˜ê²Œ íŒŒì•…
- IMPROVING íŠ¸ë Œë“œ ì‹œ BUY ì‹ í˜¸ ê°•í™” (+0.1 boost)
- DETERIORATING íŠ¸ë Œë“œ ì‹œ SELL ì‹ í˜¸ ê°•í™” (-0.1 boost)

### ğŸ”„ ì¶”ê°€ ê°œì„  í•„ìš” í•­ëª©

#### 1.1 ë‰´ìŠ¤ ì†ŒìŠ¤ ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜

**í˜„ì¬ ë¬¸ì œ**:
- ëª¨ë“  ë‰´ìŠ¤ë¥¼ ë™ë“±í•˜ê²Œ ì·¨ê¸‰
- Bloomberg, Reutersì™€ Unknown blogì˜ ê°€ì¤‘ì¹˜ê°€ ê°™ìŒ

**ê°œì„  ë°©í–¥**:
```python
SOURCE_CREDIBILITY = {
    "Bloomberg": 1.0,
    "Reuters": 1.0,
    "WSJ": 0.95,
    "CNBC": 0.9,
    "Yahoo Finance": 0.8,
    "Seeking Alpha": 0.7,
    "Unknown": 0.5
}

def _calculate_weighted_sentiment(self, news_summaries: List[Dict]) -> float:
    """ë‰´ìŠ¤ ì†ŒìŠ¤ ì‹ ë¢°ë„ë¥¼ ë°˜ì˜í•œ ê°€ì¤‘ í‰ê· """
    weighted_sum = 0
    total_weight = 0

    for news in news_summaries:
        source = news.get('source', 'Unknown')
        credibility = SOURCE_CREDIBILITY.get(source, 0.5)
        sentiment = news.get('sentiment', 0)

        weighted_sum += sentiment * credibility
        total_weight += credibility

    return weighted_sum / total_weight if total_weight > 0 else 0
```

#### 1.2 ì‹œê°„ ê°ì‡  (Temporal Decay)

**í˜„ì¬ ë¬¸ì œ**:
- 15ì¼ ì „ ë‰´ìŠ¤ì™€ ì˜¤ëŠ˜ ë‰´ìŠ¤ì˜ ì¤‘ìš”ë„ê°€ ê°™ìŒ

**ê°œì„  ë°©í–¥**:
```python
import math

def _apply_temporal_decay(self, news_summaries: List[Dict]) -> List[Dict]:
    """ì‹œê°„ì— ë”°ë¼ ë‰´ìŠ¤ ì¤‘ìš”ë„ ê°ì†Œ"""
    now = datetime.now()

    for news in news_summaries:
        published_date = news.get('published_at', now)
        days_ago = (now - published_date).days

        # ì§€ìˆ˜ ê°ì‡ : decay_factor = e^(-0.1 * days)
        # 0ì¼: 1.0, 7ì¼: 0.5, 15ì¼: 0.22
        decay_factor = math.exp(-0.1 * days_ago)

        news['weight'] = decay_factor
        news['decayed_sentiment'] = news['sentiment'] * decay_factor

    return news_summaries
```

**íš¨ê³¼**:
- ìµœê·¼ ë‰´ìŠ¤ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
- ì˜¤ë˜ëœ ë‰´ìŠ¤ëŠ” ë°°ê²½ ì •ë³´ë¡œë§Œ í™œìš©

#### 1.3 ê°ì„± ì ìˆ˜ ì‹ ë¢°êµ¬ê°„

**í˜„ì¬ ë¬¸ì œ**:
- Geminiê°€ ë°˜í™˜í•œ ê°ì„± ì ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ì‹ ë¢°
- ë‰´ìŠ¤ ê°œìˆ˜ê°€ ì ì„ ë•Œ ì‹ ë¢°ë„ ë‚®ìŒ

**ê°œì„  ë°©í–¥**:
```python
def _calculate_confidence_interval(self, news_count: int, sentiment_score: float) -> tuple:
    """
    ë‰´ìŠ¤ ê°œìˆ˜ë¥¼ ê³ ë ¤í•œ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°

    Returns:
        (lower_bound, upper_bound, confidence_level)
    """
    import numpy as np

    # í‘œë³¸ í¬ê¸°ì— ë”°ë¥¸ í‘œì¤€ì˜¤ì°¨ ê³„ì‚°
    # SE = Ïƒ / âˆšn (Ïƒ=0.3 ê°€ì •)
    standard_error = 0.3 / np.sqrt(news_count) if news_count > 0 else 1.0

    # 95% ì‹ ë¢°êµ¬ê°„ (z=1.96)
    margin_of_error = 1.96 * standard_error

    lower_bound = max(-1.0, sentiment_score - margin_of_error)
    upper_bound = min(1.0, sentiment_score + margin_of_error)

    # ë‰´ìŠ¤ ê°œìˆ˜ì— ë”°ë¥¸ ì‹ ë¢°ë„
    if news_count >= 20:
        confidence_level = 0.95
    elif news_count >= 10:
        confidence_level = 0.85
    elif news_count >= 5:
        confidence_level = 0.70
    else:
        confidence_level = 0.50

    return (lower_bound, upper_bound, confidence_level)
```

#### 1.4 ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„

**í˜„ì¬ ë¬¸ì œ**:
- ì‹¤ì , ê·œì œ, M&A, ì œí’ˆ ë°œí‘œ ë“±ì„ êµ¬ë¶„í•˜ì§€ ì•ŠìŒ

**ê°œì„  ë°©í–¥**:
```python
NEWS_CATEGORIES = {
    "EARNINGS": {
        "keywords": ["earnings", "revenue", "profit", "EPS"],
        "impact_multiplier": 1.5  # ì‹¤ì ì€ ì¤‘ìš”ë„ 1.5ë°°
    },
    "REGULATION": {
        "keywords": ["SEC", "lawsuit", "investigation", "fine"],
        "impact_multiplier": 1.3
    },
    "PRODUCT": {
        "keywords": ["launch", "release", "announced", "unveil"],
        "impact_multiplier": 1.1
    },
    "M&A": {
        "keywords": ["merger", "acquisition", "buyout", "takeover"],
        "impact_multiplier": 1.4
    }
}

def _categorize_news(self, title: str, content: str) -> str:
    """ë‰´ìŠ¤ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
    text = (title + " " + content).lower()

    for category, info in NEWS_CATEGORIES.items():
        if any(kw in text for kw in info['keywords']):
            return category

    return "GENERAL"
```

---

## 2. Trader Agent ê°œì„ 

### ğŸ¯ ìµœìš°ì„  ê°œì„  í•­ëª©

#### 2.1 ë©€í‹° íƒ€ì„í”„ë ˆì„ ë¶„ì„

**êµ¬í˜„ ë°©ë²•**:
```python
async def analyze_multi_timeframe(self, ticker: str) -> Dict:
    """
    ì¼ë´‰, ì£¼ë´‰, ì›”ë´‰ ë™ì‹œ ë¶„ì„

    ì „ëµ:
    - ì›”ë´‰ ì¶”ì„¸ í™•ì¸ â†’ ì£¼ë´‰ ì¶”ì„¸ í™•ì¸ â†’ ì¼ë´‰ ì§„ì… íƒ€ì´ë°
    - ìƒìœ„ íƒ€ì„í”„ë ˆì„ ì¶”ì„¸ì™€ ì¼ì¹˜í•  ë•Œë§Œ ê°•í•œ ì‹ í˜¸
    """
    # 1. ì›”ë´‰ ë°ì´í„° (20ê°œì›”)
    monthly_data = await self._fetch_ohlcv(ticker, timeframe='1mo', limit=20)
    monthly_trend = self._analyze_trend(monthly_data)  # UPTREND/DOWNTREND/SIDEWAYS

    # 2. ì£¼ë´‰ ë°ì´í„° (52ì£¼)
    weekly_data = await self._fetch_ohlcv(ticker, timeframe='1wk', limit=52)
    weekly_trend = self._analyze_trend(weekly_data)

    # 3. ì¼ë´‰ ë°ì´í„° (100ì¼)
    daily_data = await self._fetch_ohlcv(ticker, timeframe='1d', limit=100)
    daily_signals = self._analyze_daily(daily_data)

    # 4. íƒ€ì„í”„ë ˆì„ ì •ë ¬ë„ í™•ì¸
    alignment_score = self._calculate_alignment(monthly_trend, weekly_trend, daily_signals['trend'])

    # 5. ì‹ í˜¸ ê°•ë„ ì¡°ì •
    if alignment_score > 0.8:  # ëª¨ë“  íƒ€ì„í”„ë ˆì„ ì¼ì¹˜
        confidence_boost = 0.2
        reasoning = f"ê°•í•œ ì‹ í˜¸: ì›”ë´‰({monthly_trend}), ì£¼ë´‰({weekly_trend}), ì¼ë´‰({daily_signals['trend']}) ì •ë ¬"
    elif alignment_score < 0.3:  # íƒ€ì„í”„ë ˆì„ ì¶©ëŒ
        confidence_penalty = -0.3
        reasoning = f"í˜¼ì¡° ì‹ í˜¸: íƒ€ì„í”„ë ˆì„ ë¶ˆì¼ì¹˜ (ì •ë ¬ë„ {alignment_score:.1%})"

    return {
        "action": daily_signals['action'],
        "confidence": min(0.95, daily_signals['confidence'] + confidence_boost),
        "reasoning": reasoning,
        "monthly_trend": monthly_trend,
        "weekly_trend": weekly_trend,
        "alignment_score": alignment_score
    }
```

#### 2.2 ì§€ì§€ì„ /ì €í•­ì„  ìë™ íƒì§€

**Pivot Point ë°©ì‹**:
```python
def _find_support_resistance(self, ohlcv_data: List[Dict]) -> Dict:
    """
    ìµœê·¼ ê³ ì /ì €ì  ê¸°ë°˜ ì§€ì§€ì„ /ì €í•­ì„  íƒì§€

    ë°©ë²•:
    - Pivot High: ì¢Œìš° 5ê°œ ë´‰ë³´ë‹¤ ë†’ì€ ê³ ì 
    - Pivot Low: ì¢Œìš° 5ê°œ ë´‰ë³´ë‹¤ ë‚®ì€ ì €ì 
    """
    import numpy as np

    highs = [bar['high'] for bar in ohlcv_data]
    lows = [bar['low'] for bar in ohlcv_data]

    resistance_levels = []
    support_levels = []

    # Pivot Point íƒì§€ (ì¢Œìš° 5ê°œ ë´‰ í™•ì¸)
    for i in range(5, len(ohlcv_data) - 5):
        # Pivot High
        if all(highs[i] > highs[i-5:i]) and all(highs[i] > highs[i+1:i+6]):
            resistance_levels.append(highs[i])

        # Pivot Low
        if all(lows[i] < lows[i-5:i]) and all(lows[i] < lows[i+1:i+6]):
            support_levels.append(lows[i])

    # ìµœê·¼ 3ê°œ ì €í•­ì„ /ì§€ì§€ì„ ë§Œ ì‚¬ìš©
    resistance_levels = sorted(resistance_levels, reverse=True)[:3]
    support_levels = sorted(support_levels, reverse=True)[:3]

    current_price = ohlcv_data[-1]['close']

    # í˜„ì¬ê°€ì™€ ì§€ì§€/ì €í•­ ê±°ë¦¬ ê³„ì‚°
    nearest_support = max([s for s in support_levels if s < current_price], default=None)
    nearest_resistance = min([r for r in resistance_levels if r > current_price], default=None)

    support_distance = (current_price - nearest_support) / current_price if nearest_support else None
    resistance_distance = (nearest_resistance - current_price) / current_price if nearest_resistance else None

    return {
        "support_levels": support_levels,
        "resistance_levels": resistance_levels,
        "nearest_support": nearest_support,
        "nearest_resistance": nearest_resistance,
        "support_distance_pct": support_distance * 100 if support_distance else None,
        "resistance_distance_pct": resistance_distance * 100 if resistance_distance else None
    }
```

**ë§¤ë§¤ ì‹ í˜¸ì— ë°˜ì˜**:
```python
# ì§€ì§€ì„  ê·¼ì²˜ = ë§¤ìˆ˜ ê¸°íšŒ
if support_distance_pct and support_distance_pct < 2:  # ì§€ì§€ì„  2% ì´ë‚´
    confidence_boost += 0.15
    reasoning += f" | ì§€ì§€ì„  ê·¼ì²˜ ë§¤ìˆ˜ ê¸°íšŒ (${nearest_support:.2f})"

# ì €í•­ì„  ëŒíŒŒ = ê°•í•œ ë§¤ìˆ˜
if current_price > nearest_resistance:
    confidence_boost += 0.2
    reasoning += f" | ì €í•­ì„  ëŒíŒŒ (${nearest_resistance:.2f})"
```

#### 2.3 ë³¼ë¦°ì €ë°´ë“œ ì¶”ê°€

**êµ¬í˜„**:
```python
def _calculate_bollinger_bands(self, prices: List[float], period: int = 20, std_dev: int = 2) -> Dict:
    """
    ë³¼ë¦°ì €ë°´ë“œ ê³„ì‚°

    Returns:
        - upper_band: ìƒë‹¨ ë°´ë“œ (MA + 2Ïƒ)
        - middle_band: ì¤‘ê°„ì„  (20ì¼ MA)
        - lower_band: í•˜ë‹¨ ë°´ë“œ (MA - 2Ïƒ)
        - bandwidth: ë°´ë“œ í­ (ë³€ë™ì„± ì§€í‘œ)
        - percent_b: í˜„ì¬ê°€ ìœ„ì¹˜ (0~1, 0.5=ì¤‘ê°„)
    """
    import numpy as np

    prices_array = np.array(prices[-period:])

    middle_band = np.mean(prices_array)
    std = np.std(prices_array)

    upper_band = middle_band + (std_dev * std)
    lower_band = middle_band - (std_dev * std)

    bandwidth = (upper_band - lower_band) / middle_band

    current_price = prices[-1]
    percent_b = (current_price - lower_band) / (upper_band - lower_band) if (upper_band - lower_band) > 0 else 0.5

    return {
        "upper_band": upper_band,
        "middle_band": middle_band,
        "lower_band": lower_band,
        "bandwidth": bandwidth,
        "percent_b": percent_b,
        "squeeze": bandwidth < 0.1  # ë°´ë“œ í­ ì¢ì•„ì§ (ë³€ë™ì„± ëŒíŒŒ ëŒ€ê¸°)
    }
```

**ë§¤ë§¤ ì‹ í˜¸**:
```python
bb = self._calculate_bollinger_bands(prices)

# 1. í•˜ë‹¨ ë°´ë“œ ì´íƒˆ â†’ ë°˜ë“± ë§¤ìˆ˜
if bb['percent_b'] < 0:  # í•˜ë‹¨ ë°´ë“œ ì•„ë˜
    action = "BUY"
    confidence = 0.80
    reasoning = "ë³¼ë¦°ì €ë°´ë“œ í•˜ë‹¨ ì´íƒˆ, ê³¼ë§¤ë„ ë°˜ë“± ê¸°ëŒ€"

# 2. ìƒë‹¨ ë°´ë“œ ì´íƒˆ â†’ ê³¼ì—´ ë§¤ë„
elif bb['percent_b'] > 1:  # ìƒë‹¨ ë°´ë“œ ìœ„
    action = "SELL"
    confidence = 0.75
    reasoning = "ë³¼ë¦°ì €ë°´ë“œ ìƒë‹¨ ì´íƒˆ, ê³¼ì—´ ì¡°ì • ì˜ˆìƒ"

# 3. ë°´ë“œ ì¢ì•„ì§ (Squeeze) â†’ ë³€ë™ì„± ëŒíŒŒ ëŒ€ê¸°
elif bb['squeeze']:
    action = "HOLD"
    confidence = 0.60
    reasoning = "ë³¼ë¦°ì €ë°´ë“œ ìˆ˜ì¶•, í° ì›€ì§ì„ ëŒ€ê¸° (Bandwidth < 10%)"
```

#### 2.4 í”¼ë³´ë‚˜ì¹˜ ë˜ëŒë¦¼ ë ˆë²¨

**êµ¬í˜„**:
```python
def _calculate_fibonacci_levels(self, ohlcv_data: List[Dict]) -> Dict:
    """
    ìµœê·¼ ê³ ì /ì €ì  ê¸°ë°˜ í”¼ë³´ë‚˜ì¹˜ ë˜ëŒë¦¼ ê³„ì‚°

    ë ˆë²¨:
    - 0% (ìµœê³ ì )
    - 23.6% ë˜ëŒë¦¼
    - 38.2% ë˜ëŒë¦¼
    - 50% ë˜ëŒë¦¼
    - 61.8% ë˜ëŒë¦¼ (í™©ê¸ˆë¹„)
    - 100% (ìµœì €ì )
    """
    # ìµœê·¼ ê³ ì /ì €ì  ì°¾ê¸° (52ì£¼)
    recent_high = max([bar['high'] for bar in ohlcv_data])
    recent_low = min([bar['low'] for bar in ohlcv_data])

    diff = recent_high - recent_low

    fib_levels = {
        "0%": recent_high,
        "23.6%": recent_high - (diff * 0.236),
        "38.2%": recent_high - (diff * 0.382),
        "50%": recent_high - (diff * 0.5),
        "61.8%": recent_high - (diff * 0.618),  # í™©ê¸ˆë¹„
        "100%": recent_low
    }

    current_price = ohlcv_data[-1]['close']

    # í˜„ì¬ê°€ê°€ ì–´ëŠ ë ˆë²¨ ê·¼ì²˜ì¸ì§€ í™•ì¸
    nearest_level = min(fib_levels.items(), key=lambda x: abs(x[1] - current_price))

    return {
        "levels": fib_levels,
        "recent_high": recent_high,
        "recent_low": recent_low,
        "nearest_level": nearest_level[0],
        "nearest_price": nearest_level[1],
        "distance_pct": abs(current_price - nearest_level[1]) / current_price * 100
    }
```

**ë§¤ë§¤ ì‹ í˜¸**:
```python
fib = self._calculate_fibonacci_levels(ohlcv_data)

# 61.8% í™©ê¸ˆë¹„ ê·¼ì²˜ = ê°•í•œ ì§€ì§€
if fib['nearest_level'] == '61.8%' and fib['distance_pct'] < 1:
    confidence_boost += 0.15
    reasoning += f" | í”¼ë³´ë‚˜ì¹˜ 61.8% í™©ê¸ˆë¹„ ì§€ì§€ (${fib['nearest_price']:.2f})"

# 38.2% ë˜ëŒë¦¼ ì™„ë£Œ â†’ ì¬ìƒìŠ¹
elif fib['nearest_level'] == '38.2%' and current_price > fib['levels']['38.2%']:
    confidence_boost += 0.10
    reasoning += " | í”¼ë³´ë‚˜ì¹˜ 38.2% ë˜ëŒë¦¼ í›„ ì¬ìƒìŠ¹"
```

---

## 3. Risk Agent ê°œì„ 

### âœ… ì™„ë£Œëœ ê°œì„  (2025-12-27)

#### VaR (Value at Risk) ê³„ì‚°

**íŒŒì¼**: [backend/ai/debate/risk_agent.py:380-460](../backend/ai/debate/risk_agent.py#L380)

**êµ¬í˜„ ì™„ë£Œ**:
```python
def _calculate_var(self, returns: List[float], confidence_level: float = 0.95) -> Dict:
    """
    VaR (Value at Risk) ê³„ì‚° (Historical Method)

    Returns:
        - var_1day: 1ì¼ VaR (%)
        - var_10day: 10ì¼ VaR (%)
        - cvar: Conditional VaR (Expected Shortfall)
    """
    # Historical VaR: í•˜ìœ„ percentile ì‚¬ìš©
    var_percentile = (1 - confidence_level) * 100
    var_1day = np.percentile(returns_array, var_percentile)

    # 10ì¼ VaR (Square Root of Time Rule)
    var_10day = var_1day * np.sqrt(10)

    # CVaR: VaR ì´ˆê³¼ ì†ì‹¤ì˜ í‰ê· 
    tail_losses = returns_array[returns_array <= var_1day]
    cvar = np.mean(tail_losses) if len(tail_losses) > 0 else var_1day
```

**ë§¤ë§¤ ì‹ í˜¸ í†µí•©** (lines 135-158):
- VaR < -5%: SELL ì‹ í˜¸ (í—Œë²• ì œ4ì¡° ìœ„ë°˜ ê°€ëŠ¥ì„±)
- CVaR < -10%: confidence_boost ê°ì†Œ
- VaR > -2%: confidence_boost ì¦ê°€ (ë‚®ì€ ë¦¬ìŠ¤í¬)

### ğŸ¯ ì¶”ê°€ ê°œì„  í•„ìš” í•­ëª©

#### 3.1 ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°

**êµ¬í˜„**:
```python
def _calculate_sharpe_ratio(self, returns: List[float], risk_free_rate: float = 0.04) -> float:
    """
    ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°

    ê³µì‹: (í‰ê·  ìˆ˜ìµë¥  - ë¬´ìœ„í—˜ ìˆ˜ìµë¥ ) / ìˆ˜ìµë¥  í‘œì¤€í¸ì°¨

    Args:
        returns: ì¼ë³„ ìˆ˜ìµë¥  ë¦¬ìŠ¤íŠ¸
        risk_free_rate: ì—°ê°„ ë¬´ìœ„í—˜ ìˆ˜ìµë¥  (ê¸°ë³¸ê°’: 4%)

    Returns:
        Sharpe Ratio (1.0 ì´ìƒì´ë©´ ì–‘í˜¸, 2.0 ì´ìƒì´ë©´ ìš°ìˆ˜)
    """
    import numpy as np

    if len(returns) < 20:
        return 0.0  # ë°ì´í„° ë¶€ì¡±

    returns_array = np.array(returns)

    # ì—°ê°„í™” (252 ê±°ë˜ì¼ ê°€ì •)
    annual_return = np.mean(returns_array) * 252
    annual_volatility = np.std(returns_array) * np.sqrt(252)

    if annual_volatility == 0:
        return 0.0

    sharpe_ratio = (annual_return - risk_free_rate) / annual_volatility

    return sharpe_ratio
```

**ë§¤ë§¤ ì‹ í˜¸ ë°˜ì˜**:
```python
sharpe = self._calculate_sharpe_ratio(historical_returns)

if sharpe < 0.5:
    action = "SELL"
    confidence = 0.85
    reasoning = f"ë‚®ì€ ìƒ¤í”„ ë¹„ìœ¨ ({sharpe:.2f} < 0.5) - ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ìˆ˜ìµ ë¶€ì¡±"
elif sharpe > 1.5:
    action = "BUY"
    confidence = 0.80
    reasoning = f"ìš°ìˆ˜í•œ ìƒ¤í”„ ë¹„ìœ¨ ({sharpe:.2f}) - ì•ˆì •ì  ìˆ˜ìµ ê¸°ëŒ€"
```

#### 3.2 VaR (Value at Risk) ê³„ì‚°

**Historical VaR ë°©ì‹**:
```python
def _calculate_var(self, returns: List[float], confidence_level: float = 0.95) -> Dict:
    """
    VaR ê³„ì‚° (Historical Method)

    VaR = 95% ì‹ ë¢°ìˆ˜ì¤€ì—ì„œ ìµœëŒ€ ì˜ˆìƒ ì†ì‹¤

    Returns:
        - var_1day: 1ì¼ VaR
        - var_10day: 10ì¼ VaR (âˆš10 ìŠ¤ì¼€ì¼)
        - cvar: Conditional VaR (í‰ê·  ì†ì‹¤)
    """
    import numpy as np

    returns_array = np.array(returns)

    # 95% VaR = 5% ìµœì•…ì˜ ì†ì‹¤
    var_percentile = 1 - confidence_level
    var_1day = np.percentile(returns_array, var_percentile * 100)

    # 10ì¼ VaR (âˆš10 ìŠ¤ì¼€ì¼)
    var_10day = var_1day * np.sqrt(10)

    # CVaR (Conditional VaR): VaR ì´ˆê³¼ ì†ì‹¤ì˜ í‰ê· 
    tail_losses = returns_array[returns_array <= var_1day]
    cvar = np.mean(tail_losses) if len(tail_losses) > 0 else var_1day

    return {
        "var_1day": var_1day,
        "var_10day": var_10day,
        "cvar": cvar,
        "confidence_level": confidence_level
    }
```

**í¬ì§€ì…˜ í¬ê¸° ê¶Œì¥**:
```python
var_result = self._calculate_var(historical_returns)

# VaR ê¸°ë°˜ í¬ì§€ì…˜ í¬ê¸° ì œí•œ
# ëª©í‘œ: 1ì¼ VaRê°€ ì´ ìë³¸ì˜ 2% ì´í•˜
max_position_value = total_capital * 0.02 / abs(var_result['var_1day'])

return {
    "recommended_position_size": max_position_value,
    "var_1day": var_result['var_1day'],
    "reasoning": f"VaR ê¸°ë°˜ ê¶Œì¥ í¬ì§€ì…˜ í¬ê¸°: ${max_position_value:,.0f} (ì´ ìë³¸ì˜ {max_position_value/total_capital:.1%})"
}
```

#### 3.3 ì¼ˆë¦¬ ê¸°ì¤€ (Kelly Criterion)

**êµ¬í˜„**:
```python
def _calculate_kelly_position(self, win_rate: float, avg_win: float, avg_loss: float) -> float:
    """
    ì¼ˆë¦¬ ê¸°ì¤€ í¬ì§€ì…˜ í¬ê¸° ê³„ì‚°

    ê³µì‹: f* = (p * b - q) / b

    Args:
        win_rate: ìŠ¹ë¥  (0~1)
        avg_win: í‰ê·  ì´ìµë¥ 
        avg_loss: í‰ê·  ì†ì‹¤ë¥ 

    Returns:
        ìµœì  í¬ì§€ì…˜ ë¹„ìœ¨ (0~1)
    """
    if avg_loss == 0:
        return 0.0

    p = win_rate  # ìŠ¹ë¥ 
    q = 1 - win_rate  # íŒ¨ìœ¨
    b = avg_win / abs(avg_loss)  # ì´ìµ/ì†ì‹¤ ë¹„ìœ¨

    # ì¼ˆë¦¬ ê³µì‹
    kelly_fraction = (p * b - q) / b

    # ì•ˆì „ ë§ˆì§„: Half-Kelly (ì¼ˆë¦¬ì˜ 50%)
    half_kelly = max(0, min(kelly_fraction * 0.5, 0.25))  # ìµœëŒ€ 25%

    return half_kelly
```

**ì‚¬ìš© ì˜ˆ**:
```python
# ê³¼ê±° ê±°ë˜ ë¶„ì„
win_rate = 0.60  # 60% ìŠ¹ë¥ 
avg_win = 0.08  # í‰ê·  8% ìˆ˜ìµ
avg_loss = 0.04  # í‰ê·  4% ì†ì‹¤

kelly_pct = self._calculate_kelly_position(win_rate, avg_win, avg_loss)
recommended_position = total_capital * kelly_pct

return {
    "kelly_percentage": kelly_pct,
    "recommended_position": recommended_position,
    "reasoning": f"ì¼ˆë¦¬ ê¸°ì¤€ ê¶Œì¥ í¬ì§€ì…˜: {kelly_pct:.1%} (${recommended_position:,.0f})"
}
```

---

## 4. Macro Agent ê°œì„ 

### âœ… ì™„ë£Œëœ ê°œì„  (2025-12-27)

#### ìˆ˜ìµë¥  ê³¡ì„  (Yield Curve) ë¶„ì„

**íŒŒì¼**: [backend/ai/debate/macro_agent.py:230-280](../backend/ai/debate/macro_agent.py#L230)

**êµ¬í˜„ ì™„ë£Œ**:
```python
def _analyze_yield_curve(self, yield_2y: float, yield_10y: float) -> Dict:
    """
    ìˆ˜ìµë¥  ê³¡ì„  ìŠ¤í”„ë ˆë“œ (10Y - 2Y):
    - ì—­ì „ (< 0): ê²½ê¸° ì¹¨ì²´ ì‹ í˜¸ (ê°•í•œ SELL)
    - í‰íƒ„í™” (0 ~ 25bps): ê²½ê¸° ë‘”í™” ì¡°ì§
    - ì •ìƒ (25 ~ 150bps): ê±´ê°•í•œ ê²½ì œ
    - ê°€íŒŒë¦„ (> 150bps): ê²½ê¸° í™•ì¥ ê¸°ëŒ€
    """
```

**ë§¤ë§¤ ì‹ í˜¸ í†µí•©** (lines 104-118):
- ì—­ì „ (< 0bps): SELL ì‹ í˜¸ (ê²½ê¸° ì¹¨ì²´ ìœ„í—˜)
- ê°€íŒŒë¦„ (> 150bps): confidence +0.15 (ê²½ê¸° í™•ì¥)
- í‰íƒ„í™” (0-25bps): confidence -0.10 (ê²½ê¸° ë‘”í™”)

### ğŸ¯ ì¶”ê°€ ê°œì„  í•„ìš” í•­ëª©

#### 4.1 ìœ ê°€ ë¶„ì„ (WTI Crude) â­ ì¶”ê°€ ì˜ˆì •

**ì˜í–¥**:
- ìœ ê°€ ìƒìŠ¹ â†’ ì¸í”Œë ˆ ì••ë ¥ ì¦ê°€ â†’ ì—ë„ˆì§€ ì„¹í„° ìœ ë¦¬, í•­ê³µ/ìš´ì†¡ ë¶ˆë¦¬
- ìœ ê°€ í•˜ë½ â†’ ì†Œë¹„ì¬/ìš´ì†¡ ìœ ë¦¬, ì—ë„ˆì§€ ì„¹í„° ë¶ˆë¦¬

**êµ¬í˜„**:
```python
def _analyze_oil_price(self, wti_price: float, wti_change_30d: float) -> Dict:
    """
    ìœ ê°€ ë¶„ì„ (WTI Crude)

    Args:
        wti_price: í˜„ì¬ WTI ê°€ê²© ($/barrel)
        wti_change_30d: 30ì¼ ë³€í™”ìœ¨ (%)

    Returns:
        {
            "oil_price": float,
            "signal": "HIGH|NORMAL|LOW",
            "inflation_pressure": "INCREASING|STABLE|DECREASING",
            "sector_impact": {...}
        }
    """
    # ìœ ê°€ ìˆ˜ì¤€ íŒë‹¨
    if wti_price > 90:
        signal = "HIGH"
        inflation_pressure = "INCREASING"
        sector_impact = {
            "energy": "POSITIVE",  # XLE (Energy ETF)
            "airlines": "NEGATIVE",  # í•­ê³µì‚¬ ë¹„ìš© ì¦ê°€
            "consumer": "NEGATIVE"  # ì†Œë¹„ì¬ ì••ë°•
        }
    elif wti_price < 60:
        signal = "LOW"
        inflation_pressure = "DECREASING"
        sector_impact = {
            "energy": "NEGATIVE",
            "airlines": "POSITIVE",
            "consumer": "POSITIVE"
        }
    else:
        signal = "NORMAL"
        inflation_pressure = "STABLE"
        sector_impact = {}

    # ê¸‰ë“±/ê¸‰ë½ ì²´í¬
    if wti_change_30d > 20:
        reasoning = f"ìœ ê°€ ê¸‰ë“± ({wti_change_30d:.1f}%) - ì¸í”Œë ˆ ì••ë ¥ ì¦ê°€, ì—ë„ˆì§€ ì„¹í„° ê°•ì„¸"
    elif wti_change_30d < -20:
        reasoning = f"ìœ ê°€ ê¸‰ë½ ({wti_change_30d:.1f}%) - ì†Œë¹„ ì—¬ë ¥ ì¦ê°€, ì—ë„ˆì§€ ì„¹í„° ì•½ì„¸"
    else:
        reasoning = f"ìœ ê°€ ì•ˆì • (${wti_price:.2f}/ë°°ëŸ´)"

    return {
        "oil_price": wti_price,
        "oil_change_30d": wti_change_30d,
        "signal": signal,
        "inflation_pressure": inflation_pressure,
        "sector_impact": sector_impact,
        "reasoning": reasoning
    }
```

**ë§¤ë§¤ ì‹ í˜¸ í†µí•©**:
```python
# ìœ ê°€ ë¶„ì„
oil_analysis = None
if "wti_crude" in macro_data:
    oil_analysis = self._analyze_oil_price(
        wti_price=macro_data["wti_crude"],
        wti_change_30d=macro_data.get("wti_change_30d", 0)
    )

    # ìœ ê°€ ì˜í–¥ ë°˜ì˜
    sector = self._get_sector(ticker)  # í‹°ì»¤ì˜ ì„¹í„° í™•ì¸

    if sector == "Energy" and oil_analysis["signal"] == "HIGH":
        confidence_boost += 0.10
        reasoning += " | ìœ ê°€ ê³ ê³µí–‰ì§„ - ì—ë„ˆì§€ ì„¹í„° ìˆ˜í˜œ"
    elif sector in ["Airlines", "Transportation"] and oil_analysis["signal"] == "HIGH":
        confidence_boost -= 0.10
        reasoning += " | ìœ ê°€ ìƒìŠ¹ - ìš´ì†¡ ë¹„ìš© ë¶€ë‹´"
```

#### 4.2 ë‹¬ëŸ¬ ì¸ë±ìŠ¤ ë¶„ì„ (DXY) â­ ì¶”ê°€ ì˜ˆì •

**ì˜í–¥**:
- ë‹¬ëŸ¬ ê°•ì„¸ â†’ ë¯¸êµ­ ìˆ˜ì¶œ ë¶ˆë¦¬, ì‹ í¥êµ­ ì••ë°•, ê¸ˆ/ì›ìì¬ í•˜ë½
- ë‹¬ëŸ¬ ì•½ì„¸ â†’ ë¯¸êµ­ ìˆ˜ì¶œ ìœ ë¦¬, ì‹ í¥êµ­ ìˆ˜í˜œ, ê¸ˆ/ì›ìì¬ ìƒìŠ¹

**êµ¬í˜„**:
```python
def _analyze_dollar_index(self, dxy: float, dxy_change_30d: float) -> Dict:
    """
    ë‹¬ëŸ¬ ì¸ë±ìŠ¤ (DXY) ë¶„ì„

    Args:
        dxy: í˜„ì¬ ë‹¬ëŸ¬ ì¸ë±ìŠ¤ (ê¸°ì¤€: 100)
        dxy_change_30d: 30ì¼ ë³€í™”ìœ¨ (%)

    Returns:
        {
            "dxy": float,
            "signal": "STRONG|NEUTRAL|WEAK",
            "impact": {...}
        }
    """
    # ë‹¬ëŸ¬ ê°•ë„ íŒë‹¨
    if dxy > 105:
        signal = "STRONG"
        impact = {
            "us_exporters": "NEGATIVE",  # ìˆ˜ì¶œ ê¸°ì—… ë¶ˆë¦¬
            "multinationals": "NEGATIVE",  # ë‹¤êµ­ì  ê¸°ì—… ë¶ˆë¦¬
            "emerging_markets": "NEGATIVE",  # ì‹ í¥êµ­ ì••ë°•
            "gold": "NEGATIVE",  # ê¸ˆ ê°€ê²© í•˜ë½
            "commodities": "NEGATIVE"  # ì›ìì¬ ê°€ê²© í•˜ë½
        }
    elif dxy < 95:
        signal = "WEAK"
        impact = {
            "us_exporters": "POSITIVE",
            "multinationals": "POSITIVE",
            "emerging_markets": "POSITIVE",
            "gold": "POSITIVE",
            "commodities": "POSITIVE"
        }
    else:
        signal = "NEUTRAL"
        impact = {}

    # ê¸‰ë“±/ê¸‰ë½
    if dxy_change_30d > 5:
        reasoning = f"ë‹¬ëŸ¬ ê¸‰ê°•ì„¸ (DXY {dxy:.2f}, +{dxy_change_30d:.1f}%) - ìˆ˜ì¶œ ê¸°ì—… ë¶€ë‹´, ì‹ í¥êµ­ ì••ë°•"
    elif dxy_change_30d < -5:
        reasoning = f"ë‹¬ëŸ¬ ê¸‰ì•½ì„¸ (DXY {dxy:.2f}, {dxy_change_30d:.1f}%) - ìˆ˜ì¶œ ìœ ë¦¬, ê¸ˆ/ì›ìì¬ ê°•ì„¸"
    else:
        reasoning = f"ë‹¬ëŸ¬ ì•ˆì • (DXY {dxy:.2f})"

    return {
        "dxy": dxy,
        "dxy_change_30d": dxy_change_30d,
        "signal": signal,
        "impact": impact,
        "reasoning": reasoning
    }
```

**ë§¤ë§¤ ì‹ í˜¸ í†µí•©**:
```python
# ë‹¬ëŸ¬ ì¸ë±ìŠ¤ ë¶„ì„
dxy_analysis = None
if "dxy" in macro_data:
    dxy_analysis = self._analyze_dollar_index(
        dxy=macro_data["dxy"],
        dxy_change_30d=macro_data.get("dxy_change_30d", 0)
    )

    # ë‹¬ëŸ¬ ì˜í–¥ ë°˜ì˜
    if self._is_us_exporter(ticker) and dxy_analysis["signal"] == "STRONG":
        confidence_boost -= 0.08
        reasoning += " | ë‹¬ëŸ¬ ê°•ì„¸ - ìˆ˜ì¶œ ê²½ìŸë ¥ ì•½í™”"
    elif self._is_multinational(ticker) and dxy_analysis["signal"] == "STRONG":
        confidence_boost -= 0.05
        reasoning += " | ë‹¬ëŸ¬ ê°•ì„¸ - í•´ì™¸ ìˆ˜ìµ í™˜ì°¨ì†"
```

#### 4.3 PMI (êµ¬ë§¤ê´€ë¦¬ìì§€ìˆ˜) ë¶„ì„

**êµ¬í˜„**:
```python
async def _analyze_pmi(self) -> Dict:
    """
    ì œì¡°ì—… PMI ë¶„ì„

    - PMI > 50: ì œì¡°ì—… í™•ì¥
    - PMI < 50: ì œì¡°ì—… ìœ„ì¶•
    - PMI ì¶”ì„¸ê°€ ì¤‘ìš” (ìƒìŠ¹/í•˜ë½)
    """
    # ISM Manufacturing PMI
    fred = Fred(api_key=os.environ.get('FRED_API_KEY'))

    pmi = fred.get_series('MANEMP', observation_start=datetime.now() - timedelta(days=180))

    current_pmi = pmi.iloc[-1]
    prev_pmi = pmi.iloc[-2]
    pmi_3m_avg = pmi.iloc[-3:].mean()

    # ì¶”ì„¸ ê³„ì‚°
    if current_pmi > prev_pmi and current_pmi > 50:
        trend = "EXPANDING_ACCELERATING"
    elif current_pmi > 50:
        trend = "EXPANDING_SLOWING"
    elif current_pmi < prev_pmi and current_pmi < 50:
        trend = "CONTRACTING_ACCELERATING"
    else:
        trend = "CONTRACTING_SLOWING"

    return {
        "current_pmi": current_pmi,
        "prev_pmi": prev_pmi,
        "pmi_3m_avg": pmi_3m_avg,
        "trend": trend,
        "is_expansion": current_pmi > 50
    }
```

#### 4.3 ì„¹í„° ë¡œí…Œì´ì…˜ ë¶„ì„

**êµ¬í˜„**:
```python
def _analyze_sector_rotation(self, economic_cycle: str) -> Dict:
    """
    ê²½ê¸° ì‚¬ì´í´ë³„ ì„¹í„° ë¡œí…Œì´ì…˜

    ê²½ê¸° ì‚¬ì´í´:
    - EARLY_RECOVERY: ê¸ˆë¦¬ ì¸í•˜ ì‹œì‘, PMI ìƒìŠ¹
    - MID_CYCLE: ê²½ê¸° í™•ì¥, ì¸í”Œë ˆì´ì…˜ ì•ˆì •
    - LATE_CYCLE: ì¸í”Œë ˆì´ì…˜ ìƒìŠ¹, ê¸ˆë¦¬ ì¸ìƒ
    - RECESSION: ê²½ê¸° ìœ„ì¶•, ê¸ˆë¦¬ ì¸í•˜
    """
    SECTOR_ROTATION = {
        "EARLY_RECOVERY": {
            "best": ["Financials", "Consumer Discretionary", "Technology"],
            "reasoning": "ê¸ˆë¦¬ ì¸í•˜ + ê²½ê¸° íšŒë³µ â†’ ê¸ˆìœµ/ì†Œë¹„ì¬/ê¸°ìˆ ì£¼ ì„ í˜¸"
        },
        "MID_CYCLE": {
            "best": ["Technology", "Industrials", "Materials"],
            "reasoning": "ê²½ê¸° í™•ì¥ â†’ ê¸°ìˆ ì£¼/ì‚°ì—…ì¬/ì›ìì¬ ê°•ì„¸"
        },
        "LATE_CYCLE": {
            "best": ["Energy", "Materials", "Industrials"],
            "reasoning": "ì¸í”Œë ˆì´ì…˜ ìƒìŠ¹ â†’ ì—ë„ˆì§€/ì›ìì¬ ìˆ˜í˜œ"
        },
        "RECESSION": {
            "best": ["Healthcare", "Consumer Staples", "Utilities"],
            "reasoning": "ê²½ê¸° ë°©ì–´ â†’ í—¬ìŠ¤ì¼€ì–´/í•„ìˆ˜ì†Œë¹„ì¬/ìœ í‹¸ë¦¬í‹°"
        }
    }

    return SECTOR_ROTATION.get(economic_cycle, SECTOR_ROTATION["MID_CYCLE"])
```

---

## 5. Institutional Agent ê°œì„ 

### ğŸ¯ ìµœìš°ì„  ê°œì„  í•­ëª©

#### 5.1 ë‹¤í¬í’€ ê±°ë˜ëŸ‰ ë¶„ì„

**êµ¬í˜„**:
```python
async def _analyze_dark_pool(self, ticker: str) -> Dict:
    """
    ë‹¤í¬í’€ ê±°ë˜ëŸ‰ ë¶„ì„

    ë‹¤í¬í’€:
    - ì¥ì™¸ ëŒ€ëŸ‰ ê±°ë˜ (ê¸°ê´€ íˆ¬ìì)
    - ë‹¤í¬í’€ ë¹„ì¤‘ ì¦ê°€ = ê¸°ê´€ ë§¤ì§‘ ì‹ í˜¸
    """
    # Finra ATS (Alternative Trading System) ë°ì´í„° ì‚¬ìš©
    # ë˜ëŠ” IEX API

    from iexfinance.stocks import Stock

    stock = Stock(ticker, token=os.environ.get('IEX_API_KEY'))

    # IEX Volume (íˆ¬ëª… ê±°ë˜ì†Œ)
    iex_volume = stock.get_volume()

    # ì´ ê±°ë˜ëŸ‰
    total_volume = stock.get_quote()['latestVolume']

    # ë‹¤í¬í’€ ê±°ë˜ëŸ‰ (ì¶”ì •)
    dark_pool_volume = total_volume - iex_volume
    dark_pool_ratio = dark_pool_volume / total_volume if total_volume > 0 else 0

    # ê³¼ê±° í‰ê· ê³¼ ë¹„êµ
    avg_dark_pool_ratio = 0.35  # í‰ê·  35% (FINRA í†µê³„)

    is_elevated = dark_pool_ratio > avg_dark_pool_ratio * 1.2

    return {
        "dark_pool_volume": dark_pool_volume,
        "dark_pool_ratio": dark_pool_ratio,
        "avg_ratio": avg_dark_pool_ratio,
        "is_elevated": is_elevated,
        "signal": "ACCUMULATION" if is_elevated else "NORMAL"
    }
```

#### 5.2 ì˜µì…˜ Unusual Activity

**êµ¬í˜„**:
```python
async def _analyze_unusual_options(self, ticker: str) -> Dict:
    """
    ì˜µì…˜ ë¹„ì •ìƒ ê±°ë˜ íƒì§€

    Unusual Activity:
    - í‰ê·  ëŒ€ë¹„ 10ë°° ì´ìƒ ê±°ë˜ëŸ‰
    - ëŒ€ëŸ‰ ì½œ/í’‹ ë§¤ìˆ˜
    - ê³ ì•¡ í”„ë¦¬ë¯¸ì—„ ì§€ë¶ˆ (ê³ ê¸‰ ì •ë³´ ë°˜ì˜)
    """
    # ì˜µì…˜ ì²´ì¸ ë°ì´í„°
    import yfinance as yf

    stock = yf.Ticker(ticker)

    # ë§Œê¸°ì¼ ê°€ì ¸ì˜¤ê¸°
    expirations = stock.options

    if not expirations:
        return {"unusual_activity": False}

    # ê°€ì¥ ê°€ê¹Œìš´ ë§Œê¸°
    nearest_expiration = expirations[0]

    # ì˜µì…˜ ì²´ì¸
    options_chain = stock.option_chain(nearest_expiration)
    calls = options_chain.calls
    puts = options_chain.puts

    # ê±°ë˜ëŸ‰ ì´ìƒì¹˜ íƒì§€
    call_volume_avg = calls['volume'].mean()
    put_volume_avg = puts['volume'].mean()

    unusual_calls = calls[calls['volume'] > call_volume_avg * 10]
    unusual_puts = puts[puts['volume'] > put_volume_avg * 10]

    # Put/Call Ratio
    total_call_volume = calls['volume'].sum()
    total_put_volume = puts['volume'].sum()
    put_call_ratio = total_put_volume / total_call_volume if total_call_volume > 0 else 0

    return {
        "unusual_call_count": len(unusual_calls),
        "unusual_put_count": len(unusual_puts),
        "put_call_ratio": put_call_ratio,
        "sentiment": "BULLISH" if put_call_ratio < 0.7 else "BEARISH" if put_call_ratio > 1.3 else "NEUTRAL"
    }
```

#### 5.3 ìˆ ì¸í„°ë ˆìŠ¤íŠ¸ (ê³µë§¤ë„ ë¹„ì¤‘)

**êµ¬í˜„**:
```python
async def _analyze_short_interest(self, ticker: str) -> Dict:
    """
    ê³µë§¤ë„ ë¹„ì¤‘ ë¶„ì„

    Short Interest:
    - ë†’ì€ ìˆ ì¸í„°ë ˆìŠ¤íŠ¸ = ì•½ì„¸ ë² íŒ…
    - ê¸‰ê²©í•œ ì¦ê°€ = í•˜ë½ ì••ë ¥
    - ìˆ ìŠ¤í€´ì¦ˆ ê°€ëŠ¥ì„± (ìˆ ì»¤ë²„ë§)
    """
    import yfinance as yf

    stock = yf.Ticker(ticker)
    info = stock.info

    # ìˆ ë¹„ì¤‘
    short_percent_float = info.get('shortPercentOfFloat', 0) * 100

    # ìˆ ì»¤ë²„ ì¼ìˆ˜ (Short Ratio)
    short_ratio = info.get('shortRatio', 0)

    # ìˆ ìŠ¤í€´ì¦ˆ ìœ„í—˜ë„
    if short_percent_float > 20 and short_ratio > 5:
        squeeze_risk = "HIGH"
    elif short_percent_float > 10:
        squeeze_risk = "MODERATE"
    else:
        squeeze_risk = "LOW"

    return {
        "short_percent_float": short_percent_float,
        "short_ratio": short_ratio,
        "squeeze_risk": squeeze_risk,
        "sentiment": "BEARISH" if short_percent_float > 15 else "NEUTRAL"
    }
```

---

## 6. Analyst Agent ê°œì„ 

### âœ… ì™„ë£Œëœ ê°œì„  (2025-12-27)

#### ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„

**íŒŒì¼**: [backend/ai/debate/analyst_agent.py:287-452](../backend/ai/debate/analyst_agent.py#L287)

**êµ¬í˜„ ì™„ë£Œ**:
```python
def _compare_with_peers(self, ticker: str, fundamental_data: Dict) -> Dict:
    """
    ë™ì¢…ì—…ê³„ ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„

    Returns:
        - sector: ì„¹í„°ëª…
        - peer_comparison: P/E, Growth, Margin vs ì„¹í„° í‰ê· 
        - competitive_position: LEADER/COMPETITIVE/LAGGING
        - competitive_score: -3 ~ +3 ì ìˆ˜
    """
```

**ì„¹í„° ë§¤í•‘**: AAPL, MSFT, GOOGL (Technology), TSLA (Automotive), JPM (Financials) ë“±

**ë§¤ë§¤ ì‹ í˜¸ í†µí•©** (lines 161-186):
- LEADER: BUY ì‹ í˜¸ ê°•í™” (+0.15 confidence)
- LAGGING: SELL ì‹ í˜¸ ê°•í™” ë˜ëŠ” BUY ì‹ í˜¸ ì•½í™” (-0.15 confidence)

### ğŸ¯ ì¶”ê°€ ê°œì„  í•„ìš” í•­ëª©

#### 6.1 PEG Ratio (ì„±ì¥ ëŒ€ë¹„ ë°¸ë¥˜ì—ì´ì…˜)

**êµ¬í˜„**:
```python
def _calculate_peg_ratio(self, pe_ratio: float, growth_rate: float) -> Dict:
    """
    PEG Ratio ê³„ì‚°

    ê³µì‹: PEG = P/E Ratio / ì—°ê°„ ì„±ì¥ë¥ 

    í•´ì„:
    - PEG < 1.0: ì €í‰ê°€ (ì„±ì¥ ëŒ€ë¹„ ì‹¸ë‹¤)
    - PEG = 1.0: ì ì •ê°€
    - PEG > 2.0: ê³ í‰ê°€ (ì„±ì¥ ëŒ€ë¹„ ë¹„ì‹¸ë‹¤)
    """
    if growth_rate <= 0:
        return {
            "peg_ratio": None,
            "valuation": "UNKNOWN",
            "reasoning": "ìŒìˆ˜ ì„±ì¥ë¥  - PEG ê³„ì‚° ë¶ˆê°€"
        }

    peg_ratio = pe_ratio / growth_rate

    if peg_ratio < 1.0:
        valuation = "UNDERVALUED"
        reasoning = f"PEG {peg_ratio:.2f} < 1.0 â†’ ì„±ì¥ ëŒ€ë¹„ ì €í‰ê°€"
    elif peg_ratio < 1.5:
        valuation = "FAIR"
        reasoning = f"PEG {peg_ratio:.2f} â†’ ì ì • ë°¸ë¥˜ì—ì´ì…˜"
    else:
        valuation = "OVERVALUED"
        reasoning = f"PEG {peg_ratio:.2f} > 1.5 â†’ ì„±ì¥ ëŒ€ë¹„ ê³ í‰ê°€"

    return {
        "peg_ratio": peg_ratio,
        "valuation": valuation,
        "reasoning": reasoning
    }
```

#### 6.2 ROE (ìê¸°ìë³¸ì´ìµë¥ )

**êµ¬í˜„**:
```python
def _analyze_roe(self, net_income: float, shareholders_equity: float) -> Dict:
    """
    ROE ë¶„ì„

    ê³µì‹: ROE = ìˆœì´ìµ / ìê¸°ìë³¸

    í•´ì„:
    - ROE > 15%: ìš°ìˆ˜
    - ROE 10-15%: ì–‘í˜¸
    - ROE < 10%: ë¶€ì§„
    """
    if shareholders_equity <= 0:
        return {"roe": None, "quality": "UNKNOWN"}

    roe = (net_income / shareholders_equity) * 100

    if roe > 15:
        quality = "EXCELLENT"
        reasoning = f"ROE {roe:.1f}% â†’ ìš°ìˆ˜í•œ ìë³¸ íš¨ìœ¨ì„±"
    elif roe > 10:
        quality = "GOOD"
        reasoning = f"ROE {roe:.1f}% â†’ ì–‘í˜¸í•œ ìˆ˜ìµì„±"
    elif roe > 0:
        quality = "POOR"
        reasoning = f"ROE {roe:.1f}% â†’ ë‚®ì€ ìë³¸ íš¨ìœ¨"
    else:
        quality = "NEGATIVE"
        reasoning = f"ROE {roe:.1f}% â†’ ì†ì‹¤ ë°œìƒ"

    return {
        "roe": roe,
        "quality": quality,
        "reasoning": reasoning
    }
```

#### 6.3 FCF (ì‰ì—¬í˜„ê¸ˆíë¦„)

**êµ¬í˜„**:
```python
def _analyze_free_cash_flow(self, operating_cf: float, capex: float, revenue: float) -> Dict:
    """
    FCF ë¶„ì„

    ê³µì‹: FCF = ì˜ì—…í˜„ê¸ˆíë¦„ - ìë³¸ì§€ì¶œ
    FCF Margin = FCF / ë§¤ì¶œ

    í•´ì„:
    - FCF Margin > 15%: ìš°ìˆ˜
    - ì–‘ìˆ˜ FCF: ê±´ì „
    - ìŒìˆ˜ FCF: í˜„ê¸ˆ ì†Œì§„
    """
    fcf = operating_cf - capex
    fcf_margin = (fcf / revenue * 100) if revenue > 0 else 0

    if fcf_margin > 15:
        quality = "EXCELLENT"
        reasoning = f"FCF Margin {fcf_margin:.1f}% â†’ ê°•ë ¥í•œ í˜„ê¸ˆ ì°½ì¶œë ¥"
    elif fcf_margin > 5:
        quality = "GOOD"
        reasoning = f"FCF Margin {fcf_margin:.1f}% â†’ ê±´ì „í•œ í˜„ê¸ˆíë¦„"
    elif fcf > 0:
        quality = "FAIR"
        reasoning = f"FCF ì–‘ìˆ˜ â†’ í˜„ê¸ˆíë¦„ ìœ ì§€"
    else:
        quality = "POOR"
        reasoning = f"FCF ìŒìˆ˜ â†’ í˜„ê¸ˆ ì†Œì§„ ìœ„í—˜"

    return {
        "fcf": fcf,
        "fcf_margin": fcf_margin,
        "quality": quality,
        "reasoning": reasoning
    }
```

---

## 7. ChipWar Agent ê°œì„ 

### ğŸ¯ ìµœìš°ì„  ê°œì„  í•­ëª©

#### 7.1 AMD MI300X ë¶„ì„ ì¶”ê°€

**í˜„ì¬ ë¬¸ì œ**:
- AMD MI300Xê°€ ì¹© í”„ë¡œí•„ì— ì—†ìŒ
- NVIDIA ë…ì ìœ¼ë¡œë§Œ ì¸ì‹

**ê°œì„ **:
```python
CHIP_PROFILES = {
    "NVIDIA_H100": {
        "name": "NVIDIA H100",
        "manufacturer": "NVIDIA",
        "performance_score": 100,  # ê¸°ì¤€ì 
        "market_share": 0.85,
        "tco_index": 1.2  # TCO ì§€ìˆ˜ (1.0 = í‰ê· )
    },
    "AMD_MI300X": {
        "name": "AMD MI300X",
        "manufacturer": "AMD",
        "performance_score": 95,  # H100 ëŒ€ë¹„ 95%
        "market_share": 0.08,
        "tco_index": 0.9,  # TCO 10% ìš°ìœ„
        "disruption_potential": 0.7  # íŒŒê´´ì  ì ì¬ë ¥
    },
    "GOOGLE_TPU_V5": {
        "name": "Google TPU v5",
        "manufacturer": "Google",
        "performance_score": 85,
        "market_share": 0.05,
        "tco_index": 0.8,  # ë‚´ë¶€ ì‚¬ìš©
        "workload_specialization": "TRANSFORMERS"
    }
}
```

#### 7.2 MLPerf ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°

**êµ¬í˜„**:
```python
async def _fetch_mlperf_results(self, ticker: str) -> Dict:
    """
    MLPerf ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì¡°íšŒ

    MLPerf:
    - ë¨¸ì‹ ëŸ¬ë‹ ì„±ëŠ¥ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬
    - Training/Inference ë¶„ë¦¬
    - ì‹¤ì œ ì›Œí¬ë¡œë“œ ì„±ëŠ¥ ì¸¡ì •
    """
    # MLPerf ê³µì‹ ê²°ê³¼ (mlcommons.org)
    MLPERF_RESULTS_V4 = {
        "NVIDIA_H100": {
            "training_score": 100,
            "inference_score": 100,
            "efficiency": 90
        },
        "AMD_MI300X": {
            "training_score": 92,
            "inference_score": 88,
            "efficiency": 95  # ì „ë ¥ íš¨ìœ¨ ìš°ìˆ˜
        },
        "GOOGLE_TPU_V5": {
            "training_score": 85,
            "inference_score": 95,  # Inference íŠ¹í™”
            "efficiency": 88
        }
    }

    chip_name = self._get_chip_from_ticker(ticker)

    if chip_name in MLPERF_RESULTS_V4:
        results = MLPERF_RESULTS_V4[chip_name]

        return {
            "training_score": results['training_score'],
            "inference_score": results['inference_score'],
            "efficiency": results['efficiency'],
            "competitive_position": "LEADER" if results['training_score'] > 90 else "COMPETITIVE"
        }

    return {"mlperf_available": False}
```

---

## 8. êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1 (ì¦‰ì‹œ êµ¬í˜„) - âœ… ì™„ë£Œ (2025-12-27)

1. âœ… **News Agent ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„** (ì™„ë£Œ)
2. âœ… **Risk Agent VaR ê³„ì‚°** (ì™„ë£Œ)
3. âœ… **Analyst Agent ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„** (ì™„ë£Œ)
4. âœ… **Sentiment Agent ìƒì„±** (ì™„ë£Œ) - ì‹ ê·œ ì—ì´ì „íŠ¸

### Phase 2 (ë‹¤ìŒ ìš°ì„ ìˆœìœ„)

1. **Macro Agent ìœ ê°€/ë‹¬ëŸ¬ ë¶„ì„** â­ NEW (1ì‹œê°„)
2. **Trader Agent ì§€ì§€/ì €í•­ì„  íƒì§€** (1ì‹œê°„)
3. **Trader Agent ë©€í‹° íƒ€ì„í”„ë ˆì„** (2ì‹œê°„)
4. **Trader Agent ë³¼ë¦°ì €ë°´ë“œ** (1ì‹œê°„)
5. **Risk Agent ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°** (30ë¶„)

### Phase 3 (1ì£¼ ì´ë‚´)

6. **Analyst Agent PEG Ratio** (30ë¶„)
7. **Institutional Agent ë‹¤í¬í’€ ë¶„ì„** (2ì‹œê°„)
8. **Analyst Agent ROE/FCF** (1ì‹œê°„)
9. **Macro Agent PMI ë¶„ì„** (1ì‹œê°„)

### Phase 4 (2ì£¼ ì´ë‚´)

9. **Trader Agent í”¼ë³´ë‚˜ì¹˜**
10. **ChipWar Agent AMD MI300X**
11. **Institutional Agent ì˜µì…˜ ë¶„ì„**

---

## ğŸ“Š ì˜ˆìƒ ì„±ê³¼ ê°œì„ 

### í˜„ì¬ ì‹œìŠ¤í…œ
- Agent ê°œìˆ˜: 7ê°œ
- Constitutional í†µê³¼ìœ¨: 37%
- ì—ì´ì „íŠ¸ ì •í™•ë„: ë¯¸ì¸¡ì •
- ëª¨ì˜ ê±°ë˜ ìŠ¹ë¥ : ë¯¸ì‹œí–‰

### Phase 1 ì™„ë£Œ í›„ (2025-12-27) âœ…
- Agent ê°œìˆ˜: **8ê°œ** (Sentiment Agent ì¶”ê°€)
- Constitutional í†µê³¼ìœ¨: **80%+ ì˜ˆìƒ** (VaR ì‚¬ì „ ì²´í¬)
- ì†Œì…œ ê°ì„± ë°˜ì˜: **100%** (Twitter/Reddit ì‹¤ì‹œê°„)
- ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„: **100%** (ì„¹í„° ìƒëŒ€ í‰ê°€)
- VaR ê¸°ë°˜ ë¦¬ìŠ¤í¬ ê´€ë¦¬: **100%**

### ìµœì¢… ëª©í‘œ (Phase 1-4 ì™„ë£Œ ì‹œ)
- Constitutional í†µê³¼ìœ¨: **90%+**
- ì—ì´ì „íŠ¸ ì •í™•ë„: **65%+** (Self-Learning í›„)
- ëª¨ì˜ ê±°ë˜ ìŠ¹ë¥ : **60%+**
- ìƒ¤í”„ ë¹„ìœ¨: **1.0+**

---

## ğŸ¯ ì‹ ê·œ ì¶”ê°€ëœ Agent

### Sentiment Agent (2025-12-27)

**íŒŒì¼**: [backend/ai/debate/sentiment_agent.py](../backend/ai/debate/sentiment_agent.py)

**íˆ¬í‘œ ê°€ì¤‘ì¹˜**: 8%

**í•µì‹¬ ê¸°ëŠ¥**:
1. Twitter/Reddit ê°ì„± ë¶„ì„ (-1.0 ~ 1.0)
2. Fear & Greed Index ì—­íˆ¬ì ì „ëµ
   - Extreme Fear (< 25) â†’ CONTRARIAN_BUY
   - Extreme Greed (> 75) â†’ CONTRARIAN_SELL
3. Meme Stock ê°ì§€ (ê³ ê±°ë˜ëŸ‰ + ê¸‰ê²©í•œ ê°ì„± ë³€í™”)
4. ì†Œì…œ íŠ¸ë Œë”© ë¶„ì„

**War Room í†µí•©**: 8ê°œ Agent êµ¬ì„± (ì´ 100% íˆ¬í‘œ ê°€ì¤‘ì¹˜)

---

**ì‘ì„± ì™„ë£Œ**: 2025-12-27
**Phase 1 ì™„ë£Œ**: 2025-12-27 âœ…
**ë‹¤ìŒ ë¦¬ë·°**: Phase 2 ì°©ìˆ˜ ì‹œ ì—…ë°ì´íŠ¸
