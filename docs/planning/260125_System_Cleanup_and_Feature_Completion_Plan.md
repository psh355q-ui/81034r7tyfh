# AI Trading System - ì‹œìŠ¤í…œ ì •ë¦¬ ë° ê¸°ëŠ¥ ì™„ì„± ê³„íš

**ì‘ì„±ì¼**: 2026-01-25
**ê¸°ê°„**: 2026-01-27 ~ 2026-06-30 (6ê°œì›”)
**ëª©í‘œ**: ë ˆê±°ì‹œ ì •ë¦¬ + ë¶€ë¶„ êµ¬í˜„ ê¸°ëŠ¥ 100% ì™„ì„±

---

## ğŸ“‹ Executive Summary

### í˜„ì¬ ìƒí™©
- âœ… **í•µì‹¬ ê¸°ëŠ¥**: 100% êµ¬í˜„ ì™„ë£Œ (War Room MVP, Briefing v2.3, Intelligence v2.0)
- âš ï¸ **ë ˆê±°ì‹œ ì½”ë“œ**: 15% ì¡´ì¬ (debate/, war_room_router ë“±)
- âš ï¸ **ë¶€ë¶„ êµ¬í˜„**: 3ê°œ ê¸°ëŠ¥ (Persona 50%, WebSocket 70%, Risk 30%)
- âš ï¸ **ë¬¸ì„œ ê³¼ë‹¤**: 583ê°œ â†’ 200ê°œ í•µì‹¬ ë¬¸ì„œë¡œ ì••ì¶• í•„ìš”

### ëª©í‘œ (2026-06-30)
- âœ… ë ˆê±°ì‹œ ì½”ë“œ 100% ì œê±°
- âœ… ë¬¸ì„œ 200ê°œë¡œ ì••ì¶• (65% ê°ì†Œ)
- âœ… Persona-based Trading 100% ì™„ì„±
- âœ… Real-time Execution 100% ì™„ì„±
- âœ… Advanced Risk Models 100% ì™„ì„±
- ğŸ†• Mobile App (PWA) 80% ì™„ì„±

---

## ğŸ“… ì „ì²´ íƒ€ì„ë¼ì¸

```
Week 1-2  (2026-01-27 ~ 2026-02-09): ë ˆê±°ì‹œ ì •ë¦¬ Phase 2 (War Room ì¡°ì‚¬)
Week 3-4  (2026-02-10 ~ 2026-02-23): ë ˆê±°ì‹œ ì •ë¦¬ Phase 3 (Debate ì œê±°)
Week 5-6  (2026-02-24 ~ 2026-03-09): ë¬¸ì„œ ì••ì¶• (583 â†’ 200)
Week 7-12 (2026-03-10 ~ 2026-04-20): Persona-based Trading ì™„ì„±
Week 13-18(2026-04-21 ~ 2026-06-01): Real-time Execution ì™„ì„±
Week 19-22(2026-06-02 ~ 2026-06-29): Advanced Risk Models ì™„ì„±
Week 23-26(2026-06-30 ~ 2026-07-27): Mobile App (PWA) MVP (ë³´ë„ˆìŠ¤)
```

---

## ğŸ¯ Phase 0: ì‚¬ì „ ì¤€ë¹„ (Week 0 - ì´ë²ˆ ì£¼)

### ì‘ì—… í•­ëª©

#### T0.1 ê°œë°œ í™˜ê²½ ì ê²€
```bash
# ì‹œìŠ¤í…œ ì²´í¬
0_ì‹œìŠ¤í…œ_ì²´í¬.bat

# DB ìƒíƒœ í™•ì¸
python backend/scripts/check_db_health.py

# Structure Map ìµœì‹ í™”
python backend/utils/structure_mapper.py
```

#### T0.2 ë¸Œëœì¹˜ ì „ëµ ìˆ˜ë¦½
```bash
# ë©”ì¸ ì‘ì—… ë¸Œëœì¹˜ ìƒì„±
git checkout -b feature/system-cleanup-2026

# í•˜ìœ„ ë¸Œëœì¹˜ (í•„ìš” ì‹œ)
# - feature/legacy-removal
# - feature/persona-trading
# - feature/realtime-execution
# - feature/advanced-risk
```

#### T0.3 ë°±ì—… ìƒì„±
```bash
# í˜„ì¬ ìƒíƒœ íƒœê·¸
git tag -a backup-before-cleanup-20260125 -m "Backup before major cleanup"
git push origin backup-before-cleanup-20260125

# ì „ì²´ ë°±ì—…
tar -czf backups/full_backup_20260125.tar.gz backend/ frontend/ docs/
```

#### T0.4 ì²´í¬ë¦¬ìŠ¤íŠ¸ í™•ì¸
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
- [ ] í”„ë¡œë•ì…˜ ë°°í¬ ì •ìƒ í™•ì¸
- [ ] ë°±ì—… ì™„ë£Œ
- [ ] íŒ€ì›/ì‚¬ìš©ì ê³µì§€ (ìˆë‹¤ë©´)

---

## ğŸ§¹ Phase 1: ë ˆê±°ì‹œ ì½”ë“œ ì •ë¦¬ (Week 1-4)

### Week 1-2: War Room Legacy ì¡°ì‚¬ ë° Deprecation

#### ëª©í‘œ
- War Room Legacy (`war_room_router.py`) ì‚¬ìš© í˜„í™© íŒŒì•…
- Phase Integration Router ì‚¬ìš© í˜„í™© íŒŒì•…
- Deprecation Warning ì¶”ê°€

#### ìƒì„¸ ì‘ì—…

##### Day 1 (2026-01-27 ì›”): ì‚¬ìš© í˜„í™© ì¡°ì‚¬
```bash
# 1. í”„ë¡ íŠ¸ì—”ë“œ ê²€ìƒ‰
cd frontend
grep -r "war-room" src/ > ../analysis/frontend_war_room_usage.txt
grep -r "/phase" src/ > ../analysis/frontend_phase_usage.txt

# 2. ë°±ì—”ë“œ ê²€ìƒ‰
cd ../backend
grep -r "war_room_router" . > ../analysis/backend_war_room_refs.txt
grep -r "phase_integration_router" . > ../analysis/backend_phase_refs.txt

# 3. ë¡œê·¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
cat > scripts/analyze_api_usage.py <<'EOF'
"""
Analyze API usage from logs

Parse logs to find:
- /api/war-room/* call count
- /api/war-room-mvp/* call count
- /phase/* call count

Time range: Last 30 days
"""

import re
from datetime import datetime, timedelta
from collections import defaultdict

def analyze_logs(log_file_path: str):
    war_room_legacy = defaultdict(int)
    war_room_mvp = defaultdict(int)
    phase_integration = defaultdict(int)

    with open(log_file_path, 'r') as f:
        for line in f:
            if '/api/war-room/' in line and '/api/war-room-mvp/' not in line:
                # Legacy War Room
                date = extract_date(line)
                war_room_legacy[date] += 1
            elif '/api/war-room-mvp/' in line:
                # MVP War Room
                date = extract_date(line)
                war_room_mvp[date] += 1
            elif '/phase/' in line:
                # Phase Integration
                date = extract_date(line)
                phase_integration[date] += 1

    return {
        'war_room_legacy': dict(war_room_legacy),
        'war_room_mvp': dict(war_room_mvp),
        'phase_integration': dict(phase_integration)
    }

def extract_date(log_line: str) -> str:
    # Extract date from log line
    # Format: YYYY-MM-DD
    match = re.search(r'\d{4}-\d{2}-\d{2}', log_line)
    return match.group(0) if match else 'unknown'

if __name__ == '__main__':
    import sys
    log_file = sys.argv[1] if len(sys.argv) > 1 else 'logs/app.log'
    results = analyze_logs(log_file)

    print("=== API Usage Analysis ===")
    print(f"\nWar Room Legacy: {sum(results['war_room_legacy'].values())} calls")
    print(f"War Room MVP: {sum(results['war_room_mvp'].values())} calls")
    print(f"Phase Integration: {sum(results['phase_integration'].values())} calls")
EOF
```

##### Day 2 (2026-01-28 í™”): ë¶„ì„ ê²°ê³¼ ì •ë¦¬
```bash
# ë¡œê·¸ ë¶„ì„ ì‹¤í–‰
python scripts/analyze_api_usage.py logs/app.log > analysis/api_usage_report.txt

# ê²°ê³¼ ì •ë¦¬ ë¬¸ì„œ ì‘ì„±
cat > docs/analysis/260128_API_Usage_Analysis.md <<'EOF'
# API Usage Analysis Report

**Date**: 2026-01-28
**Period**: Last 30 days

## Results

### War Room Legacy (/api/war-room/*)
- Total calls: [TO BE FILLED]
- Daily average: [TO BE FILLED]
- Peak usage: [TO BE FILLED]

### War Room MVP (/api/war-room-mvp/*)
- Total calls: [TO BE FILLED]
- Daily average: [TO BE FILLED]
- Peak usage: [TO BE FILLED]

### Phase Integration (/phase/*)
- Total calls: [TO BE FILLED]
- Daily average: [TO BE FILLED]
- Peak usage: [TO BE FILLED]

## Recommendation

### If Legacy calls > 0:
- Add Deprecation Warning
- Monitor for 2 weeks
- Migrate users to MVP

### If Legacy calls == 0:
- Safe to remove immediately
- Proceed to Phase 3
EOF
```

##### Day 3-4 (2026-01-29 ìˆ˜ ~ 2026-01-30 ëª©): Deprecation Warning ì¶”ê°€
```python
# backend/api/war_room_router.py ìˆ˜ì •

import warnings
from datetime import datetime

# íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€
DEPRECATION_MESSAGE = """
âš ï¸ DEPRECATION WARNING âš ï¸

This War Room Legacy API is deprecated and will be removed on 2026-02-28.

Please migrate to War Room MVP API:
- Old: POST /api/war-room/debate
- New: POST /api/war-room-mvp/debate

Migration Guide: docs/guides/WAR_ROOM_MIGRATION_GUIDE.md

For questions, contact: [your-email]
"""

logger.warning(DEPRECATION_MESSAGE)

# ê° ì—”ë“œí¬ì¸íŠ¸ì— ë¡œê¹… ì¶”ê°€
@router.post("/debate")
async def debate_endpoint(...):
    logger.warning(
        f"[DEPRECATED] War Room Legacy called at {datetime.now()} - "
        f"Please migrate to /api/war-room-mvp/debate"
    )

    # ê¸°ì¡´ ë¡œì§...
```

##### Day 5 (2026-01-31 ê¸ˆ): Migration Guide ì‘ì„±
```markdown
# docs/guides/WAR_ROOM_MIGRATION_GUIDE.md

# War Room Migration Guide: Legacy â†’ MVP

**Last Update**: 2026-01-31
**Deadline**: 2026-02-28

## Why Migrate?

War Room MVP offers:
- âœ… Faster response (Two-Stage architecture)
- âœ… Lower cost (GLM-4.7 vs multiple models)
- âœ… Better accuracy (3+1 agent vs 8 agent)
- âœ… Active maintenance (Legacy is frozen)

## API Changes

### Endpoint
- AS-IS: `POST /api/war-room/debate`
- TO-BE: `POST /api/war-room-mvp/debate`

### Request Schema
[TO BE FILLED - ì‹¤ì œ ìŠ¤í‚¤ë§ˆ ë¹„êµ]

### Response Schema
[TO BE FILLED - ì‹¤ì œ ì‘ë‹µ ë¹„êµ]

## Migration Steps

### Step 1: Update Frontend
```tsx
// Before
const response = await fetch('/api/war-room/debate', {
  method: 'POST',
  body: JSON.stringify(data)
});

// After
const response = await fetch('/api/war-room-mvp/debate', {
  method: 'POST',
  body: JSON.stringify(data)
});
```

### Step 2: Update Scripts
[TO BE FILLED]

### Step 3: Test
[TO BE FILLED]
```

##### Week 2 (2026-02-03 ~ 2026-02-09): ëª¨ë‹ˆí„°ë§ ë° ì‚¬ìš©ì ì§€ì›
- Deprecation Warning ë°œìƒ íšŸìˆ˜ ì¶”ì 
- ì‚¬ìš©ì ë¬¸ì˜ ëŒ€ì‘
- Migration Guide ê°œì„ 

---

### Week 3-4: ë ˆê±°ì‹œ ì œê±° (Phase 3)

#### ì „ì œì¡°ê±´ ì²´í¬
```bash
# ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] War Room Legacy í˜¸ì¶œ 0ê±´ (ì—°ì† 7ì¼)
- [ ] Phase Integration í˜¸ì¶œ 0ê±´ (ì—°ì† 7ì¼)
- [ ] Migration ì™„ë£Œ í™•ì¸
- [ ] ë°±ì—… ì™„ë£Œ
```

#### Day 15-16 (2026-02-10 ~ 2026-02-11): ì•„ì¹´ì´ë¹™
```bash
# 1. ì•„ì¹´ì´ë¸Œ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p backend/ai/archived/debate_legacy_20260210/

# 2. ë°±ì—…
cp -r backend/ai/debate/ backend/ai/archived/debate_legacy_20260210/

# 3. README ì‘ì„±
cat > backend/ai/archived/debate_legacy_20260210/README.md <<'EOF'
# Legacy Debate System Archive

**Archive Date**: 2026-02-10
**Reason**: Replaced by War Room MVP (3+1 Agent)

## Original Location
- backend/ai/debate/

## Replacement System
- backend/ai/mvp/war_room_mvp.py (Production)
- backend/routers/war_room_mvp_router.py (API)

## Agent Comparison

### Legacy (8 Agents)
- News Agent (14%)
- Trader Agent (16%)
- Risk Agent (16%)
- Analyst Agent (12%)
- Macro Agent (14%)
- Institutional Agent (14%)
- Chip War Agent (14%)
- PM Agent (Mediator)

### MVP (3+1 Agents)
- Trader Agent MVP (35%)
- Risk Agent MVP (30%)
- Analyst Agent MVP (35%)
- PM Agent MVP (Final Decision Maker)

## Performance Comparison

| Metric | Legacy | MVP |
|--------|--------|-----|
| Response Time | 30-45s | 15-20s |
| Cost per Call | $0.15 | $0.05 |
| Accuracy | 65% | 78% |

## Restore Instructions

If needed, copy this directory back to `backend/ai/debate/`

DO NOT restore without team approval.
EOF

# 4. Git íƒœê·¸
git tag -a debate-legacy-archived-20260210 -m "Archive debate system before removal"
git push origin debate-legacy-archived-20260210
```

#### Day 17 (2026-02-12 ìˆ˜): ë¼ìš°í„° ì œê±°
```bash
# 1. War Room Legacy Router ì œê±°
git rm backend/api/war_room_router.py

# 2. Phase Integration Router ì œê±°
git rm backend/api/phase_integration_router.py

# 3. main.py ìˆ˜ì •
# - war_room_router ì„í¬íŠ¸ ì œê±°
# - phase_router ì„í¬íŠ¸ ì œê±°
# - include_router() í˜¸ì¶œ ì œê±°

# ì»¤ë°‹
git add backend/main.py
git commit -m "refactor: remove war room legacy and phase integration routers

- Remove backend/api/war_room_router.py
- Remove backend/api/phase_integration_router.py
- Update main.py router registration
- Archived in backend/ai/archived/debate_legacy_20260210/

BREAKING CHANGE: /api/war-room/* and /phase/* endpoints removed
Use /api/war-room-mvp/* instead

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

#### Day 18 (2026-02-13 ëª©): Debate ì—ì´ì „íŠ¸ ì œê±°
```bash
# 1. Debate ë””ë ‰í† ë¦¬ ì œê±°
git rm -rf backend/ai/debate/

# 2. í…ŒìŠ¤íŠ¸ ì œê±° (debate ê´€ë ¨)
git rm backend/tests/test_chip_war_agent.py
git rm backend/tests/test_priority_calculator.py
git rm backend/tests/test_skeptic_live.py
git rm backend/tests/test_phase_e_integration.py

# 3. ê¸°íƒ€ ì°¸ì¡° ì •ë¦¬
# backend/ai/reporters/report_orchestrator.py
# backend/orchestration/data_accumulation_orchestrator.py
# - debate ì„í¬íŠ¸ ì œê±°
# - MVPë¡œ ëŒ€ì²´

# ì»¤ë°‹
git commit -m "refactor: remove legacy debate system

- Remove backend/ai/debate/ (14 files)
- Remove debate-related tests (4 files)
- Update report_orchestrator.py to use MVP
- Update data_accumulation_orchestrator.py to use MVP

Total removed: ~6,000 lines

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

#### Day 19-20 (2026-02-14 ê¸ˆ ~ 2026-02-15 í† ): ê²€ì¦ ë° í…ŒìŠ¤íŠ¸
```bash
# 1. Structure Map ì—…ë°ì´íŠ¸
python backend/utils/structure_mapper.py

# 2. ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
npm run test:backend

# 3. ì‹œìŠ¤í…œ ì²´í¬
0_ì‹œìŠ¤í…œ_ì²´í¬.bat

# 4. í”„ë¡œë•ì…˜ ë°°í¬ í…ŒìŠ¤íŠ¸
# - ë¡œì»¬ì—ì„œ ì „ì²´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
# - War Room MVP ì •ìƒ ì‘ë™ í™•ì¸
# - ë¸Œë ˆì´í‚¹ ì²´ì¸ì§€ ì—†ëŠ”ì§€ í™•ì¸

# 5. ë¬¸ì„œ ì—…ë°ì´íŠ¸
# - SYSTEM_STATUS_MAP.md ì—…ë°ì´íŠ¸
# - LEGACY_CLEANUP_PLAN.md ì™„ë£Œ ì²´í¬
# - CHANGELOG.md ì—…ë°ì´íŠ¸
```

---

## ğŸ“š Phase 2: ë¬¸ì„œ ì••ì¶• (Week 5-6)

### ëª©í‘œ
- 583ê°œ ë¬¸ì„œ â†’ 200ê°œ í•µì‹¬ ë¬¸ì„œ
- ë ˆê±°ì‹œ/ì¤‘ë³µ ë¬¸ì„œ ì•„ì¹´ì´ë¹™
- ë¬¸ì„œ êµ¬ì¡° ì¬í¸

### Week 5: ë¶„ì„ ë° ë¶„ë¥˜ (2026-02-24 ~ 2026-03-02)

#### Day 21 (2026-02-24 ì›”): ë¬¸ì„œ ë¶„ë¥˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
```python
# scripts/classify_docs.py

"""
Document Classification Script

Classify all 583 docs into:
1. KEEP (í•µì‹¬ ë¬¸ì„œ, 200ê°œ ëª©í‘œ)
2. ARCHIVE (ê³¼ê±° ê¸°ë¡, ë³´ê´€)
3. DELETE (ì¤‘ë³µ/ì“¸ëª¨ì—†ìŒ, ì‚­ì œ)

Criteria:
- KEEP: ìµœì‹ , ì°¸ì¡° ë§ìŒ, í”„ë¡œë•ì…˜ ê´€ë ¨
- ARCHIVE: ì™„ë£Œëœ Phase, ê³¼ê±° í† ë¡ 
- DELETE: ì¤‘ë³µ, ì˜¤ë˜ë¨ (6ê°œì›”+), ì°¸ì¡° ì—†ìŒ
"""

import os
from pathlib import Path
from datetime import datetime, timedelta
import re
from collections import defaultdict

def classify_document(file_path: Path) -> str:
    """Classify a single document"""

    # 1. Check file age
    stat = file_path.stat()
    age_days = (datetime.now() - datetime.fromtimestamp(stat.st_mtime)).days

    # 2. Check references
    refs = count_references(file_path)

    # 3. Check directory
    if 'legacy' in str(file_path) or 'archive' in str(file_path):
        return 'ARCHIVE'

    if 'deleted' in str(file_path):
        return 'DELETE'

    # 4. Check date in filename
    filename = file_path.name
    date_match = re.search(r'(\d{6})_', filename)
    if date_match:
        file_date = datetime.strptime(date_match.group(1), '%y%m%d')
        if (datetime.now() - file_date).days > 180:  # 6ê°œì›” ì´ìƒ
            return 'ARCHIVE'

    # 5. Check importance
    if refs >= 5:
        return 'KEEP'

    if age_days > 90 and refs == 0:
        return 'DELETE'

    # Default
    return 'ARCHIVE' if age_days > 60 else 'KEEP'

def count_references(file_path: Path) -> int:
    """Count how many times this file is referenced"""
    # Search in all Python/TypeScript files
    # Return reference count
    pass

if __name__ == '__main__':
    docs_dir = Path('docs')
    classifications = defaultdict(list)

    for md_file in docs_dir.rglob('*.md'):
        category = classify_document(md_file)
        classifications[category].append(md_file)

    print(f"KEEP: {len(classifications['KEEP'])}")
    print(f"ARCHIVE: {len(classifications['ARCHIVE'])}")
    print(f"DELETE: {len(classifications['DELETE'])}")

    # Save results
    with open('analysis/doc_classification.json', 'w') as f:
        import json
        json.dump({
            'KEEP': [str(p) for p in classifications['KEEP']],
            'ARCHIVE': [str(p) for p in classifications['ARCHIVE']],
            'DELETE': [str(p) for p in classifications['DELETE']]
        }, f, indent=2)
```

#### Day 22-24 (2026-02-25 í™” ~ 2026-02-27 ëª©): ìˆ˜ë™ ê²€í† 
```bash
# 1. ë¶„ë¥˜ ê²°ê³¼ í™•ì¸
python scripts/classify_docs.py
cat analysis/doc_classification.json

# 2. ìˆ˜ë™ ê²€í†  (ì¤‘ìš”!)
# - KEEP ëª©ë¡ í™•ì¸ (200ê°œ ì´í•˜ë¡œ ì¡°ì •)
# - ARCHIVE ëª©ë¡ í™•ì¸ (ë ˆê±°ì‹œë§Œ í¬í•¨)
# - DELETE ëª©ë¡ í™•ì¸ (ë³µêµ¬ ë¶ˆê°€ëŠ¥)

# 3. ì¡°ì •ëœ ë¶„ë¥˜ ì €ì¥
cp analysis/doc_classification.json analysis/doc_classification_final.json
# (ìˆ˜ë™ìœ¼ë¡œ ì¡°ì •)
```

#### Day 25 (2026-02-28 ê¸ˆ): í•µì‹¬ ë¬¸ì„œ ì„ ì •
```markdown
# docs/analysis/260228_Core_Documentation_List.md

# Core Documentation (200 Files)

## 00. Root Level (10 files)
1. README.md - Main entry
2. CLAUDE.md - AI development guide
3. QUICK_START.md - Quick start
4. SYSTEM_STATUS_MAP.md - System overview
5. LEGACY_CLEANUP_PLAN.md - Cleanup plan
6. PARTIAL_IMPLEMENTATION_REVIEW.md - Feature review
7. PROJECT_OVERVIEW.md - Project overview
8. RETROSPECTIVE.md - Retrospective
9. IMPLEMENTATION_SUMMARY.md - Implementation summary
10. Live_Trading.md - Live trading guide

## 01. Architecture (5 files)
1. docs/architecture/ARCHITECTURE.md
2. docs/architecture/SYSTEM_ARCHITECTURE.md
3. docs/architecture/SYSTEM_ARCHITECTURE_FULL.md
4. docs/architecture/structure-map.md (auto-generated)
5. docs/architecture/260104_Complete_Development_History_and_Structure.md

## 02. Planning (20 files)
Active plans only:
1. 01-multi-strategy-orchestration-plan.md
2. 02-multi-strategy-orchestration-tasks.md
3. 260118_market_intelligence_roadmap.md
4. 260124_Daily_Briefing_v2.3_Protocol_Implementation_Plan.md
5. 12-db-modernization-plan.md
... (15 more core plans)

[CONTINUE FOR ALL 200 FILES]
```

### Week 6: ì‹¤í–‰ (2026-03-03 ~ 2026-03-09)

#### Day 26-27 (2026-03-03 ì›” ~ 2026-03-04 í™”): ì•„ì¹´ì´ë¸Œ ì´ë™
```bash
# 1. ARCHIVE ë¬¸ì„œ ì´ë™
mkdir -p docs/archive/2026_Q1_cleanup/

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python scripts/archive_docs.py

# scripts/archive_docs.py ë‚´ìš©:
import json
import shutil
from pathlib import Path

with open('analysis/doc_classification_final.json') as f:
    classification = json.load(f)

archive_dir = Path('docs/archive/2026_Q1_cleanup')
archive_dir.mkdir(parents=True, exist_ok=True)

for doc_path in classification['ARCHIVE']:
    src = Path(doc_path)
    # Preserve directory structure
    rel_path = src.relative_to('docs')
    dst = archive_dir / rel_path
    dst.parent.mkdir(parents=True, exist_ok=True)
    shutil.move(src, dst)

print(f"Archived {len(classification['ARCHIVE'])} documents")
```

#### Day 28 (2026-03-05 ìˆ˜): ë¶ˆí•„ìš” ë¬¸ì„œ ì‚­ì œ
```bash
# DELETE ë¬¸ì„œ ì‚­ì œ
python scripts/delete_docs.py

# í™•ì¸ í›„ ì»¤ë°‹
git add .
git commit -m "docs: archive old documentation and remove duplicates

- Archive 350+ legacy documents to docs/archive/2026_Q1_cleanup/
- Delete 33 duplicate/obsolete documents
- Retain 200 core documents
- Total reduction: 583 â†’ 200 files (65% reduction)

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>"
```

#### Day 29-30 (2026-03-06 ëª© ~ 2026-03-07 ê¸ˆ): ë¬¸ì„œ ì¬êµ¬ì¡°í™”
```bash
# í•µì‹¬ ë¬¸ì„œ ì¬êµ¬ì¡°í™”
docs/
â”œâ”€â”€ README.md (ë©”ì¸ ì¸ë±ìŠ¤)
â”œâ”€â”€ QUICK_START.md
â”œâ”€â”€ CLAUDE.md
â”œâ”€â”€ SYSTEM_STATUS_MAP.md
â”œâ”€â”€ 00_Core/ (í•µì‹¬ ìŠ¤í™ 20ê°œ)
â”œâ”€â”€ 01_Architecture/ (5ê°œ)
â”œâ”€â”€ 02_Planning/ (ì•¡í‹°ë¸Œ ê³„íš 20ê°œ)
â”œâ”€â”€ 03_Guides/ (ì‹¤ìš© ê°€ì´ë“œ 30ê°œ)
â”œâ”€â”€ 04_API/ (API ë¬¸ì„œ 20ê°œ)
â”œâ”€â”€ 05_Features/ (ê¸°ëŠ¥ë³„ 15ê°œ)
â”œâ”€â”€ archive/ (350+ ì•„ì¹´ì´ë¸Œ)
â””â”€â”€ templates/ (ë¬¸ì„œ í…œí”Œë¦¿ 10ê°œ)

# README ì—…ë°ì´íŠ¸
cat > docs/README.md <<'EOF'
# AI Trading System Documentation

**Last Update**: 2026-03-07
**Total Documents**: 200 core + 350+ archived

## Quick Links
- [Quick Start](QUICK_START.md)
- [System Overview](SYSTEM_STATUS_MAP.md)
- [Architecture](01_Architecture/SYSTEM_ARCHITECTURE.md)
- [Planning](02_Planning/)
- [Guides](03_Guides/)

## Document Structure
...
EOF
```

---

## ğŸ¨ Phase 3: Persona-based Trading ì™„ì„± (Week 7-12)

### Week 7-8: Daily Briefing í˜ë¥´ì†Œë‚˜ ë¶„ë¦¬

#### Day 35-37 (2026-03-10 ~ 2026-03-12): DailyBriefingService ìˆ˜ì •
```python
# backend/services/daily_briefing_service.py í™•ì¥

class PersonaBriefingService:
    """Persona-specific briefing generation"""

    PERSONA_CONFIGS = {
        'trading': {
            'time_horizon': '1-5 days',
            'focus': ['technical_analysis', 'short_term_catalysts', 'intraday_signals'],
            'style': 'concise_actionable',
            'sections': ['market_pulse', 'key_movers', 'quick_actions'],
        },
        'long_term': {
            'time_horizon': '6-18 months',
            'focus': ['fundamentals', 'themes', 'macro_trends'],
            'style': 'analytical_educational',
            'sections': ['market_narrative', 'deep_dive', 'strategic_positioning'],
        },
        'dividend': {
            'time_horizon': '1+ years',
            'focus': ['dividend_safety', 'valuation', 'income_stability'],
            'style': 'conservative_detailed',
            'sections': ['income_highlights', 'safety_check', 'value_opportunities'],
        },
        'aggressive': {
            'time_horizon': '1 day',
            'focus': ['volatility', 'momentum', 'breakouts'],
            'style': 'fast_numerical',
            'sections': ['hot_stocks', 'volatility_plays', 'instant_alerts'],
        }
    }

    async def generate_persona_briefing(
        self,
        persona: str = 'trading',
        mode: str = 'CLOSING'  # CLOSING or MORNING
    ) -> Dict:
        """Generate persona-specific briefing"""

        config = self.PERSONA_CONFIGS[persona]

        # 1. Fetch data filtered by persona focus
        data = await self._fetch_persona_data(config['focus'])

        # 2. Build persona-specific prompt
        prompt = self._build_persona_prompt(persona, mode, data, config)

        # 3. Generate with appropriate style
        briefing = await self._generate_with_style(prompt, config['style'])

        # 4. Structure by persona sections
        structured = self._structure_output(briefing, config['sections'])

        return {
            'persona': persona,
            'mode': mode,
            'time_horizon': config['time_horizon'],
            'briefing': structured,
            'generated_at': datetime.now().isoformat()
        }

    def _build_persona_prompt(
        self,
        persona: str,
        mode: str,
        data: Dict,
        config: Dict
    ) -> str:
        """Build persona-specific prompt"""

        if persona == 'trading':
            return f"""
You are a short-term trader (1-5 day horizon).

Mode: {mode}
Focus: {', '.join(config['focus'])}

Market Data:
{data}

Generate a concise, actionable briefing with:
1. Market Pulse (30ì´ˆ ìš”ì•½)
2. Key Movers (ìƒìœ„ 3ê°œ)
3. Quick Actions (ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ íŠ¸ë ˆì´ë“œ ì•„ì´ë””ì–´)

Style: Direct, numerical, action-oriented
"""
        elif persona == 'long_term':
            return f"""
You are a long-term investor (6-18 month horizon).

Mode: {mode}
Focus: {', '.join(config['focus'])}

Market Data:
{data}

Generate an analytical briefing with:
1. Market Narrative (ì „ì²´ ìŠ¤í† ë¦¬)
2. Deep Dive (ì£¼ìš” í…Œë§ˆ 3ê°œ ì‹¬ì¸µ ë¶„ì„)
3. Strategic Positioning (í¬íŠ¸í´ë¦¬ì˜¤ ì¡°ì • ì œì•ˆ)

Style: Analytical, educational, big-picture
"""
        # ... (dividend, aggressive ì¶”ê°€)
```

#### Day 38-40 (2026-03-13 ~ 2026-03-15): API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
```python
# backend/api/briefing_router.py í™•ì¥

@router.get("/api/briefing/persona/{persona}")
async def get_persona_briefing(
    persona: str,
    mode: str = Query('CLOSING', regex='^(CLOSING|MORNING)$'),
    db: Session = Depends(get_sync_session)
):
    """
    Get persona-specific briefing

    Personas:
    - trading: 1-5 day horizon, technical focus
    - long_term: 6-18 month horizon, fundamental focus
    - dividend: 1+ year horizon, income focus
    - aggressive: 1 day horizon, volatility focus
    """

    if persona not in ['trading', 'long_term', 'dividend', 'aggressive']:
        raise HTTPException(400, f"Invalid persona: {persona}")

    service = PersonaBriefingService()
    briefing = await service.generate_persona_briefing(persona, mode)

    # Cache for 1 hour
    cache_key = f"persona_briefing:{persona}:{mode}"
    await cache.set(cache_key, briefing, ex=3600)

    return briefing

@router.get("/api/briefing/all-personas")
async def get_all_persona_briefings(
    mode: str = Query('CLOSING')
):
    """Get briefings for all personas"""

    personas = ['trading', 'long_term', 'dividend', 'aggressive']
    service = PersonaBriefingService()

    results = {}
    for persona in personas:
        results[persona] = await service.generate_persona_briefing(persona, mode)

    return results
```

### Week 9-10: UI í†µí•©

#### Day 45-47 (2026-03-17 ~ 2026-03-19): Persona Selector ì»´í¬ë„ŒíŠ¸
```tsx
// frontend/src/components/PersonaSelector.tsx

import { Select, Tag } from 'antd';
import { UserOutlined, RiseOutlined, DollarOutlined, ThunderboltOutlined } from '@ant-design/icons';

const PERSONAS = [
  {
    key: 'trading',
    label: 'Trading',
    icon: <RiseOutlined />,
    color: 'blue',
    description: 'ë‹¨ê¸° (1-5ì¼)',
    horizon: '1-5 days'
  },
  {
    key: 'long_term',
    label: 'Long-term',
    icon: <UserOutlined />,
    color: 'green',
    description: 'ì¥ê¸° (6-18ê°œì›”)',
    horizon: '6-18 months'
  },
  {
    key: 'dividend',
    label: 'Dividend',
    icon: <DollarOutlined />,
    color: 'gold',
    description: 'ë°°ë‹¹ (1ë…„+)',
    horizon: '1+ year'
  },
  {
    key: 'aggressive',
    label: 'Aggressive',
    icon: <ThunderboltOutlined />,
    color: 'red',
    description: 'ì´ˆë‹¨ê¸° (1ì¼)',
    horizon: '1 day'
  }
];

export const PersonaSelector: React.FC<{
  value?: string;
  onChange?: (value: string) => void;
}> = ({ value = 'trading', onChange }) => {
  return (
    <Select
      value={value}
      onChange={onChange}
      style={{ width: 200 }}
      size="large"
    >
      {PERSONAS.map(persona => (
        <Select.Option key={persona.key} value={persona.key}>
          <div style={{ display: 'flex', alignItems: 'center', gap: 8 }}>
            {persona.icon}
            <span>{persona.label}</span>
            <Tag color={persona.color} style={{ marginLeft: 'auto' }}>
              {persona.description}
            </Tag>
          </div>
        </Select.Option>
      ))}
    </Select>
  );
};

// ì‚¬ìš© ì˜ˆì‹œ
export const DashboardHeader: React.FC = () => {
  const [activePersona, setActivePersona] = useState('trading');

  return (
    <div className="dashboard-header">
      <h1>AI Trading Dashboard</h1>
      <PersonaSelector value={activePersona} onChange={setActivePersona} />
    </div>
  );
};
```

#### Day 48-50 (2026-03-20 ~ 2026-03-22): í˜ë¥´ì†Œë‚˜ë³„ ëŒ€ì‹œë³´ë“œ ë ˆì´ì•„ì›ƒ
```tsx
// frontend/src/pages/PersonaDashboard.tsx

import { useQuery } from '@tanstack/react-query';
import { PersonaSelector } from '@/components/PersonaSelector';
import { TradingDashboard } from './personas/TradingDashboard';
import { LongTermDashboard } from './personas/LongTermDashboard';
import { DividendDashboard } from './personas/DividendDashboard';
import { AggressiveDashboard } from './personas/AggressiveDashboard';

export const PersonaDashboard: React.FC = () => {
  const [activePersona, setActivePersona] = useState('trading');

  // Fetch persona-specific briefing
  const { data: briefing, isLoading } = useQuery(
    ['briefing', activePersona, 'CLOSING'],
    () => fetchPersonaBriefing(activePersona, 'CLOSING'),
    {
      refetchInterval: 60000, // 1ë¶„ë§ˆë‹¤ ê°±ì‹ 
      staleTime: 30000 // 30ì´ˆ ìºì‹œ
    }
  );

  // Render persona-specific layout
  const renderDashboard = () => {
    switch (activePersona) {
      case 'trading':
        return <TradingDashboard briefing={briefing} />;
      case 'long_term':
        return <LongTermDashboard briefing={briefing} />;
      case 'dividend':
        return <DividendDashboard briefing={briefing} />;
      case 'aggressive':
        return <AggressiveDashboard briefing={briefing} />;
      default:
        return <TradingDashboard briefing={briefing} />;
    }
  };

  return (
    <div className="persona-dashboard">
      <PersonaSelector value={activePersona} onChange={setActivePersona} />
      {isLoading ? <Spin size="large" /> : renderDashboard()}
    </div>
  );
};
```

### Week 11-12: ë¦¬í¬íŠ¸ë³„ í˜ë¥´ì†Œë‚˜ ì ìš©

#### Day 55-60 (2026-03-24 ~ 2026-03-29): Weekly/Monthly Report í˜ë¥´ì†Œë‚˜ í™•ì¥
```python
# backend/services/weekly_report_generator.py í™•ì¥

class PersonaWeeklyReportGenerator:
    """Generate persona-specific weekly reports"""

    async def generate_persona_report(
        self,
        persona: str,
        week_start: datetime
    ) -> Dict:
        """Generate weekly report for specific persona"""

        # Fetch week's data
        data = await self._fetch_week_data(week_start)

        if persona == 'trading':
            # ë‹¨ê¸°: ì¼ë³„ ì£¼ìš” ì´ë²¤íŠ¸, ìŠ¹ë¥  í†µê³„, ë¹ ë¥¸ í•™ìŠµ í¬ì¸íŠ¸
            return await self._generate_trading_weekly(data)

        elif persona == 'long_term':
            # ì¥ê¸°: í…Œë§ˆ ì§„í–‰ ìƒí™©, í€ë”ë©˜í„¸ ë³€í™”, í¬ì§€ì…˜ ì¡°ì • ì œì•ˆ
            return await self._generate_long_term_weekly(data)

        elif persona == 'dividend':
            # ë°°ë‹¹: ë°°ë‹¹ ë°œí‘œ, ë°°ë‹¹ ê·€ì¡±ì£¼ ë³€ë™, ìˆ˜ìµë¥  ë¶„ì„
            return await self._generate_dividend_weekly(data)

        elif persona == 'aggressive':
            # ì´ˆë‹¨ê¸°: ë³€ë™ì„± ë¶„ì„, ìµœê³ /ìµœì € ìˆ˜ìµ ê±°ë˜, ìœ„í—˜ ê²½ê³ 
            return await self._generate_aggressive_weekly(data)
```

---

## âš¡ Phase 4: Real-time Execution ì™„ì„± (Week 13-18)

### Week 13-15: ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° WebSocket

#### Day 65-70 (2026-04-21 ~ 2026-04-26): Market Data WebSocket Manager
```python
# backend/api/market_data_ws.py (ì‹ ê·œ)

from fastapi import WebSocket, WebSocketDisconnect
from typing import Set, List, Dict
import asyncio
import yfinance as yf
from datetime import datetime

class MarketDataWebSocketManager:
    """Real-time market data streaming via WebSocket"""

    def __init__(self):
        self.active_connections: Dict[WebSocket, Set[str]] = {}
        self.quote_tasks: Dict[str, asyncio.Task] = {}

    async def connect(self, websocket: WebSocket):
        """Accept WebSocket connection"""
        await websocket.accept()
        self.active_connections[websocket] = set()
        logger.info(f"[MarketDataWS] New connection. Total: {len(self.active_connections)}")

    def disconnect(self, websocket: WebSocket):
        """Remove WebSocket connection"""
        if websocket in self.active_connections:
            symbols = self.active_connections[websocket]
            del self.active_connections[websocket]

            # Stop quote tasks if no more subscribers
            for symbol in symbols:
                if not self._has_subscribers(symbol):
                    self._stop_quote_task(symbol)

        logger.info(f"[MarketDataWS] Connection closed. Total: {len(self.active_connections)}")

    async def subscribe(self, websocket: WebSocket, symbols: List[str]):
        """Subscribe to symbols"""
        if websocket not in self.active_connections:
            return

        for symbol in symbols:
            self.active_connections[websocket].add(symbol)

            # Start quote task if not running
            if symbol not in self.quote_tasks:
                self.quote_tasks[symbol] = asyncio.create_task(
                    self._stream_quotes(symbol)
                )

    async def unsubscribe(self, websocket: WebSocket, symbols: List[str]):
        """Unsubscribe from symbols"""
        if websocket not in self.active_connections:
            return

        for symbol in symbols:
            self.active_connections[websocket].discard(symbol)

            # Stop quote task if no more subscribers
            if not self._has_subscribers(symbol):
                self._stop_quote_task(symbol)

    async def _stream_quotes(self, symbol: str):
        """Stream real-time quotes for a symbol"""
        try:
            while True:
                # Fetch latest quote
                ticker = yf.Ticker(symbol)
                info = ticker.info

                quote = {
                    'symbol': symbol,
                    'price': info.get('currentPrice'),
                    'change': info.get('regularMarketChangePercent'),
                    'volume': info.get('volume'),
                    'timestamp': datetime.now().isoformat()
                }

                # Broadcast to subscribers
                await self._broadcast_to_subscribers(symbol, {
                    'type': 'quote',
                    'data': quote
                })

                # Wait 5 seconds (adjust based on API limits)
                await asyncio.sleep(5)

        except asyncio.CancelledError:
            logger.info(f"[MarketDataWS] Quote stream stopped for {symbol}")
        except Exception as e:
            logger.error(f"[MarketDataWS] Error streaming {symbol}: {e}")

    async def _broadcast_to_subscribers(self, symbol: str, message: Dict):
        """Broadcast message to all subscribers of a symbol"""
        disconnected = []

        for websocket, symbols in self.active_connections.items():
            if symbol in symbols:
                try:
                    await websocket.send_json(message)
                except Exception as e:
                    logger.error(f"[MarketDataWS] Broadcast error: {e}")
                    disconnected.append(websocket)

        # Remove disconnected clients
        for ws in disconnected:
            self.disconnect(ws)

    def _has_subscribers(self, symbol: str) -> bool:
        """Check if symbol has any subscribers"""
        for symbols in self.active_connections.values():
            if symbol in symbols:
                return True
        return False

    def _stop_quote_task(self, symbol: str):
        """Stop quote streaming task"""
        if symbol in self.quote_tasks:
            self.quote_tasks[symbol].cancel()
            del self.quote_tasks[symbol]

# Global instance
market_data_ws_manager = MarketDataWebSocketManager()

# FastAPI endpoint
@router.websocket("/api/market-data/ws")
async def market_data_websocket(websocket: WebSocket):
    """WebSocket endpoint for real-time market data"""
    await market_data_ws_manager.connect(websocket)

    try:
        while True:
            # Receive client messages
            message = await websocket.receive_json()

            if message['type'] == 'subscribe':
                await market_data_ws_manager.subscribe(
                    websocket,
                    message['symbols']
                )
            elif message['type'] == 'unsubscribe':
                await market_data_ws_manager.unsubscribe(
                    websocket,
                    message['symbols']
                )

    except WebSocketDisconnect:
        market_data_ws_manager.disconnect(websocket)
```

#### Day 71-75 (2026-04-27 ~ 2026-05-01): í”„ë¡ íŠ¸ì—”ë“œ WebSocket í´ë¼ì´ì–¸íŠ¸
```tsx
// frontend/src/hooks/useMarketDataWebSocket.ts

import { useState, useEffect, useRef } from 'react';

interface Quote {
  symbol: string;
  price: number;
  change: number;
  volume: number;
  timestamp: string;
}

export const useMarketDataWebSocket = (symbols: string[]) => {
  const [quotes, setQuotes] = useState<Record<string, Quote>>({});
  const [isConnected, setIsConnected] = useState(false);
  const wsRef = useRef<WebSocket | null>(null);

  useEffect(() => {
    // Connect to WebSocket
    const ws = new WebSocket('ws://localhost:8001/api/market-data/ws');
    wsRef.current = ws;

    ws.onopen = () => {
      console.log('[MarketDataWS] Connected');
      setIsConnected(true);

      // Subscribe to symbols
      ws.send(JSON.stringify({
        type: 'subscribe',
        symbols: symbols
      }));
    };

    ws.onmessage = (event) => {
      const message = JSON.parse(event.data);

      if (message.type === 'quote') {
        const quote = message.data;
        setQuotes((prev) => ({
          ...prev,
          [quote.symbol]: quote
        }));
      }
    };

    ws.onerror = (error) => {
      console.error('[MarketDataWS] Error:', error);
    };

    ws.onclose = () => {
      console.log('[MarketDataWS] Disconnected');
      setIsConnected(false);
    };

    // Cleanup
    return () => {
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({
          type: 'unsubscribe',
          symbols: symbols
        }));
        ws.close();
      }
    };
  }, [symbols.join(',')]);

  return { quotes, isConnected };
};

// ì‚¬ìš© ì˜ˆì‹œ
export const RealTimeChart: React.FC = () => {
  const { quotes, isConnected } = useMarketDataWebSocket(['NVDA', 'MSFT', 'AAPL']);

  return (
    <div>
      <div>Status: {isConnected ? 'ğŸŸ¢ Connected' : 'ğŸ”´ Disconnected'}</div>
      {Object.values(quotes).map(quote => (
        <div key={quote.symbol}>
          {quote.symbol}: ${quote.price} ({quote.change > 0 ? '+' : ''}{quote.change}%)
        </div>
      ))}
    </div>
  );
};
```

### Week 16-17: ëª¨ë°”ì¼ ì•Œë¦¼ í™•ì¥

#### Day 80-85 (2026-05-05 ~ 2026-05-10): Push Notification Service
```python
# backend/services/push_notification_service.py (ì‹ ê·œ)

from firebase_admin import messaging, credentials, initialize_app
import os
from typing import Dict, List

# Firebase ì´ˆê¸°í™”
cred = credentials.Certificate(os.getenv('FIREBASE_CREDENTIALS_PATH'))
initialize_app(cred)

class PushNotificationService:
    """Send push notifications to mobile devices"""

    async def send_conflict_alert(
        self,
        user_tokens: List[str],
        conflict: Dict
    ):
        """Send conflict alert to mobile devices"""

        message = messaging.MulticastMessage(
            notification=messaging.Notification(
                title='âš ï¸ Strategy Conflict Detected',
                body=f"{conflict['ticker']}: {conflict['message']}"
            ),
            data={
                'type': 'conflict',
                'ticker': conflict['ticker'],
                'conflicting_strategy': conflict['conflicting_strategy'],
                'owning_strategy': conflict['owning_strategy'],
                'resolution': conflict['resolution']
            },
            tokens=user_tokens
        )

        response = messaging.send_multicast(message)

        return {
            'success_count': response.success_count,
            'failure_count': response.failure_count
        }

    async def send_signal_alert(
        self,
        user_tokens: List[str],
        signal: Dict
    ):
        """Send trading signal alert"""

        message = messaging.MulticastMessage(
            notification=messaging.Notification(
                title=f"ğŸš¨ {signal['action']} Signal: {signal['ticker']}",
                body=f"Confidence: {signal['confidence']:.0%} | Reason: {signal['reasoning'][:50]}..."
            ),
            data={
                'type': 'signal',
                'ticker': signal['ticker'],
                'action': signal['action'],
                'confidence': str(signal['confidence']),
                'reasoning': signal['reasoning']
            },
            tokens=user_tokens
        )

        response = messaging.send_multicast(message)

        return {
            'success_count': response.success_count,
            'failure_count': response.failure_count
        }

    async def send_daily_briefing(
        self,
        user_tokens: List[str],
        briefing_summary: str
    ):
        """Send daily briefing notification"""

        message = messaging.MulticastMessage(
            notification=messaging.Notification(
                title='ğŸ“Š Daily Briefing Available',
                body=briefing_summary
            ),
            data={
                'type': 'briefing',
                'url': '/briefing/latest'
            },
            tokens=user_tokens
        )

        response = messaging.send_multicast(message)

        return {
            'success_count': response.success_count,
            'failure_count': response.failure_count
        }

# Event Bus í†µí•©
from backend.events.subscribers import event_bus

@event_bus.subscribe('CONFLICT_DETECTED')
async def on_conflict_detected(event):
    """Send push notification on conflict"""
    push_service = PushNotificationService()

    # Get user tokens from DB
    # (ì‚¬ìš©ìê°€ ì•±ì—ì„œ ë“±ë¡í•œ FCM í† í°)
    user_tokens = await get_user_fcm_tokens()

    await push_service.send_conflict_alert(user_tokens, event.data)

@event_bus.subscribe('TRADING_SIGNAL_GENERATED')
async def on_signal_generated(event):
    """Send push notification on signal"""
    push_service = PushNotificationService()
    user_tokens = await get_user_fcm_tokens()

    await push_service.send_signal_alert(user_tokens, event.data)
```

### Week 18: Live Dashboard

#### Day 90-95 (2026-05-26 ~ 2026-05-31): Live Dashboard í†µí•©
```tsx
// frontend/src/pages/LiveDashboard.tsx

import { useMarketDataWebSocket } from '@/hooks/useMarketDataWebSocket';
import { useConflictWebSocket } from '@/hooks/useConflictWebSocket';
import { RealTimeChart } from '@/components/RealTimeChart';
import { ConflictAlert } from '@/components/ConflictAlert';
import { LiveSignals } from '@/components/LiveSignals';

export const LiveDashboard: React.FC = () => {
  const { quotes, isConnected: marketConnected } = useMarketDataWebSocket([
    'NVDA', 'MSFT', 'AAPL', 'GOOGL', 'AMZN'
  ]);

  const { conflicts, isConnected: conflictConnected } = useConflictWebSocket();

  return (
    <div className="live-dashboard">
      <div className="connection-status">
        <Tag color={marketConnected ? 'green' : 'red'}>
          Market Data: {marketConnected ? 'Connected' : 'Disconnected'}
        </Tag>
        <Tag color={conflictConnected ? 'green' : 'red'}>
          Conflict Alerts: {conflictConnected ? 'Connected' : 'Disconnected'}
        </Tag>
      </div>

      <Row gutter={16}>
        <Col span={16}>
          <RealTimeChart quotes={quotes} />
        </Col>
        <Col span={8}>
          <ConflictAlert conflicts={conflicts} />
          <LiveSignals />
        </Col>
      </Row>
    </div>
  );
};
```

---

## ğŸ“ˆ Phase 5: Advanced Risk Models ì™„ì„± (Week 19-22)

### Week 19-20: VaR ê³„ì‚°

#### Day 100-105 (2026-06-02 ~ 2026-06-07): VaR Calculator êµ¬í˜„
```python
# backend/analytics/var_calculator.py (ì‹ ê·œ)

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple
from datetime import datetime, timedelta
from scipy.stats import norm

class VaRCalculator:
    """Value at Risk Calculator"""

    def __init__(self):
        self.confidence_levels = [0.95, 0.99]
        self.time_horizons = [1, 10]  # days

    def calculate_historical_var(
        self,
        returns: np.ndarray,
        confidence_level: float = 0.95,
        time_horizon: int = 1
    ) -> float:
        """
        Historical VaR calculation

        Args:
            returns: Array of historical returns
            confidence_level: Confidence level (0.95 = 95%)
            time_horizon: Time horizon in days

        Returns:
            VaR value (negative number indicating loss)
        """
        # Sort returns
        sorted_returns = np.sort(returns)

        # Find percentile
        index = int((1 - confidence_level) * len(sorted_returns))
        var = sorted_returns[index]

        # Scale by time horizon (sqrt rule)
        var_scaled = var * np.sqrt(time_horizon)

        return var_scaled

    def calculate_parametric_var(
        self,
        returns: np.ndarray,
        confidence_level: float = 0.95,
        time_horizon: int = 1
    ) -> float:
        """
        Parametric VaR (assumes normal distribution)

        VaR = mean + z_score * std * sqrt(horizon)
        """
        mean = np.mean(returns)
        std = np.std(returns)
        z_score = norm.ppf(1 - confidence_level)

        var = mean + z_score * std * np.sqrt(time_horizon)

        return var

    def calculate_monte_carlo_var(
        self,
        portfolio: Dict[str, float],  # {symbol: weight}
        returns_history: pd.DataFrame,  # Columns = symbols
        confidence_level: float = 0.95,
        time_horizon: int = 1,
        simulations: int = 10000
    ) -> Tuple[float, np.ndarray]:
        """
        Monte Carlo VaR simulation

        Returns:
            (VaR value, simulated returns array)
        """
        # Calculate portfolio statistics
        symbols = list(portfolio.keys())
        weights = np.array([portfolio[s] for s in symbols])

        # Historical mean and covariance
        mean_returns = returns_history[symbols].mean().values
        cov_matrix = returns_history[symbols].cov().values

        # Simulate portfolio returns
        simulated_returns = np.random.multivariate_normal(
            mean_returns,
            cov_matrix,
            size=simulations
        )

        # Calculate portfolio returns
        portfolio_returns = simulated_returns @ weights

        # Scale by time horizon
        portfolio_returns_scaled = portfolio_returns * np.sqrt(time_horizon)

        # Calculate VaR
        var = np.percentile(portfolio_returns_scaled, (1 - confidence_level) * 100)

        return var, portfolio_returns_scaled

    def calculate_conditional_var(
        self,
        returns: np.ndarray,
        confidence_level: float = 0.95
    ) -> float:
        """
        Conditional VaR (Expected Shortfall)

        Average loss given that VaR is exceeded
        """
        var = self.calculate_historical_var(returns, confidence_level)

        # Returns worse than VaR
        tail_returns = returns[returns <= var]

        # Average of tail
        cvar = np.mean(tail_returns) if len(tail_returns) > 0 else var

        return cvar

    async def calculate_portfolio_var(
        self,
        portfolio_id: str,
        db: Session
    ) -> Dict:
        """Calculate VaR for entire portfolio"""

        # Fetch portfolio positions
        positions = await self._fetch_portfolio_positions(portfolio_id, db)

        # Fetch historical returns (252 days = 1 year)
        returns_df = await self._fetch_returns_history(
            list(positions.keys()),
            days=252
        )

        results = {}

        # Historical VaR
        for conf_level in self.confidence_levels:
            for horizon in self.time_horizons:
                key = f"historical_var_{int(conf_level*100)}_{horizon}d"

                # Monte Carlo simulation
                var, simulations = self.calculate_monte_carlo_var(
                    portfolio=positions,
                    returns_history=returns_df,
                    confidence_level=conf_level,
                    time_horizon=horizon,
                    simulations=10000
                )

                results[key] = {
                    'var': float(var),
                    'conf_level': conf_level,
                    'time_horizon': horizon,
                    'method': 'monte_carlo',
                    'simulations': 10000
                }

        # Conditional VaR (CVaR)
        portfolio_returns = returns_df @ np.array(list(positions.values()))
        results['cvar_95'] = self.calculate_conditional_var(
            portfolio_returns.values,
            confidence_level=0.95
        )

        return results
```

#### Day 106-110 (2026-06-08 ~ 2026-06-12): DB ëª¨ë¸ ë° API
```python
# backend/database/models.py ì¶”ê°€

class PortfolioRisk(Base):
    __tablename__ = 'portfolio_risk'

    id = Column(Integer, primary_key=True)
    portfolio_id = Column(UUID, ForeignKey('portfolios.id'))

    # VaR values (negative = loss)
    var_1day_95 = Column(Float)  # 1-day 95% VaR
    var_1day_99 = Column(Float)  # 1-day 99% VaR
    var_10day_95 = Column(Float)  # 10-day 95% VaR
    var_10day_99 = Column(Float)  # 10-day 99% VaR

    # Conditional VaR
    cvar_95 = Column(Float)
    cvar_99 = Column(Float)

    # Metadata
    method = Column(String(50))  # historical, parametric, monte_carlo
    simulations = Column(Integer)  # For Monte Carlo
    calculated_at = Column(DateTime, default=datetime.utcnow)

    portfolio = relationship('Portfolio', back_populates='risk_metrics')

# backend/api/risk_router.py (ì‹ ê·œ)

@router.get("/api/portfolios/{portfolio_id}/var")
async def get_portfolio_var(
    portfolio_id: str,
    db: Session = Depends(get_sync_session)
):
    """Get portfolio VaR metrics"""

    calculator = VaRCalculator()
    var_metrics = await calculator.calculate_portfolio_var(portfolio_id, db)

    # Save to DB
    risk_record = PortfolioRisk(
        portfolio_id=portfolio_id,
        var_1day_95=var_metrics['historical_var_95_1d']['var'],
        var_1day_99=var_metrics['historical_var_99_1d']['var'],
        var_10day_95=var_metrics['historical_var_95_10d']['var'],
        var_10day_99=var_metrics['historical_var_99_10d']['var'],
        cvar_95=var_metrics['cvar_95'],
        method='monte_carlo',
        simulations=10000
    )
    db.add(risk_record)
    db.commit()

    return var_metrics
```

### Week 21: Sharpe/Sortino Ratio

#### Day 111-115 (2026-06-09 ~ 2026-06-13): Risk-Adjusted Metrics
```python
# backend/analytics/risk_adjusted_metrics.py (ì‹ ê·œ)

class RiskAdjustedMetrics:
    """Calculate risk-adjusted performance metrics"""

    def __init__(self, risk_free_rate: float = 0.04):
        """
        Args:
            risk_free_rate: Annual risk-free rate (default 4%)
        """
        self.risk_free_rate = risk_free_rate
        self.daily_rfr = risk_free_rate / 252

    def calculate_sharpe_ratio(
        self,
        returns: np.ndarray,
        annualize: bool = True
    ) -> float:
        """
        Sharpe Ratio = (Return - RFR) / Std Dev

        Higher is better
        > 1.0 = Good
        > 2.0 = Very Good
        > 3.0 = Excellent
        """
        excess_return = np.mean(returns) - self.daily_rfr
        std_dev = np.std(returns)

        sharpe = excess_return / std_dev if std_dev > 0 else 0

        if annualize:
            sharpe *= np.sqrt(252)

        return sharpe

    def calculate_sortino_ratio(
        self,
        returns: np.ndarray,
        annualize: bool = True
    ) -> float:
        """
        Sortino Ratio = (Return - RFR) / Downside Dev

        Only penalizes downside volatility
        Better than Sharpe for asymmetric returns
        """
        excess_return = np.mean(returns) - self.daily_rfr

        # Downside returns only
        downside_returns = returns[returns < self.daily_rfr]
        downside_std = np.std(downside_returns) if len(downside_returns) > 0 else 0

        sortino = excess_return / downside_std if downside_std > 0 else 0

        if annualize:
            sortino *= np.sqrt(252)

        return sortino

    def calculate_calmar_ratio(
        self,
        returns: np.ndarray,
        annualize: bool = True
    ) -> float:
        """
        Calmar Ratio = Annual Return / Max Drawdown

        Measures return vs worst drawdown
        """
        annual_return = np.mean(returns) * 252 if annualize else np.mean(returns)

        # Calculate max drawdown
        cumulative = (1 + returns).cumprod()
        running_max = np.maximum.accumulate(cumulative)
        drawdown = (cumulative - running_max) / running_max
        max_drawdown = np.min(drawdown)

        calmar = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0

        return calmar

    def calculate_all_ratios(
        self,
        returns: np.ndarray
    ) -> Dict[str, float]:
        """Calculate all risk-adjusted ratios"""

        return {
            'sharpe_ratio': self.calculate_sharpe_ratio(returns),
            'sortino_ratio': self.calculate_sortino_ratio(returns),
            'calmar_ratio': self.calculate_calmar_ratio(returns),
            'annual_return': np.mean(returns) * 252,
            'annual_volatility': np.std(returns) * np.sqrt(252),
            'max_drawdown': self._calculate_max_drawdown(returns)
        }

    def _calculate_max_drawdown(self, returns: np.ndarray) -> float:
        """Calculate maximum drawdown"""
        cumulative = (1 + returns).cumprod()
        running_max = np.maximum.accumulate(cumulative)
        drawdown = (cumulative - running_max) / running_max
        return np.min(drawdown)

# backend/database/models.py ì¶”ê°€

class StrategyPerformance(Base):
    __tablename__ = 'strategy_performance'

    id = Column(Integer, primary_key=True)
    strategy_id = Column(UUID, ForeignKey('strategies.id'))

    # Risk-adjusted metrics
    sharpe_ratio = Column(Float)
    sortino_ratio = Column(Float)
    calmar_ratio = Column(Float)

    # Basic metrics
    annual_return = Column(Float)
    annual_volatility = Column(Float)
    max_drawdown = Column(Float)

    # Period
    start_date = Column(Date)
    end_date = Column(Date)
    measured_at = Column(DateTime, default=datetime.utcnow)

    strategy = relationship('Strategy', back_populates='performance_metrics')
```

### Week 22: Beta/Correlation

#### Day 116-120 (2026-06-14 ~ 2026-06-18): Correlation Analyzer
```python
# backend/analytics/correlation_analyzer.py (ì‹ ê·œ)

class CorrelationAnalyzer:
    """Analyze portfolio correlations and diversification"""

    def calculate_beta(
        self,
        stock_returns: np.ndarray,
        market_returns: np.ndarray
    ) -> Dict[str, float]:
        """
        Calculate beta to market (SPY)

        Beta = Cov(stock, market) / Var(market)

        Beta > 1: More volatile than market
        Beta = 1: Matches market
        Beta < 1: Less volatile than market
        """
        covariance = np.cov(stock_returns, market_returns)[0][1]
        market_variance = np.var(market_returns)

        beta = covariance / market_variance if market_variance > 0 else 1.0

        # R-squared (correlation strength)
        correlation = np.corrcoef(stock_returns, market_returns)[0][1]
        r_squared = correlation ** 2

        return {
            'beta': beta,
            'r_squared': r_squared,
            'correlation': correlation
        }

    def calculate_correlation_matrix(
        self,
        returns_df: pd.DataFrame
    ) -> pd.DataFrame:
        """
        Calculate correlation matrix for portfolio

        Returns correlation matrix (symbols Ã— symbols)
        """
        return returns_df.corr()

    def calculate_diversification_score(
        self,
        correlation_matrix: pd.DataFrame
    ) -> float:
        """
        Calculate diversification score (0-100)

        Lower correlation = higher diversification
        Score = (1 - avg_correlation) * 100
        """
        # Get upper triangle (exclude diagonal)
        upper_triangle = correlation_matrix.values[
            np.triu_indices_from(correlation_matrix.values, k=1)
        ]

        avg_correlation = np.mean(upper_triangle)

        # Convert to 0-100 scale
        diversification_score = (1 - avg_correlation) * 100

        return max(0, min(100, diversification_score))

    def identify_clusters(
        self,
        correlation_matrix: pd.DataFrame,
        threshold: float = 0.7
    ) -> List[List[str]]:
        """
        Identify highly correlated clusters

        Clusters: Groups of stocks with correlation > threshold
        """
        from scipy.cluster.hierarchy import linkage, fcluster

        # Hierarchical clustering
        linkage_matrix = linkage(correlation_matrix, method='average')

        # Form clusters
        cluster_labels = fcluster(linkage_matrix, t=1-threshold, criterion='distance')

        # Group by cluster
        clusters = {}
        for i, symbol in enumerate(correlation_matrix.index):
            cluster_id = cluster_labels[i]
            if cluster_id not in clusters:
                clusters[cluster_id] = []
            clusters[cluster_id].append(symbol)

        return list(clusters.values())

    async def analyze_portfolio_correlation(
        self,
        portfolio_id: str,
        db: Session
    ) -> Dict:
        """Comprehensive portfolio correlation analysis"""

        # Fetch positions
        positions = await self._fetch_portfolio_positions(portfolio_id, db)
        symbols = list(positions.keys())

        # Fetch returns (1 year)
        returns_df = await self._fetch_returns_history(symbols, days=252)

        # Fetch market returns (SPY)
        market_returns = await self._fetch_market_returns(days=252)

        # 1. Correlation matrix
        corr_matrix = self.calculate_correlation_matrix(returns_df)

        # 2. Beta to market for each stock
        betas = {}
        for symbol in symbols:
            betas[symbol] = self.calculate_beta(
                returns_df[symbol].values,
                market_returns.values
            )

        # 3. Diversification score
        div_score = self.calculate_diversification_score(corr_matrix)

        # 4. Identify clusters
        clusters = self.identify_clusters(corr_matrix, threshold=0.7)

        return {
            'correlation_matrix': corr_matrix.to_dict(),
            'betas': betas,
            'diversification_score': div_score,
            'clusters': clusters,
            'summary': {
                'avg_correlation': corr_matrix.values[
                    np.triu_indices_from(corr_matrix.values, k=1)
                ].mean(),
                'max_correlation': corr_matrix.values[
                    np.triu_indices_from(corr_matrix.values, k=1)
                ].max(),
                'portfolio_beta': np.mean([b['beta'] for b in betas.values()])
            }
        }
```

---

## ğŸ‰ Phase 6: ìµœì¢… ê²€ì¦ ë° ë¬¸ì„œí™” (Week 23-26)

### Week 23: í†µí•© í…ŒìŠ¤íŠ¸

#### Day 121-125 (2026-06-19 ~ 2026-06-23): E2E í…ŒìŠ¤íŠ¸
```bash
# E2E í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

# 1. Persona-based Trading
- [ ] Trading í˜ë¥´ì†Œë‚˜ ë¸Œë¦¬í•‘ ìƒì„±
- [ ] Long-term í˜ë¥´ì†Œë‚˜ ë¸Œë¦¬í•‘ ìƒì„±
- [ ] Dividend í˜ë¥´ì†Œë‚˜ ë¸Œë¦¬í•‘ ìƒì„±
- [ ] Aggressive í˜ë¥´ì†Œë‚˜ ë¸Œë¦¬í•‘ ìƒì„±
- [ ] í˜ë¥´ì†Œë‚˜ ì „í™˜ UI í…ŒìŠ¤íŠ¸

# 2. Real-time Execution
- [ ] WebSocket ì—°ê²° í…ŒìŠ¤íŠ¸
- [ ] ì‹¤ì‹œê°„ ì‹œì„¸ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸
- [ ] Conflict alert WebSocket í…ŒìŠ¤íŠ¸
- [ ] Push notification í…ŒìŠ¤íŠ¸ (Firebase)
- [ ] Live Dashboard ë Œë”ë§ í…ŒìŠ¤íŠ¸

# 3. Advanced Risk Models
- [ ] VaR ê³„ì‚° (Historical, Parametric, Monte Carlo)
- [ ] Sharpe/Sortino/Calmar Ratio ê³„ì‚°
- [ ] Beta ê³„ì‚° (vs SPY)
- [ ] Correlation matrix ìƒì„±
- [ ] Diversification score ê³„ì‚°

# ì‹¤í–‰
cd frontend
npm run test:e2e
```

### Week 24: ë¬¸ì„œí™”

#### Day 126-130 (2026-06-24 ~ 2026-06-28): ë¬¸ì„œ ì—…ë°ì´íŠ¸
```markdown
# ì—…ë°ì´íŠ¸í•  ë¬¸ì„œ ëª©ë¡

1. SYSTEM_STATUS_MAP.md
   - Persona-based Trading: 50% â†’ 100%
   - Real-time Execution: 70% â†’ 100%
   - Advanced Risk Models: 30% â†’ 100%

2. API ë¬¸ì„œ
   - /api/briefing/persona/{persona}
   - /api/market-data/ws
   - /api/portfolios/{id}/var
   - /api/portfolios/{id}/correlation

3. ì‚¬ìš©ì ê°€ì´ë“œ
   - Persona ì„ íƒ ê°€ì´ë“œ
   - WebSocket ì—°ê²° ê°€ì´ë“œ
   - Risk Metrics í•´ì„ ê°€ì´ë“œ

4. ê°œë°œì ê°€ì´ë“œ
   - Persona í™•ì¥ ë°©ë²•
   - WebSocket í´ë¼ì´ì–¸íŠ¸ ì‘ì„±
   - Risk Model ì»¤ìŠ¤í„°ë§ˆì´ì§•
```

### Week 25-26: ë°°í¬ ë° ëª¨ë‹ˆí„°ë§

#### Day 131-140 (2026-06-29 ~ 2026-07-08): í”„ë¡œë•ì…˜ ë°°í¬
```bash
# 1. í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ë¶€í•˜ í…ŒìŠ¤íŠ¸)
- [ ] ë³´ì•ˆ ê²€ì‚¬
- [ ] ë°±ì—… ìƒì„±
- [ ] ë¡¤ë°± ê³„íš ìˆ˜ë¦½

# 2. ë°°í¬ ì‹¤í–‰
git tag -a v3.0.0 -m "Release v3.0.0: Complete feature set"
git push origin v3.0.0

# 3. ëª¨ë‹ˆí„°ë§ ì„¤ì •
- Prometheus ë©”íŠ¸ë¦­ í™•ì¸
- ë¡œê·¸ ëª¨ë‹ˆí„°ë§
- ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘

# 4. ê³µì§€
- ì‚¬ìš©ì ê³µì§€ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
- Migration ê°€ì´ë“œ ì œê³µ
- FAQ ì—…ë°ì´íŠ¸
```

---

## ğŸ“Š ìµœì¢… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë ˆê±°ì‹œ ì •ë¦¬
- [ ] backend/ai/legacy/debate/ ì œê±° âœ… (Phase 1 ì™„ë£Œ)
- [ ] backend/ai/debate/ ì œê±°
- [ ] backend/api/war_room_router.py ì œê±°
- [ ] backend/api/phase_integration_router.py ì œê±°
- [ ] ê´€ë ¨ í…ŒìŠ¤íŠ¸ ì œê±°
- [ ] Structure Map ì—…ë°ì´íŠ¸

### ë¬¸ì„œ ì••ì¶•
- [ ] 583ê°œ â†’ 200ê°œ í•µì‹¬ ë¬¸ì„œ
- [ ] legacy/archive ì´ë™
- [ ] ë¬¸ì„œ êµ¬ì¡° ì¬í¸
- [ ] README ì—…ë°ì´íŠ¸

### Persona-based Trading
- [ ] DailyBriefingService í˜ë¥´ì†Œë‚˜ ë¶„ë¦¬
- [ ] API ì—”ë“œí¬ì¸íŠ¸ (/api/briefing/persona/{persona})
- [ ] PersonaSelector UI ì»´í¬ë„ŒíŠ¸
- [ ] í˜ë¥´ì†Œë‚˜ë³„ ëŒ€ì‹œë³´ë“œ ë ˆì´ì•„ì›ƒ
- [ ] Weekly/Monthly Report í˜ë¥´ì†Œë‚˜ í™•ì¥

### Real-time Execution
- [ ] MarketDataWebSocketManager êµ¬í˜„
- [ ] í”„ë¡ íŠ¸ì—”ë“œ WebSocket í´ë¼ì´ì–¸íŠ¸
- [ ] Push Notification Service (Firebase)
- [ ] Email/SMS ì•Œë¦¼
- [ ] Live Dashboard

### Advanced Risk Models
- [ ] VaR Calculator (Historical, Parametric, Monte Carlo)
- [ ] RiskAdjustedMetrics (Sharpe, Sortino, Calmar)
- [ ] CorrelationAnalyzer (Beta, Correlation Matrix)
- [ ] DB ëª¨ë¸ (PortfolioRisk, StrategyPerformance)
- [ ] API ì—”ë“œí¬ì¸íŠ¸

---

## ğŸ“… ë§ˆì¼ìŠ¤í†¤ ìš”ì•½

| Week | Phase | ì£¼ìš” ì‘ì—… | ì™„ë£Œ ê¸°ì¤€ |
|------|-------|----------|----------|
| 1-2 | ë ˆê±°ì‹œ ì¡°ì‚¬ | War Room Legacy ì‚¬ìš© í˜„í™©, Deprecation | ì¡°ì‚¬ ë³´ê³ ì„œ ì™„ì„± |
| 3-4 | ë ˆê±°ì‹œ ì œê±° | Debate ì œê±°, Router ì œê±° | ë ˆê±°ì‹œ ì½”ë“œ 0% |
| 5-6 | ë¬¸ì„œ ì••ì¶• | 583 â†’ 200 ë¬¸ì„œ | í•µì‹¬ 200ê°œ ì„ ì • |
| 7-12 | Persona Trading | Briefing ë¶„ë¦¬, UI, Report | 100% ì™„ì„± |
| 13-18 | Real-time | WebSocket, Push, Dashboard | 100% ì™„ì„± |
| 19-22 | Risk Models | VaR, Sharpe, Beta | 100% ì™„ì„± |
| 23-26 | ìµœì¢… ê²€ì¦ | í…ŒìŠ¤íŠ¸, ë¬¸ì„œ, ë°°í¬ | v3.0.0 ë¦´ë¦¬ìŠ¤ |

---

## ğŸ¯ ì„±ê³µ ì§€í‘œ

### ì •ëŸ‰ì  ì§€í‘œ

| ì§€í‘œ | Before | After (ëª©í‘œ) |
|------|--------|-------------|
| **ë ˆê±°ì‹œ ì½”ë“œ** | 15% | 0% |
| **ë¬¸ì„œ ìˆ˜** | 583ê°œ | 200ê°œ |
| **Persona Trading** | 50% | 100% |
| **Real-time** | 70% | 100% |
| **Risk Models** | 30% | 100% |
| **ì „ì²´ ì™„ì„±ë„** | 85% | 100% |

### ì •ì„±ì  ì§€í‘œ

- âœ… ì½”ë“œë² ì´ìŠ¤ ëª…í™•ì„± (ë‹¨ì¼ War Room ì‹œìŠ¤í…œ)
- âœ… ë¬¸ì„œ ì ‘ê·¼ì„± (200ê°œ í•µì‹¬ ë¬¸ì„œ)
- âœ… ì‚¬ìš©ì ê²½í—˜ (í˜ë¥´ì†Œë‚˜ë³„ ë§ì¶¤ ì„œë¹„ìŠ¤)
- âœ… ì‹¤ì‹œê°„ì„± (WebSocket ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸)
- âœ… ë¦¬ìŠ¤í¬ ê´€ë¦¬ (ê³ ê¸‰ Risk Metrics)

---

## ğŸ“ ì°¸ê³  ë¬¸ì„œ

- [SYSTEM_STATUS_MAP.md](../SYSTEM_STATUS_MAP.md) - ì‹œìŠ¤í…œ í˜„í™©
- [LEGACY_CLEANUP_PLAN.md](../LEGACY_CLEANUP_PLAN.md) - ë ˆê±°ì‹œ ì •ë¦¬
- [PARTIAL_IMPLEMENTATION_REVIEW.md](../PARTIAL_IMPLEMENTATION_REVIEW.md) - ë¶€ë¶„ êµ¬í˜„ ê²€í† 

---

**ì‘ì„±ì**: AI Trading System Team
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2026-01-25
**ë‹¤ìŒ ë¦¬ë·°**: Week 2 ì¢…ë£Œ ì‹œ (2026-02-09)
**ìƒíƒœ**: ğŸ“‹ Ready to Execute
