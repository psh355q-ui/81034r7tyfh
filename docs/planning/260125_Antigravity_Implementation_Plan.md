# AI Trading System - Antigravity ììœ¨ ì‹¤í–‰ ê³„íš

**ì‘ì„±ì¼**: 2026-01-25
**ì‹¤í–‰ ëª¨ë“œ**: Antigravity Agentic Workflow
**ê¸°ê°„**: 2026-01-27 ~ 2026-06-30 (26ì£¼)
**ëª©í‘œ**: AI ì£¼ë„ TDD + ììœ¨ ê²€ì¦ + ìë™ ë¬¸ì„œí™”ë¡œ 100% ì™„ì„±

---

## ğŸ¤– Antigravity ì›Œí¬í”Œë¡œìš° ì›ì¹™

### 1. AI-First Development
- **ëª¨ë“  ê¸°ëŠ¥ì€ í…ŒìŠ¤íŠ¸ê°€ ë¨¼ì €** (TDD ê°•ì œ)
- **AIê°€ í…ŒìŠ¤íŠ¸ ì‘ì„± â†’ êµ¬í˜„ â†’ ê²€ì¦** ììœ¨ ìˆ˜í–‰
- **ì‚¬ëŒì€ ìŠ¹ì¸ë§Œ** (Plan â†’ Approve â†’ Execute)

### 2. Self-Validating Tasks
ê° íƒœìŠ¤í¬ëŠ” ë‹¤ìŒì„ í¬í•¨:
- **ì…ë ¥**: í•„ìš”í•œ ë°ì´í„°/íŒŒì¼
- **ì¶œë ¥**: ìƒì„±ë  íŒŒì¼/ê²°ê³¼
- **ê²€ì¦**: ìë™ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
- **ì™„ë£Œ ì¡°ê±´**: ëª…í™•í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### 3. Continuous Documentation
- Structure Map ìë™ ì—…ë°ì´íŠ¸
- ë¬¸ì„œ ìë™ ìƒì„± (ì½”ë“œ â†’ ë¬¸ì„œ)
- ë³€ê²½ ì‚¬í•­ ìë™ ì¶”ì 

---

## ğŸ“‹ Phase 0: Antigravity í™˜ê²½ êµ¬ì¶• (Week 0)

### T0.1: Antigravity Test Harness êµ¬ì¶•

#### ì…ë ¥
- í˜„ì¬ í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ (`tests/`, `frontend/tests/`)
- í…ŒìŠ¤íŠ¸ ëŸ¬ë„ˆ ì„¤ì • (`pytest`, `playwright`)

#### ì¶œë ¥
```python
# backend/tests/antigravity/test_harness.py

"""
Antigravity Test Harness

Self-validating test infrastructure that:
1. Automatically discovers and runs all tests
2. Reports test coverage
3. Blocks commits if tests fail
4. Auto-generates test reports
"""

import pytest
import subprocess
from pathlib import Path
from typing import Dict, List
from datetime import datetime
import json

class AntigravityTestHarness:
    """ììœ¨ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²€ì¦"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.test_dirs = [
            project_root / "backend" / "tests",
            project_root / "frontend" / "tests"
        ]
        self.results = {}

    def run_all_tests(self) -> Dict:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜"""

        print("ğŸ¤– [Antigravity] Running all tests...")

        # Backend tests
        backend_result = self._run_backend_tests()

        # Frontend E2E tests
        frontend_result = self._run_frontend_tests()

        # Combine results
        self.results = {
            'backend': backend_result,
            'frontend': frontend_result,
            'timestamp': datetime.now().isoformat(),
            'overall_pass': backend_result['passed'] and frontend_result['passed']
        }

        return self.results

    def _run_backend_tests(self) -> Dict:
        """ë°±ì—”ë“œ pytest ì‹¤í–‰"""

        result = subprocess.run(
            ['pytest', 'backend/tests/', '--cov=backend', '--cov-report=json'],
            capture_output=True,
            text=True,
            cwd=self.project_root
        )

        # Parse coverage
        coverage_file = self.project_root / 'coverage.json'
        coverage = 0
        if coverage_file.exists():
            with open(coverage_file) as f:
                cov_data = json.load(f)
                coverage = cov_data['totals']['percent_covered']

        return {
            'passed': result.returncode == 0,
            'output': result.stdout,
            'coverage': coverage,
            'test_count': self._count_tests(result.stdout)
        }

    def _run_frontend_tests(self) -> Dict:
        """í”„ë¡ íŠ¸ì—”ë“œ Playwright ì‹¤í–‰"""

        result = subprocess.run(
            ['npm', 'run', 'test:e2e', '--', '--reporter=json'],
            capture_output=True,
            text=True,
            cwd=self.project_root / 'frontend'
        )

        return {
            'passed': result.returncode == 0,
            'output': result.stdout,
            'test_count': self._count_playwright_tests(result.stdout)
        }

    def generate_report(self) -> Path:
        """í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìë™ ìƒì„±"""

        report_dir = self.project_root / 'docs' / 'test_reports'
        report_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = report_dir / f'test_report_{timestamp}.md'

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"# Test Report - {timestamp}\n\n")
            f.write(f"## Overall Status: {'âœ… PASS' if self.results['overall_pass'] else 'âŒ FAIL'}\n\n")

            f.write("## Backend Tests\n")
            f.write(f"- Status: {'âœ… PASS' if self.results['backend']['passed'] else 'âŒ FAIL'}\n")
            f.write(f"- Coverage: {self.results['backend']['coverage']:.1f}%\n")
            f.write(f"- Test Count: {self.results['backend']['test_count']}\n\n")

            f.write("## Frontend Tests\n")
            f.write(f"- Status: {'âœ… PASS' if self.results['frontend']['passed'] else 'âŒ FAIL'}\n")
            f.write(f"- Test Count: {self.results['frontend']['test_count']}\n\n")

        return report_path

    def _count_tests(self, output: str) -> int:
        """pytest ì¶œë ¥ì—ì„œ í…ŒìŠ¤íŠ¸ ê°œìˆ˜ íŒŒì‹±"""
        # "120 passed in 45.2s" íŒŒì‹±
        import re
        match = re.search(r'(\d+) passed', output)
        return int(match.group(1)) if match else 0

    def _count_playwright_tests(self, output: str) -> int:
        """Playwright ì¶œë ¥ì—ì„œ í…ŒìŠ¤íŠ¸ ê°œìˆ˜ íŒŒì‹±"""
        # JSON ë¦¬í¬íŠ¸ íŒŒì‹±
        try:
            data = json.loads(output)
            return len(data.get('tests', []))
        except:
            return 0

# CLI ì¸í„°í˜ì´ìŠ¤
if __name__ == '__main__':
    harness = AntigravityTestHarness(Path(__file__).parent.parent.parent.parent)
    results = harness.run_all_tests()
    report_path = harness.generate_report()

    print(f"\n{'='*60}")
    print(f"Test Report: {report_path}")
    print(f"Overall: {'âœ… PASS' if results['overall_pass'] else 'âŒ FAIL'}")
    print(f"{'='*60}\n")

    # Exit with error if tests failed
    import sys
    sys.exit(0 if results['overall_pass'] else 1)
```

#### ê²€ì¦
```bash
# ì‹¤í–‰
python backend/tests/antigravity/test_harness.py

# ì„±ê³µ ì¡°ê±´
# - Exit code 0 (ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼)
# - Coverage > 70%
# - ë¦¬í¬íŠ¸ ìƒì„±ë¨
```

#### ì™„ë£Œ ì¡°ê±´
- [ ] AntigravityTestHarness êµ¬í˜„ ì™„ë£Œ
- [ ] ë°±ì—”ë“œ + í”„ë¡ íŠ¸ì—”ë“œ í…ŒìŠ¤íŠ¸ ìë™ ì‹¤í–‰
- [ ] Coverage ë¦¬í¬íŠ¸ ìë™ ìƒì„±
- [ ] Git hook ì„¤ì • (pre-commit ì‹œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰)

---

### T0.2: Antigravity Document Generator êµ¬ì¶•

#### ì…ë ¥
- ì½”ë“œë² ì´ìŠ¤ (`backend/`, `frontend/`)
- ê¸°ì¡´ ë¬¸ì„œ (`docs/`)

#### ì¶œë ¥
```python
# scripts/antigravity_doc_generator.py

"""
Antigravity Document Generator

ìë™ ë¬¸ì„œí™”:
1. ì½”ë“œ â†’ API ë¬¸ì„œ ìë™ ìƒì„±
2. DB ëª¨ë¸ â†’ ERD ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
3. êµ¬ì¡° ë³€ê²½ ì‹œ Structure Map ìë™ ì—…ë°ì´íŠ¸
"""

from pathlib import Path
import ast
import json
from typing import Dict, List
from datetime import datetime

class AntigravityDocGenerator:
    """ììœ¨ ë¬¸ì„œ ìƒì„±ê¸°"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.backend_dir = project_root / 'backend'
        self.docs_dir = project_root / 'docs'

    def generate_api_docs(self) -> Path:
        """API ì—”ë“œí¬ì¸íŠ¸ ìë™ ë¬¸ì„œí™”"""

        api_dir = self.backend_dir / 'api'
        endpoints = []

        # ëª¨ë“  router íŒŒì¼ ë¶„ì„
        for router_file in api_dir.glob('*_router.py'):
            endpoints.extend(self._parse_fastapi_router(router_file))

        # ë¬¸ì„œ ìƒì„±
        doc_path = self.docs_dir / '04_API' / 'API_Reference.md'
        doc_path.parent.mkdir(parents=True, exist_ok=True)

        with open(doc_path, 'w', encoding='utf-8') as f:
            f.write("# API Reference\n\n")
            f.write(f"**Auto-generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            for endpoint in sorted(endpoints, key=lambda x: x['path']):
                f.write(f"## {endpoint['method']} {endpoint['path']}\n\n")
                f.write(f"**Description**: {endpoint['description']}\n\n")

                if endpoint['params']:
                    f.write("**Parameters**:\n")
                    for param in endpoint['params']:
                        f.write(f"- `{param['name']}` ({param['type']}): {param.get('description', '')}\n")
                    f.write("\n")

                if endpoint['response']:
                    f.write(f"**Response**: {endpoint['response']}\n\n")

                f.write("---\n\n")

        return doc_path

    def generate_db_erd(self) -> Path:
        """DB ëª¨ë¸ â†’ ERD ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±"""

        models_file = self.backend_dir / 'database' / 'models.py'

        # Parse SQLAlchemy models
        models = self._parse_sqlalchemy_models(models_file)

        # Generate Mermaid ERD
        erd_path = self.docs_dir / '01_Architecture' / 'Database_ERD.md'
        erd_path.parent.mkdir(parents=True, exist_ok=True)

        with open(erd_path, 'w', encoding='utf-8') as f:
            f.write("# Database Entity Relationship Diagram\n\n")
            f.write(f"**Auto-generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("```mermaid\nerDiagram\n")

            for model in models:
                # Table definition
                columns = " || ".join([f"{c['name']} {c['type']}" for c in model['columns']])
                f.write(f"    {model['table']} {{\n")
                for col in model['columns']:
                    f.write(f"        {col['type']} {col['name']}\n")
                f.write(f"    }}\n")

                # Relationships
                for rel in model.get('relationships', []):
                    f.write(f"    {model['table']} ||--o{{ {rel['target']} : {rel['name']}\n")

            f.write("```\n")

        return erd_path

    def update_structure_map(self) -> Path:
        """Structure Map ìë™ ì—…ë°ì´íŠ¸"""

        # Run existing structure_mapper.py
        import subprocess
        result = subprocess.run(
            ['python', 'backend/utils/structure_mapper.py'],
            capture_output=True,
            text=True,
            cwd=self.project_root
        )

        return self.docs_dir / 'architecture' / 'structure-map.md'

    def _parse_fastapi_router(self, router_file: Path) -> List[Dict]:
        """FastAPI ë¼ìš°í„° íŒŒì¼ íŒŒì‹±"""

        endpoints = []

        # AST íŒŒì‹±ìœ¼ë¡œ @router.get/@router.post ì¶”ì¶œ
        with open(router_file) as f:
            tree = ast.parse(f.read())

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                for decorator in node.decorator_list:
                    if isinstance(decorator, ast.Call):
                        if hasattr(decorator.func, 'attr'):
                            method = decorator.func.attr
                            if method in ['get', 'post', 'put', 'delete', 'patch']:
                                # Extract path
                                path = decorator.args[0].s if decorator.args else '/'

                                # Extract docstring
                                docstring = ast.get_docstring(node) or "No description"

                                endpoints.append({
                                    'method': method.upper(),
                                    'path': path,
                                    'description': docstring,
                                    'params': self._extract_params(node),
                                    'response': None  # TODO: Extract response type
                                })

        return endpoints

    def _parse_sqlalchemy_models(self, models_file: Path) -> List[Dict]:
        """SQLAlchemy ëª¨ë¸ íŒŒì‹±"""

        models = []

        with open(models_file) as f:
            tree = ast.parse(f.read())

        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # Check if SQLAlchemy model (has __tablename__)
                has_tablename = any(
                    isinstance(child, ast.Assign) and
                    any(t.id == '__tablename__' for t in child.targets if isinstance(t, ast.Name))
                    for child in node.body
                )

                if has_tablename:
                    models.append({
                        'name': node.name,
                        'table': self._get_tablename(node),
                        'columns': self._extract_columns(node),
                        'relationships': []  # TODO: Extract relationships
                    })

        return models

    def _get_tablename(self, class_node: ast.ClassDef) -> str:
        """__tablename__ ì¶”ì¶œ"""
        for child in class_node.body:
            if isinstance(child, ast.Assign):
                for target in child.targets:
                    if isinstance(target, ast.Name) and target.id == '__tablename__':
                        if isinstance(child.value, ast.Constant):
                            return child.value.value
        return class_node.name.lower()

    def _extract_columns(self, class_node: ast.ClassDef) -> List[Dict]:
        """Column ì¶”ì¶œ"""
        columns = []

        for child in class_node.body:
            if isinstance(child, ast.Assign):
                for target in child.targets:
                    if isinstance(target, ast.Name):
                        # Check if Column()
                        if isinstance(child.value, ast.Call):
                            if hasattr(child.value.func, 'id') and child.value.func.id == 'Column':
                                col_type = self._get_column_type(child.value)
                                columns.append({
                                    'name': target.id,
                                    'type': col_type
                                })

        return columns

    def _get_column_type(self, call_node: ast.Call) -> str:
        """Column íƒ€ì… ì¶”ì¶œ"""
        if call_node.args:
            arg = call_node.args[0]
            if isinstance(arg, ast.Name):
                return arg.id
            elif isinstance(arg, ast.Call) and hasattr(arg.func, 'id'):
                return arg.func.id
        return 'Unknown'

    def _extract_params(self, func_node: ast.FunctionDef) -> List[Dict]:
        """í•¨ìˆ˜ íŒŒë¼ë¯¸í„° ì¶”ì¶œ"""
        params = []

        for arg in func_node.args.args:
            if arg.arg not in ['self', 'cls']:
                params.append({
                    'name': arg.arg,
                    'type': self._get_type_annotation(arg.annotation),
                    'description': ''
                })

        return params

    def _get_type_annotation(self, annotation) -> str:
        """íƒ€ì… ì–´ë…¸í…Œì´ì…˜ ì¶”ì¶œ"""
        if annotation is None:
            return 'Any'
        elif isinstance(annotation, ast.Name):
            return annotation.id
        elif isinstance(annotation, ast.Subscript):
            return f"{annotation.value.id}[...]"
        return 'Any'

# CLI
if __name__ == '__main__':
    generator = AntigravityDocGenerator(Path(__file__).parent.parent)

    print("ğŸ¤– [Antigravity] Generating documentation...")

    api_doc = generator.generate_api_docs()
    print(f"âœ… API Docs: {api_doc}")

    erd_doc = generator.generate_db_erd()
    print(f"âœ… DB ERD: {erd_doc}")

    structure_map = generator.update_structure_map()
    print(f"âœ… Structure Map: {structure_map}")

    print("\nâœ… Documentation generation complete!")
```

#### ê²€ì¦
```bash
# ì‹¤í–‰
python scripts/antigravity_doc_generator.py

# ì„±ê³µ ì¡°ê±´
# - API_Reference.md ìƒì„±ë¨
# - Database_ERD.md ìƒì„±ë¨
# - structure-map.md ì—…ë°ì´íŠ¸ë¨
```

#### ì™„ë£Œ ì¡°ê±´
- [ ] AntigravityDocGenerator êµ¬í˜„ ì™„ë£Œ
- [ ] API ë¬¸ì„œ ìë™ ìƒì„± ë™ì‘
- [ ] DB ERD ìë™ ìƒì„± ë™ì‘
- [ ] Git hook ì„¤ì • (post-commit ì‹œ ë¬¸ì„œ ìë™ ê°±ì‹ )

---

### T0.3: Antigravity Task Validator êµ¬ì¶•

#### ì¶œë ¥
```python
# scripts/antigravity_validator.py

"""
Antigravity Task Validator

ê° íƒœìŠ¤í¬ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ ììœ¨ ê²€ì¦:
1. íŒŒì¼ ì¡´ì¬ í™•ì¸
2. í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
3. ë¬¸ì„œ ì—…ë°ì´íŠ¸ í™•ì¸
4. Git ì»¤ë°‹ í™•ì¸
"""

from pathlib import Path
from typing import Dict, List
import subprocess
import json

class TaskValidator:
    """íƒœìŠ¤í¬ ì™„ë£Œ ê²€ì¦ê¸°"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.validation_results = {}

    def validate_task(self, task_id: str, criteria: Dict) -> bool:
        """
        íƒœìŠ¤í¬ ê²€ì¦

        Args:
            task_id: íƒœìŠ¤í¬ ID (ì˜ˆ: "T1.1")
            criteria: ê²€ì¦ ê¸°ì¤€
                {
                    'files': ['path/to/file.py'],
                    'tests': ['test_module::test_func'],
                    'docs': ['docs/path.md'],
                    'commits': 1
                }

        Returns:
            bool: ëª¨ë“  ê¸°ì¤€ í†µê³¼ ì—¬ë¶€
        """

        print(f"\nğŸ¤– [Antigravity] Validating {task_id}...")

        results = {
            'files': self._validate_files(criteria.get('files', [])),
            'tests': self._validate_tests(criteria.get('tests', [])),
            'docs': self._validate_docs(criteria.get('docs', [])),
            'commits': self._validate_commits(criteria.get('commits', 0))
        }

        all_passed = all(results.values())

        self.validation_results[task_id] = {
            'passed': all_passed,
            'details': results
        }

        if all_passed:
            print(f"âœ… {task_id} PASSED")
        else:
            print(f"âŒ {task_id} FAILED")
            for category, passed in results.items():
                status = "âœ…" if passed else "âŒ"
                print(f"  {status} {category}")

        return all_passed

    def _validate_files(self, file_paths: List[str]) -> bool:
        """íŒŒì¼ ì¡´ì¬ ê²€ì¦"""
        for path in file_paths:
            if not (self.project_root / path).exists():
                print(f"  âŒ Missing file: {path}")
                return False
        return True

    def _validate_tests(self, test_patterns: List[str]) -> bool:
        """í…ŒìŠ¤íŠ¸ í†µê³¼ ê²€ì¦"""
        if not test_patterns:
            return True

        for pattern in test_patterns:
            result = subprocess.run(
                ['pytest', '-k', pattern, '--tb=no'],
                capture_output=True,
                text=True,
                cwd=self.project_root
            )

            if result.returncode != 0:
                print(f"  âŒ Test failed: {pattern}")
                return False

        return True

    def _validate_docs(self, doc_paths: List[str]) -> bool:
        """ë¬¸ì„œ ì¡´ì¬ ë° ìµœì‹ í™” ê²€ì¦"""
        for path in doc_paths:
            doc_file = self.project_root / path
            if not doc_file.exists():
                print(f"  âŒ Missing doc: {path}")
                return False

            # Check if updated recently (within last hour)
            import time
            age = time.time() - doc_file.stat().st_mtime
            if age > 3600:  # 1 hour
                print(f"  âš ï¸  Doc outdated: {path} (updated {age/60:.0f} min ago)")

        return True

    def _validate_commits(self, min_commits: int) -> bool:
        """Git ì»¤ë°‹ ê²€ì¦"""
        if min_commits == 0:
            return True

        result = subprocess.run(
            ['git', 'log', '--oneline', '-n', str(min_commits)],
            capture_output=True,
            text=True,
            cwd=self.project_root
        )

        commit_count = len(result.stdout.strip().split('\n'))

        if commit_count < min_commits:
            print(f"  âŒ Expected {min_commits} commits, found {commit_count}")
            return False

        return True

    def generate_validation_report(self) -> Path:
        """ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
        report_path = self.project_root / 'docs' / 'validation_reports' / f'validation_{datetime.now().strftime("%Y%m%d")}.json'
        report_path.parent.mkdir(parents=True, exist_ok=True)

        with open(report_path, 'w') as f:
            json.dump(self.validation_results, f, indent=2)

        return report_path

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == '__main__':
    from datetime import datetime

    validator = TaskValidator(Path(__file__).parent.parent)

    # Example: Validate T1.1
    validator.validate_task('T1.1', {
        'files': ['backend/analytics/var_calculator.py'],
        'tests': ['test_var_calculator'],
        'docs': ['docs/04_API/VaR_API.md'],
        'commits': 1
    })

    report = validator.generate_validation_report()
    print(f"\nğŸ“„ Validation report: {report}")
```

#### ì™„ë£Œ ì¡°ê±´
- [ ] TaskValidator êµ¬í˜„ ì™„ë£Œ
- [ ] íŒŒì¼/í…ŒìŠ¤íŠ¸/ë¬¸ì„œ/ì»¤ë°‹ ê²€ì¦ ë™ì‘
- [ ] ê²€ì¦ ë¦¬í¬íŠ¸ JSON ìƒì„±

---

## ğŸ§¹ Phase 1: ë ˆê±°ì‹œ ì½”ë“œ ì •ë¦¬ (Week 1-4)

### T1.1: War Room Legacy ì‚¬ìš© í˜„í™© ì¡°ì‚¬ (Day 1-2)

#### TDD: í…ŒìŠ¤íŠ¸ ë¨¼ì € ì‘ì„±
```python
# backend/tests/test_api_usage_analyzer.py

import pytest
from scripts.analyze_api_usage import APIUsageAnalyzer

def test_analyzer_parses_legacy_calls():
    """ë ˆê±°ì‹œ API í˜¸ì¶œ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
    log_content = """
    2026-01-27 10:00:00 INFO POST /api/war-room/debate
    2026-01-27 10:05:00 INFO POST /api/war-room-mvp/debate
    """

    analyzer = APIUsageAnalyzer()
    results = analyzer.parse_log_content(log_content)

    assert results['war_room_legacy'] == 1
    assert results['war_room_mvp'] == 1

def test_analyzer_detects_zero_usage():
    """ì‚¬ìš©ëŸ‰ 0 ê°ì§€ í…ŒìŠ¤íŠ¸"""
    log_content = """
    2026-01-27 10:00:00 INFO POST /api/war-room-mvp/debate
    """

    analyzer = APIUsageAnalyzer()
    results = analyzer.parse_log_content(log_content)

    assert results['war_room_legacy'] == 0
    assert analyzer.is_safe_to_remove()
```

#### êµ¬í˜„
```python
# scripts/analyze_api_usage.py

class APIUsageAnalyzer:
    """API ì‚¬ìš© í˜„í™© ë¶„ì„ê¸°"""

    def __init__(self):
        self.legacy_pattern = r'/api/war-room/'
        self.mvp_pattern = r'/api/war-room-mvp/'
        self.phase_pattern = r'/phase/'

    def parse_log_file(self, log_path: str) -> Dict:
        """ë¡œê·¸ íŒŒì¼ ë¶„ì„"""
        with open(log_path) as f:
            return self.parse_log_content(f.read())

    def parse_log_content(self, content: str) -> Dict:
        """ë¡œê·¸ ë‚´ìš© íŒŒì‹±"""
        import re

        legacy_count = len(re.findall(self.legacy_pattern, content))
        mvp_count = len(re.findall(self.mvp_pattern, content))
        phase_count = len(re.findall(self.phase_pattern, content))

        return {
            'war_room_legacy': legacy_count,
            'war_room_mvp': mvp_count,
            'phase_integration': phase_count,
            'total': legacy_count + mvp_count + phase_count
        }

    def is_safe_to_remove(self) -> bool:
        """ì œê±° ì•ˆì „ ì—¬ë¶€ íŒë‹¨ (7ì¼ê°„ ì‚¬ìš©ëŸ‰ 0)"""
        # TODO: ì‹¤ì œ êµ¬í˜„ ì‹œ 7ì¼ì¹˜ ë¡œê·¸ í™•ì¸
        return True

    def generate_report(self, results: Dict) -> str:
        """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        return f"""
# API Usage Analysis Report

Date: {datetime.now().strftime('%Y-%m-%d')}

## Results

### War Room Legacy
- Total calls: {results['war_room_legacy']}
- Recommendation: {'âœ… Safe to remove' if results['war_room_legacy'] == 0 else 'âš ï¸ Still in use'}

### War Room MVP
- Total calls: {results['war_room_mvp']}

### Phase Integration
- Total calls: {results['phase_integration']}
- Recommendation: {'âœ… Safe to remove' if results['phase_integration'] == 0 else 'âš ï¸ Still in use'}
"""
```

#### ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
```bash
# scripts/validate_T1.1.sh

#!/bin/bash

echo "ğŸ¤– [Antigravity] Validating T1.1..."

# 1. í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
pytest backend/tests/test_api_usage_analyzer.py
if [ $? -ne 0 ]; then
    echo "âŒ Tests failed"
    exit 1
fi

# 2. ë¦¬í¬íŠ¸ ìƒì„± í™•ì¸
python scripts/analyze_api_usage.py logs/app.log
if [ ! -f "docs/analysis/260128_API_Usage_Analysis.md" ]; then
    echo "âŒ Report not generated"
    exit 1
fi

echo "âœ… T1.1 Validation PASSED"
```

#### ì™„ë£Œ ì¡°ê±´
- [ ] `test_api_usage_analyzer.py` ì‘ì„± ë° í†µê³¼
- [ ] `analyze_api_usage.py` êµ¬í˜„ ì™„ë£Œ
- [ ] `260128_API_Usage_Analysis.md` ìƒì„±
- [ ] ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ í†µê³¼

---

### T1.2: Deprecation Warning ì¶”ê°€ (Day 3-4)

#### TDD
```python
# backend/tests/test_war_room_deprecation.py

import pytest
from backend.api.war_room_router import router

def test_deprecation_warning_logged():
    """Deprecation Warning ë¡œê¹… í…ŒìŠ¤íŠ¸"""
    from fastapi.testclient import TestClient
    from backend.main import app

    client = TestClient(app)

    # Mock logger
    with patch('backend.api.war_room_router.logger') as mock_logger:
        response = client.post('/api/war-room/debate', json={})

        # Check warning logged
        mock_logger.warning.assert_called()
        assert 'DEPRECATED' in str(mock_logger.warning.call_args)

def test_deprecation_header_returned():
    """ì‘ë‹µ í—¤ë”ì— deprecation ì •ë³´ í¬í•¨ í…ŒìŠ¤íŠ¸"""
    from fastapi.testclient import TestClient
    from backend.main import app

    client = TestClient(app)
    response = client.post('/api/war-room/debate', json={})

    assert 'X-Deprecated' in response.headers
    assert response.headers['X-Deprecated'] == 'true'
    assert 'X-Deprecation-Date' in response.headers
```

#### êµ¬í˜„
```python
# backend/api/war_room_router.py ìˆ˜ì •

from fastapi import Header, Response
import logging

logger = logging.getLogger(__name__)

DEPRECATION_MESSAGE = """
âš ï¸ DEPRECATION WARNING âš ï¸
This endpoint is deprecated and will be removed on 2026-02-28.
Please migrate to /api/war-room-mvp/debate
"""

@router.post("/debate")
async def debate_endpoint(
    request: DebateRequest,
    response: Response
):
    """
    War Room Debate (DEPRECATED)

    âš ï¸ DEPRECATED: Use /api/war-room-mvp/debate instead
    """

    # Log deprecation
    logger.warning(f"[DEPRECATED] War Room Legacy called at {datetime.now()}")

    # Add deprecation headers
    response.headers['X-Deprecated'] = 'true'
    response.headers['X-Deprecation-Date'] = '2026-02-28'
    response.headers['X-Replacement'] = '/api/war-room-mvp/debate'

    # Existing logic
    # ...
```

#### Migration Guide ìë™ ìƒì„±
```python
# scripts/generate_migration_guide.py

def generate_war_room_migration_guide():
    """Migration Guide ìë™ ìƒì„±"""

    # AS-IS ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ
    as_is_schema = extract_schema_from_router('backend/api/war_room_router.py')

    # TO-BE ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ
    to_be_schema = extract_schema_from_router('backend/api/war_room_mvp_router.py')

    # ì°¨ì´ì  ë¹„êµ
    differences = compare_schemas(as_is_schema, to_be_schema)

    # ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ ìƒì„±
    guide = f"""
# War Room Migration Guide

## Schema Changes

### Request
{differences['request']}

### Response
{differences['response']}

## Code Examples

### Before (Legacy)
```python
response = await client.post('/api/war-room/debate', json={as_is_schema})
```

### After (MVP)
```python
response = await client.post('/api/war-room-mvp/debate', json={to_be_schema})
```
"""

    with open('docs/guides/WAR_ROOM_MIGRATION_GUIDE.md', 'w') as f:
        f.write(guide)
```

#### ì™„ë£Œ ì¡°ê±´
- [ ] Deprecation í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼
- [ ] War Room Routerì— Warning ì¶”ê°€
- [ ] Migration Guide ìë™ ìƒì„±
- [ ] ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ í†µê³¼

---

## ğŸ“š Phase 3: Persona-based Trading ì™„ì„± (Week 7-12)

### T3.1: PersonaBriefingService TDD êµ¬í˜„ (Day 35-40)

#### TDD: í…ŒìŠ¤íŠ¸ ë¨¼ì €
```python
# backend/tests/test_persona_briefing_service.py

import pytest
from backend.services.persona_briefing_service import PersonaBriefingService

@pytest.fixture
def briefing_service():
    return PersonaBriefingService()

def test_trading_persona_briefing(briefing_service):
    """Trading í˜ë¥´ì†Œë‚˜ ë¸Œë¦¬í•‘ í…ŒìŠ¤íŠ¸"""
    result = await briefing_service.generate_persona_briefing(
        persona='trading',
        mode='CLOSING'
    )

    assert result['persona'] == 'trading'
    assert result['time_horizon'] == '1-5 days'
    assert 'market_pulse' in result['briefing']
    assert 'key_movers' in result['briefing']
    assert 'quick_actions' in result['briefing']

def test_long_term_persona_briefing(briefing_service):
    """Long-term í˜ë¥´ì†Œë‚˜ ë¸Œë¦¬í•‘ í…ŒìŠ¤íŠ¸"""
    result = await briefing_service.generate_persona_briefing(
        persona='long_term',
        mode='CLOSING'
    )

    assert result['time_horizon'] == '6-18 months'
    assert 'market_narrative' in result['briefing']
    assert 'deep_dive' in result['briefing']

def test_dividend_persona_briefing(briefing_service):
    """Dividend í˜ë¥´ì†Œë‚˜ ë¸Œë¦¬í•‘ í…ŒìŠ¤íŠ¸"""
    result = await briefing_service.generate_persona_briefing(
        persona='dividend',
        mode='CLOSING'
    )

    assert result['time_horizon'] == '1+ years'
    assert 'income_highlights' in result['briefing']
    assert 'safety_check' in result['briefing']

def test_aggressive_persona_briefing(briefing_service):
    """Aggressive í˜ë¥´ì†Œë‚˜ ë¸Œë¦¬í•‘ í…ŒìŠ¤íŠ¸"""
    result = await briefing_service.generate_persona_briefing(
        persona='aggressive',
        mode='CLOSING'
    )

    assert result['time_horizon'] == '1 day'
    assert 'hot_stocks' in result['briefing']
    assert 'volatility_plays' in result['briefing']
```

#### êµ¬í˜„ (ì´ì „ ê³„íšì„œì—ì„œ ê°€ì ¸ì˜¨ PersonaBriefingService)
```python
# backend/services/persona_briefing_service.py

class PersonaBriefingService:
    # ... (ì´ì „ ê³„íšì„œ ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
```

#### ê²€ì¦ ìë™í™”
```python
# scripts/validate_persona_feature.py

"""Persona ê¸°ëŠ¥ E2E ê²€ì¦"""

import asyncio
from backend.services.persona_briefing_service import PersonaBriefingService

async def validate_all_personas():
    """ëª¨ë“  í˜ë¥´ì†Œë‚˜ ê²€ì¦"""

    service = PersonaBriefingService()
    personas = ['trading', 'long_term', 'dividend', 'aggressive']

    results = {}

    for persona in personas:
        print(f"ğŸ¤– Testing {persona} persona...")

        try:
            result = await service.generate_persona_briefing(persona, 'CLOSING')

            # Validate structure
            assert 'briefing' in result
            assert 'time_horizon' in result
            assert 'persona' in result

            results[persona] = 'âœ… PASS'
            print(f"  âœ… {persona} passed")

        except Exception as e:
            results[persona] = f'âŒ FAIL: {str(e)}'
            print(f"  âŒ {persona} failed: {e}")

    # Generate report
    with open('docs/validation_reports/persona_validation.md', 'w') as f:
        f.write("# Persona Feature Validation\n\n")
        for persona, status in results.items():
            f.write(f"- {persona}: {status}\n")

    return all('PASS' in r for r in results.values())

if __name__ == '__main__':
    success = asyncio.run(validate_all_personas())
    exit(0 if success else 1)
```

#### ì™„ë£Œ ì¡°ê±´
- [ ] 4ê°œ í˜ë¥´ì†Œë‚˜ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼
- [ ] PersonaBriefingService êµ¬í˜„ ì™„ë£Œ
- [ ] API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€ ë° í…ŒìŠ¤íŠ¸
- [ ] E2E ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ í†µê³¼
- [ ] ë¬¸ì„œ ìë™ ìƒì„± (API_Reference.md ì—…ë°ì´íŠ¸)

---

## âš¡ Phase 4: Real-time Execution ì™„ì„± (Week 13-18)

### T4.1: MarketDataWebSocketManager TDD êµ¬í˜„ (Day 65-70)

#### TDD
```python
# backend/tests/test_market_data_ws.py

import pytest
from backend.api.market_data_ws import MarketDataWebSocketManager

@pytest.mark.asyncio
async def test_websocket_connection():
    """WebSocket ì—°ê²° í…ŒìŠ¤íŠ¸"""
    manager = MarketDataWebSocketManager()

    # Mock WebSocket
    mock_ws = MockWebSocket()
    await manager.connect(mock_ws)

    assert mock_ws in manager.active_connections

@pytest.mark.asyncio
async def test_subscribe_to_symbols():
    """ì‹¬ë³¼ êµ¬ë… í…ŒìŠ¤íŠ¸"""
    manager = MarketDataWebSocketManager()
    mock_ws = MockWebSocket()

    await manager.connect(mock_ws)
    await manager.subscribe(mock_ws, ['NVDA', 'MSFT'])

    assert 'NVDA' in manager.active_connections[mock_ws]
    assert 'MSFT' in manager.active_connections[mock_ws]

@pytest.mark.asyncio
async def test_quote_streaming():
    """ì‹¤ì‹œê°„ ì‹œì„¸ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸"""
    manager = MarketDataWebSocketManager()
    mock_ws = MockWebSocket()

    await manager.connect(mock_ws)
    await manager.subscribe(mock_ws, ['NVDA'])

    # Wait for quote
    await asyncio.sleep(6)  # > 5ì´ˆ (ìŠ¤íŠ¸ë¦¬ë° ì£¼ê¸°)

    # Check if quote received
    assert len(mock_ws.sent_messages) > 0
    quote = mock_ws.sent_messages[0]
    assert quote['type'] == 'quote'
    assert quote['data']['symbol'] == 'NVDA'
```

#### êµ¬í˜„ (ì´ì „ ê³„íšì„œ ì½”ë“œ í™œìš©)

#### í”„ë¡ íŠ¸ì—”ë“œ E2E í…ŒìŠ¤íŠ¸
```typescript
// frontend/tests/e2e/market-data-ws.spec.ts

import { test, expect } from '@playwright/test';

test.describe('Market Data WebSocket', () => {
  test('should connect and receive quotes', async ({ page }) => {
    await page.goto('/live-dashboard');

    // Wait for connection
    await page.waitForSelector('text=ğŸŸ¢ Connected');

    // Wait for quote update
    await page.waitForTimeout(6000);

    // Check if quote displayed
    const nvdaPrice = await page.locator('[data-testid="quote-NVDA-price"]');
    await expect(nvdaPrice).toBeVisible();

    // Check if price is number
    const priceText = await nvdaPrice.textContent();
    expect(parseFloat(priceText!)).toBeGreaterThan(0);
  });

  test('should handle disconnection', async ({ page }) => {
    await page.goto('/live-dashboard');
    await page.waitForSelector('text=ğŸŸ¢ Connected');

    // Close WebSocket (simulate disconnection)
    await page.evaluate(() => {
      // @ts-ignore
      window.__ws.close();
    });

    // Check for disconnection status
    await page.waitForSelector('text=ğŸ”´ Disconnected');
  });
});
```

#### ì™„ë£Œ ì¡°ê±´
- [ ] WebSocket Manager í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼
- [ ] ë°±ì—”ë“œ WebSocket êµ¬í˜„ ì™„ë£Œ
- [ ] í”„ë¡ íŠ¸ì—”ë“œ hook êµ¬í˜„ ë° E2E í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] Live Dashboard ë Œë”ë§ í…ŒìŠ¤íŠ¸ í†µê³¼

---

## ğŸ“ˆ Phase 5: Advanced Risk Models ì™„ì„± (Week 19-22)

### T5.1: VaR Calculator TDD êµ¬í˜„ (Day 100-110)

#### TDD
```python
# backend/tests/test_var_calculator.py

import pytest
import numpy as np
from backend.analytics.var_calculator import VaRCalculator

@pytest.fixture
def sample_returns():
    """í…ŒìŠ¤íŠ¸ìš© ìˆ˜ìµë¥  ë°ì´í„°"""
    np.random.seed(42)
    return np.random.normal(0.001, 0.02, 252)  # 1ë…„ì¹˜

def test_historical_var_calculation(sample_returns):
    """Historical VaR ê³„ì‚° í…ŒìŠ¤íŠ¸"""
    calculator = VaRCalculator()

    var_95 = calculator.calculate_historical_var(sample_returns, 0.95)

    # VaRëŠ” ìŒìˆ˜ (ì†ì‹¤)
    assert var_95 < 0

    # 95% ì‹ ë¢°ìˆ˜ì¤€: ì•½ 5%ì˜ ìˆ˜ìµë¥ ì´ VaRë³´ë‹¤ ë‚˜ì¨
    worse_returns = sample_returns[sample_returns <= var_95]
    assert len(worse_returns) / len(sample_returns) <= 0.06  # ~5%

def test_parametric_var_calculation(sample_returns):
    """Parametric VaR ê³„ì‚° í…ŒìŠ¤íŠ¸"""
    calculator = VaRCalculator()

    var_95 = calculator.calculate_parametric_var(sample_returns, 0.95)

    # Parametric VaRëŠ” ì •ê·œë¶„í¬ ê°€ì •
    assert var_95 < 0
    assert -0.1 < var_95 < 0  # í˜„ì‹¤ì ì¸ ë²”ìœ„

def test_monte_carlo_var_simulation(sample_returns):
    """Monte Carlo VaR ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸"""
    calculator = VaRCalculator()

    # ê°„ë‹¨í•œ í¬íŠ¸í´ë¦¬ì˜¤
    portfolio = {'NVDA': 0.5, 'MSFT': 0.5}

    # Mock returns DataFrame
    import pandas as pd
    returns_df = pd.DataFrame({
        'NVDA': sample_returns,
        'MSFT': sample_returns * 0.8  # ì•½ê°„ ë‹¤ë¥¸ ë³€ë™ì„±
    })

    var_95, simulations = calculator.calculate_monte_carlo_var(
        portfolio,
        returns_df,
        confidence_level=0.95,
        simulations=10000
    )

    assert var_95 < 0
    assert len(simulations) == 10000

def test_conditional_var_calculation(sample_returns):
    """Conditional VaR (CVaR) ê³„ì‚° í…ŒìŠ¤íŠ¸"""
    calculator = VaRCalculator()

    cvar_95 = calculator.calculate_conditional_var(sample_returns, 0.95)
    var_95 = calculator.calculate_historical_var(sample_returns, 0.95)

    # CVaRëŠ” í•­ìƒ VaRë³´ë‹¤ í¬ê±°ë‚˜ ê°™ìŒ (ë” í° ì†ì‹¤)
    assert cvar_95 <= var_95
```

#### DB ë§ˆì´ê·¸ë ˆì´ì…˜ TDD
```python
# backend/tests/test_portfolio_risk_model.py

import pytest
from backend.database.models import PortfolioRisk
from backend.database.repository import PortfolioRiskRepository

def test_portfolio_risk_model_creation(db_session):
    """PortfolioRisk ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸"""

    risk = PortfolioRisk(
        portfolio_id='test-portfolio-123',
        var_1day_95=-0.025,
        var_1day_99=-0.045,
        var_10day_95=-0.08,
        var_10day_99=-0.14,
        cvar_95=-0.035,
        method='monte_carlo',
        simulations=10000
    )

    db_session.add(risk)
    db_session.commit()

    # Retrieve
    retrieved = db_session.query(PortfolioRisk).filter_by(
        portfolio_id='test-portfolio-123'
    ).first()

    assert retrieved is not None
    assert retrieved.var_1day_95 == -0.025
    assert retrieved.method == 'monte_carlo'

def test_portfolio_risk_repository(db_session):
    """PortfolioRiskRepository í…ŒìŠ¤íŠ¸"""

    repo = PortfolioRiskRepository(db_session)

    # Save
    risk_data = {
        'portfolio_id': 'test-portfolio-456',
        'var_1day_95': -0.02,
        'var_10day_95': -0.06,
        'method': 'historical'
    }

    saved = repo.save_portfolio_risk(risk_data)

    assert saved.portfolio_id == 'test-portfolio-456'

    # Retrieve
    retrieved = repo.get_latest_risk('test-portfolio-456')
    assert retrieved is not None
    assert retrieved.var_1day_95 == -0.02
```

#### ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ (ìë™ ìƒì„±)
```python
# backend/database/migrations/0025_add_portfolio_risk.py

"""
Add PortfolioRisk table

Generated by Antigravity on 2026-06-08
"""

from alembic import op
import sqlalchemy as sa

def upgrade():
    op.create_table(
        'portfolio_risk',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('portfolio_id', sa.String(36), sa.ForeignKey('portfolios.id')),
        sa.Column('var_1day_95', sa.Float()),
        sa.Column('var_1day_99', sa.Float()),
        sa.Column('var_10day_95', sa.Float()),
        sa.Column('var_10day_99', sa.Float()),
        sa.Column('cvar_95', sa.Float()),
        sa.Column('cvar_99', sa.Float()),
        sa.Column('method', sa.String(50)),
        sa.Column('simulations', sa.Integer()),
        sa.Column('calculated_at', sa.DateTime(), server_default=sa.func.now())
    )

def downgrade():
    op.drop_table('portfolio_risk')
```

#### ì™„ë£Œ ì¡°ê±´
- [ ] VaR Calculator í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼ (4ê°€ì§€ ë©”ì„œë“œ)
- [ ] VaRCalculator êµ¬í˜„ ì™„ë£Œ
- [ ] DB ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼
- [ ] ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ë° ì‹¤í–‰
- [ ] API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼
- [ ] E2E ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ í†µê³¼

---

## ğŸ‰ Phase 6: Antigravity ììœ¨ ê²€ì¦ (Week 23-26)

### T6.1: ì „ì²´ ì‹œìŠ¤í…œ E2E ììœ¨ í…ŒìŠ¤íŠ¸ (Day 121-125)

#### ììœ¨ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
```python
# scripts/antigravity_full_validation.py

"""
Antigravity Full System Validation

ì „ì²´ ì‹œìŠ¤í…œì„ ììœ¨ì ìœ¼ë¡œ ê²€ì¦:
1. ëª¨ë“  ìœ ë‹› í…ŒìŠ¤íŠ¸ ì‹¤í–‰
2. E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰
3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
4. ë³´ì•ˆ ê²€ì‚¬ ì‹¤í–‰
5. ë¬¸ì„œ ì»¤ë²„ë¦¬ì§€ ê²€ì¦
6. ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
"""

import asyncio
from pathlib import Path
from typing import Dict
import subprocess
import json

class AntigravityFullValidator:
    """ì „ì²´ ì‹œìŠ¤í…œ ììœ¨ ê²€ì¦ê¸°"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.results = {}

    async def run_full_validation(self) -> Dict:
        """ì „ì²´ ê²€ì¦ ì‹¤í–‰"""

        print("ğŸ¤– [Antigravity] Starting full system validation...")

        # 1. Unit Tests
        print("\n1ï¸âƒ£ Running unit tests...")
        self.results['unit_tests'] = await self._run_unit_tests()

        # 2. E2E Tests
        print("\n2ï¸âƒ£ Running E2E tests...")
        self.results['e2e_tests'] = await self._run_e2e_tests()

        # 3. Performance Tests
        print("\n3ï¸âƒ£ Running performance tests...")
        self.results['performance'] = await self._run_performance_tests()

        # 4. Security Scan
        print("\n4ï¸âƒ£ Running security scan...")
        self.results['security'] = await self._run_security_scan()

        # 5. Documentation Coverage
        print("\n5ï¸âƒ£ Checking documentation coverage...")
        self.results['docs_coverage'] = await self._check_docs_coverage()

        # 6. Feature Completeness
        print("\n6ï¸âƒ£ Validating feature completeness...")
        self.results['features'] = await self._validate_features()

        # Generate final report
        report_path = await self._generate_final_report()

        print(f"\nğŸ“„ Final report: {report_path}")

        return self.results

    async def _run_unit_tests(self) -> Dict:
        """ìœ ë‹› í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""

        result = subprocess.run(
            ['pytest', 'backend/tests/', '--cov=backend', '--cov-report=json', '-v'],
            capture_output=True,
            text=True,
            cwd=self.project_root
        )

        # Parse coverage
        with open(self.project_root / 'coverage.json') as f:
            coverage = json.load(f)['totals']['percent_covered']

        return {
            'passed': result.returncode == 0,
            'coverage': coverage,
            'output': result.stdout
        }

    async def _run_e2e_tests(self) -> Dict:
        """E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""

        result = subprocess.run(
            ['npm', 'run', 'test:e2e'],
            capture_output=True,
            text=True,
            cwd=self.project_root / 'frontend'
        )

        return {
            'passed': result.returncode == 0,
            'output': result.stdout
        }

    async def _run_performance_tests(self) -> Dict:
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""

        # Locust ë˜ëŠ” K6ë¡œ ë¶€í•˜ í…ŒìŠ¤íŠ¸
        # TODO: ì‹¤ì œ êµ¬í˜„

        return {
            'passed': True,
            'avg_response_time': 150,  # ms
            'max_concurrent_users': 100
        }

    async def _run_security_scan(self) -> Dict:
        """ë³´ì•ˆ ìŠ¤ìº” ì‹¤í–‰"""

        # Banditìœ¼ë¡œ Python ì½”ë“œ ìŠ¤ìº”
        result = subprocess.run(
            ['bandit', '-r', 'backend/', '-f', 'json'],
            capture_output=True,
            text=True,
            cwd=self.project_root
        )

        # Parse results
        findings = json.loads(result.stdout) if result.stdout else {}

        return {
            'passed': len(findings.get('results', [])) == 0,
            'findings': findings
        }

    async def _check_docs_coverage(self) -> Dict:
        """ë¬¸ì„œ ì»¤ë²„ë¦¬ì§€ í™•ì¸"""

        # API ì—”ë“œí¬ì¸íŠ¸ vs ë¬¸ì„œ ë¹„êµ
        # ëª¨ë“  APIê°€ ë¬¸ì„œí™”ë˜ì—ˆëŠ”ì§€ í™•ì¸

        # TODO: ì‹¤ì œ êµ¬í˜„

        return {
            'passed': True,
            'coverage': 95.0,  # %
            'missing_docs': []
        }

    async def _validate_features(self) -> Dict:
        """ê¸°ëŠ¥ ì™„ì„±ë„ ê²€ì¦"""

        features = {
            'Persona-based Trading': self._check_persona_feature(),
            'Real-time Execution': self._check_realtime_feature(),
            'Advanced Risk Models': self._check_risk_feature()
        }

        return {
            'passed': all(f['complete'] for f in features.values()),
            'features': features
        }

    def _check_persona_feature(self) -> Dict:
        """Persona ê¸°ëŠ¥ ì™„ì„±ë„ ì²´í¬"""

        checks = {
            'PersonaBriefingService exists': (self.project_root / 'backend/services/persona_briefing_service.py').exists(),
            'API endpoint exists': self._check_api_endpoint('/api/briefing/persona/{persona}'),
            'UI component exists': (self.project_root / 'frontend/src/components/PersonaSelector.tsx').exists(),
            'Tests pass': self._run_specific_tests('test_persona')
        }

        return {
            'complete': all(checks.values()),
            'checks': checks
        }

    def _check_realtime_feature(self) -> Dict:
        """Real-time ê¸°ëŠ¥ ì™„ì„±ë„ ì²´í¬"""

        checks = {
            'WebSocket manager exists': (self.project_root / 'backend/api/market_data_ws.py').exists(),
            'Frontend hook exists': (self.project_root / 'frontend/src/hooks/useMarketDataWebSocket.ts').exists(),
            'Tests pass': self._run_specific_tests('test_market_data_ws')
        }

        return {
            'complete': all(checks.values()),
            'checks': checks
        }

    def _check_risk_feature(self) -> Dict:
        """Risk ê¸°ëŠ¥ ì™„ì„±ë„ ì²´í¬"""

        checks = {
            'VaR Calculator exists': (self.project_root / 'backend/analytics/var_calculator.py').exists(),
            'Risk Metrics exists': (self.project_root / 'backend/analytics/risk_adjusted_metrics.py').exists(),
            'DB model exists': self._check_db_model('PortfolioRisk'),
            'Tests pass': self._run_specific_tests('test_var_calculator')
        }

        return {
            'complete': all(checks.values()),
            'checks': checks
        }

    async def _generate_final_report(self) -> Path:
        """ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±"""

        report_path = self.project_root / 'docs' / 'validation_reports' / 'FINAL_VALIDATION_REPORT.md'
        report_path.parent.mkdir(parents=True, exist_ok=True)

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# Antigravity Final Validation Report\n\n")
            f.write(f"**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # Overall status
            all_passed = (
                self.results['unit_tests']['passed'] and
                self.results['e2e_tests']['passed'] and
                self.results['performance']['passed'] and
                self.results['security']['passed'] and
                self.results['docs_coverage']['passed'] and
                self.results['features']['passed']
            )

            f.write(f"## Overall Status: {'âœ… PASS' if all_passed else 'âŒ FAIL'}\n\n")

            # Detailed results
            f.write("## Test Results\n\n")
            f.write(f"- Unit Tests: {'âœ…' if self.results['unit_tests']['passed'] else 'âŒ'} (Coverage: {self.results['unit_tests']['coverage']:.1f}%)\n")
            f.write(f"- E2E Tests: {'âœ…' if self.results['e2e_tests']['passed'] else 'âŒ'}\n")
            f.write(f"- Performance: {'âœ…' if self.results['performance']['passed'] else 'âŒ'}\n")
            f.write(f"- Security: {'âœ…' if self.results['security']['passed'] else 'âŒ'}\n")
            f.write(f"- Documentation: {'âœ…' if self.results['docs_coverage']['passed'] else 'âŒ'} (Coverage: {self.results['docs_coverage']['coverage']:.1f}%)\n\n")

            # Feature completeness
            f.write("## Feature Completeness\n\n")
            for feature_name, feature_status in self.results['features']['features'].items():
                status = 'âœ… 100%' if feature_status['complete'] else 'âŒ Incomplete'
                f.write(f"### {feature_name}: {status}\n\n")
                for check_name, check_result in feature_status['checks'].items():
                    f.write(f"- {'âœ…' if check_result else 'âŒ'} {check_name}\n")
                f.write("\n")

        return report_path

# CLI
if __name__ == '__main__':
    from datetime import datetime

    validator = AntigravityFullValidator(Path(__file__).parent.parent)
    results = asyncio.run(validator.run_full_validation())

    # Exit with error if validation failed
    all_passed = all([
        results['unit_tests']['passed'],
        results['e2e_tests']['passed'],
        results['performance']['passed'],
        results['security']['passed'],
        results['docs_coverage']['passed'],
        results['features']['passed']
    ])

    exit(0 if all_passed else 1)
```

#### ì™„ë£Œ ì¡°ê±´
- [ ] AntigravityFullValidator êµ¬í˜„ ì™„ë£Œ
- [ ] ëª¨ë“  ê²€ì¦ í•­ëª© í†µê³¼
- [ ] FINAL_VALIDATION_REPORT.md ìƒì„±
- [ ] v3.0.0 ë¦´ë¦¬ìŠ¤ ì¤€ë¹„ ì™„ë£Œ

---

## ğŸ“Š Antigravity ì„±ê³µ ì§€í‘œ

### ìë™í™” ìˆ˜ì¤€
| í•­ëª© | ìë™í™”ìœ¨ | ëª©í‘œ |
|------|---------|------|
| í…ŒìŠ¤íŠ¸ ì‹¤í–‰ | 100% | Git hook ìë™ ì‹¤í–‰ |
| ë¬¸ì„œ ìƒì„± | 100% | ì½”ë“œ ë³€ê²½ ì‹œ ìë™ ê°±ì‹  |
| ê²€ì¦ ë¦¬í¬íŠ¸ | 100% | íƒœìŠ¤í¬ ì™„ë£Œ ì‹œ ìë™ ìƒì„± |
| ë°°í¬ íŒŒì´í”„ë¼ì¸ | 90% | CI/CD ìë™í™” |

### í’ˆì§ˆ ì§€í‘œ
| í•­ëª© | Before | After | ëª©í‘œ |
|------|--------|-------|------|
| Test Coverage | 65% | 85%+ | 80%+ |
| Documentation Coverage | 60% | 95%+ | 90%+ |
| Code Duplication | 15% | <5% | <10% |
| ë ˆê±°ì‹œ ì½”ë“œ | 15% | 0% | 0% |

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

### Immediate Action (Week 0)
```bash
# 1. Antigravity ì¸í”„ë¼ êµ¬ì¶•
python backend/tests/antigravity/test_harness.py
python scripts/antigravity_doc_generator.py

# 2. Git Hooks ì„¤ì •
cp scripts/hooks/pre-commit .git/hooks/
chmod +x .git/hooks/pre-commit

# 3. ì²« íƒœìŠ¤í¬ ì‹¤í–‰ (T1.1)
python scripts/validate_T1.1.sh
```

### Weekly Check-in
ë§¤ì£¼ ê¸ˆìš”ì¼:
- Antigravity ê²€ì¦ ë¦¬í¬íŠ¸ í™•ì¸
- ë‹¤ìŒ ì£¼ íƒœìŠ¤í¬ ê³„íš ê²€í† 
- ë¸”ë¡œì»¤ ì´ìŠˆ í•´ê²°

---

**ì‘ì„±ì**: AI Trading System Team (Antigravity Mode)
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2026-01-25
**ë‹¤ìŒ ë¦¬ë·°**: Week 2 ì¢…ë£Œ ì‹œ (2026-02-09)
**ìƒíƒœ**: ğŸ¤– Ready for Autonomous Execution
