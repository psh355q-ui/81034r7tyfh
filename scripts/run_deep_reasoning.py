#!/usr/bin/env python3
"""
Phase 14: Deep Reasoning Strategy - í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
=====================================================

ì‚¬ìš©ë²•:
    # ì‹¬ì¸µ ì¶”ë¡  í…ŒìŠ¤íŠ¸
    python scripts/run_deep_reasoning.py --mode reasoning --news "Google announced TPU v6"
    
    # A/B ë°±í…ŒìŠ¤íŠ¸
    python scripts/run_deep_reasoning.py --mode backtest
    
    # Knowledge Graph ì´ˆê¸°í™”
    python scripts/run_deep_reasoning.py --mode init_kg
    
    # ì „ì²´ ë°ëª¨
    python scripts/run_deep_reasoning.py --mode demo
"""

import asyncio
import argparse
import sys
import os
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


async def run_reasoning(news_text: str, model: str = None):
    """ì‹¬ì¸µ ì¶”ë¡  ì‹¤í–‰"""
    from backend.ai.reasoning.deep_reasoning import DeepReasoningStrategy
    from backend.ai.ai_client_factory import AIClientFactory
    from backend.config_phase14 import settings
    
    print("=" * 70)
    print("         DEEP REASONING STRATEGY - Phase 14")
    print("=" * 70)
    print(f"\nğŸ“° News: {news_text}\n")
    
    # ëª¨ë¸ ì„ íƒ
    if model:
        client = AIClientFactory.create(model)
    else:
        # Mock í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (ì‹¤ì œ API í˜¸ì¶œ ì—†ìŒ)
        from backend.ai.ai_client_factory import MockAIClient
        client = MockAIClient("mock-demo")
        
        # Google TPU ê´€ë ¨ Mock ì‘ë‹µ ì„¤ì •
        client.set_mock_response("tpu", json.dumps({
            "theme": "Rise of Custom AI Silicon - Anti-Nvidia Alliance",
            "step1_direct": {
                "entities": ["Google", "Nvidia", "Anthropic"],
                "impacts": [
                    {"entity": "Google", "impact": "Vertical integration success - AI chip independence", "sentiment": "positive"},
                    {"entity": "Nvidia", "impact": "Loss of hyperscaler inference market", "sentiment": "negative"},
                    {"entity": "Anthropic", "impact": "Cost reduction through TPU adoption", "sentiment": "positive"}
                ]
            },
            "step2_secondary": {
                "value_chain_analysis": "Google's TPU ecosystem expansion reduces industry-wide Nvidia dependency. Broadcom, as TPU design partner, captures hidden value.",
                "beneficiaries": [
                    {"entity": "Broadcom", "reason": "TPU interconnect & ASIC design partner - royalty increase with TPU adoption"}
                ],
                "losers": [
                    {"entity": "Nvidia", "reason": "CUDA moat erosion, losing inference market share to custom silicon"}
                ],
                "reasoning_trace": [
                    "1. Google TPU v6 achieves 2x efficiency vs Nvidia H100 for inference",
                    "2. Anthropic signs 1M TPU contract â†’ validates non-CUDA development path",
                    "3. Broadcom designs TPU interconnects â†’ captures 5-7% of chip cost",
                    "4. More TPU adoption = More Broadcom revenue, less Nvidia dependency",
                    "5. Long-term: 'Nvidia tax' on AI compute diminishes"
                ]
            },
            "step3_strategy": {
                "primary_beneficiary": {
                    "ticker": "GOOGL", 
                    "action": "BUY", 
                    "confidence": 0.85, 
                    "reason": "Full-stack AI advantage: Chip + Model + Service integration"
                },
                "hidden_beneficiary": {
                    "ticker": "AVGO", 
                    "action": "BUY", 
                    "confidence": 0.90, 
                    "reason": "Pick-and-shovel play: TPU design partner, benefits from all custom ASIC growth"
                },
                "loser": {
                    "ticker": "NVDA", 
                    "action": "TRIM", 
                    "confidence": 0.60, 
                    "reason": "Long-term moat erosion, but short-term still dominant"
                },
                "bull_case": "TPU becomes industry standard for AI inference, Google dominates AI infrastructure cost curve",
                "bear_case": "CUDA ecosystem too entrenched, developers resist switching costs"
            },
            "overall_confidence": 0.78
        }))
    
    strategy = DeepReasoningStrategy(ai_client=client)
    
    result = await strategy.analyze_news(news_text)
    
    # ì•¡ì…˜ ì•„ì´í…œ ì¶œë ¥
    print("\n" + "=" * 70)
    print("                     ACTION ITEMS")
    print("=" * 70)
    
    actions = result.get_action_items()
    for action in actions:
        ticker = action.get('ticker', 'N/A')
        act = action.get('action', 'HOLD')
        conf = action.get('confidence', 0)
        reason = action.get('reason', '')
        
        emoji = "ğŸŸ¢" if act in ["BUY", "STRONG_BUY"] else "ğŸ”´" if act in ["SELL", "TRIM"] else "âšª"
        print(f"\n{emoji} {ticker}: {act} (Confidence: {conf:.0%})")
        print(f"   Reason: {reason}")
    
    # JSON ì €ì¥
    output_path = f"/tmp/reasoning_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_path, 'w') as f:
        json.dump(result.to_dict(), f, indent=2, default=str)
    print(f"\nğŸ“ Result saved to: {output_path}")
    
    return result


async def run_backtest():
    """A/B ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    from backend.backtesting.ab_backtest import ABBacktestEngine
    
    print("=" * 70)
    print("         A/B BACKTEST - Keyword vs CoT+RAG")
    print("=" * 70)
    
    engine = ABBacktestEngine()
    
    # ëª¨ë“  ì—­ì‚¬ì  ì´ë²¤íŠ¸ í…ŒìŠ¤íŠ¸
    report = await engine.run_comparison()
    
    # ë¦¬í¬íŠ¸ ì¶œë ¥
    engine.print_comparison_report(report)
    
    return report


async def init_knowledge_graph():
    """Knowledge Graph ì´ˆê¸°í™”"""
    from backend.data.knowledge_graph.knowledge_graph import KnowledgeGraph
    from backend.config_phase14 import SEED_KNOWLEDGE
    
    print("=" * 70)
    print("         KNOWLEDGE GRAPH INITIALIZATION")
    print("=" * 70)
    
    kg = KnowledgeGraph()
    
    # ìŠ¤í‚¤ë§ˆ ìƒì„±
    print("\n[1/3] Creating schema...")
    kg.ensure_schema()
    
    # Seed ë°ì´í„° import
    print("\n[2/3] Importing seed knowledge...")
    count = await kg.import_seed_knowledge(SEED_KNOWLEDGE)
    print(f"  Imported {count} relationships")
    
    # í†µê³„
    print("\n[3/3] Statistics:")
    stats = kg.get_stats()
    for key, value in stats.items():
        if key != 'relation_distribution':
            print(f"  {key}: {value}")
    
    return kg


async def run_demo():
    """ì „ì²´ ë°ëª¨"""
    print("\n" + "=" * 70)
    print("              PHASE 14: DEEP REASONING DEMO")
    print("=" * 70)
    
    # 1. Knowledge Graph ì´ˆê¸°í™”
    print("\n\nğŸ“Š STEP 1: Knowledge Graph Setup")
    print("-" * 50)
    await init_knowledge_graph()
    
    # 2. ì‹¬ì¸µ ì¶”ë¡  í…ŒìŠ¤íŠ¸
    print("\n\nğŸ§  STEP 2: Deep Reasoning Test")
    print("-" * 50)
    
    test_news_items = [
        "Google announced that Gemini 3.0 was trained entirely on TPU v6, with Anthropic signing a contract for 1 million TPUs.",
        "OpenAI is reportedly working with Broadcom to design custom AI chips for the $500B Stargate datacenter project.",
        "Samsung Electronics reports breakthrough in 2nm foundry yield, potentially winning major AI chip contracts from Nvidia."
    ]
    
    for news in test_news_items:
        await run_reasoning(news)
        print("\n" + "-" * 50 + "\n")
    
    # 3. A/B ë°±í…ŒìŠ¤íŠ¸
    print("\n\nğŸ“ˆ STEP 3: A/B Backtest Comparison")
    print("-" * 50)
    await run_backtest()
    
    print("\n" + "=" * 70)
    print("              DEMO COMPLETE!")
    print("=" * 70)
    print("""
ë‹¤ìŒ ë‹¨ê³„:
1. ì‹¤ì œ AI API í‚¤ ì„¤ì • (.env)
2. PostgreSQL + pgvector ì‹¤í–‰ (Knowledge Graph)
3. ì‹¤ì‹œê°„ ë‰´ìŠ¤ í”¼ë“œ ì—°ê²°
4. Trading Agent í†µí•©

ìì„¸í•œ ë‚´ìš©ì€ docs/Phase14_DeepReasoning.md ì°¸ì¡°
""")


def main():
    parser = argparse.ArgumentParser(
        description="Phase 14: Deep Reasoning Strategy"
    )
    parser.add_argument(
        "--mode", 
        choices=["reasoning", "backtest", "init_kg", "demo"],
        default="demo",
        help="ì‹¤í–‰ ëª¨ë“œ"
    )
    parser.add_argument(
        "--news",
        type=str,
        default="Google announced TPU v6 with 2x efficiency improvement",
        help="ë¶„ì„í•  ë‰´ìŠ¤ í…ìŠ¤íŠ¸"
    )
    parser.add_argument(
        "--model",
        type=str,
        default=None,
        help="ì‚¬ìš©í•  AI ëª¨ë¸ (ì˜ˆ: gemini-1.5-pro, claude-3-haiku-20240307)"
    )
    
    args = parser.parse_args()
    
    if args.mode == "reasoning":
        asyncio.run(run_reasoning(args.news, args.model))
    elif args.mode == "backtest":
        asyncio.run(run_backtest())
    elif args.mode == "init_kg":
        asyncio.run(init_knowledge_graph())
    elif args.mode == "demo":
        asyncio.run(run_demo())


if __name__ == "__main__":
    main()
